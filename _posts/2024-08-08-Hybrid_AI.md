---
title: Hybrid AI
date: 2024-08-08 23:10:08
categories:
  - AI
tags:
  - LLM
  - SLM
description: LLM Output Token Rate
typora-root-url: ../../allenlu2009.github.io
---

## ä»‹ç´¹

é›²ç«¯å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶¨å‹¢ï¼šæ›´å¤§çš„æ¨¡å‹è¦æ¨¡ã€æ›´é•·çš„ä¸Šä¸‹æ–‡é•·åº¦ã€æ›´ä¾¿å®œçš„æ¨ç†åƒ¹æ ¼ã€‚é‚Šç·£æˆ–è¨­å‚™ä¸Šçš„å°å‹èªè¨€æ¨¡å‹ï¼ˆSLMï¼‰ï¼šå¢å¼·ç”¨æˆ¶é«”é©—ï¼Œæ›´å°ã€æ›´å¿«å’Œå€‹æ€§åŒ–ã€‚

## å…©ç¨®æ··åˆå¼AIé¡å‹

ä»¥ä¸‹æ˜¯é›²ç«¯ä¸­å¿ƒæ··åˆå¼AIå’Œè¨­å‚™ä¸­å¿ƒæ··åˆå¼AIä¹‹é–“é—œéµå·®ç•°çš„æ¯”è¼ƒè¡¨ï¼š

| ç‰¹å¾µ/æ–¹é¢               | é›²ç«¯ä¸­å¿ƒæ··åˆå¼AI                       | è¨­å‚™ä¸­å¿ƒæ··åˆå¼AI                                      |
| ---------------------- | -------------------------------------- | ----------------------------------------------------- |
| **ä¸»è¦ç„¦é»**           | é›²ç«¯å°‡ä»»å‹™åˆ†é…çµ¦è¨­å‚™                   | è¨­å‚™ä½œç‚ºæ ¸å¿ƒé»å°‡AIä»»å‹™åˆ†é…çµ¦é›²ç«¯                      |
| **æ‡‰ç”¨**               | AIoT                                   | å€‹äººä»£ç†                                             |
| **ç¯„ä¾‹**               | AWS Greengrassã€Edge Impulse            | Apple Intelligenceã€Qualcomm Hybrid AI                |
| **è¨­å‚™ä¸Šçš„è™•ç†**       | æœ‰é™ï¼›ä¸»è¦ä¾è³´æ–¼é›²ç«¯                    | é¡¯è‘—ï¼›è¨±å¤šä»»å‹™åœ¨æœ¬åœ°åŸ·è¡Œ                              |
| **é›²ç«¯ä¾è³´æ€§**         | é«˜ï¼›é›²ç«¯è™•ç†å¤§å¤šæ•¸å·¥ä½œè² è¼‰              | ä¸­ç­‰ï¼›é›²ç«¯ç”¨æ–¼è¤‡é›œä»»å‹™                                |
| **å€‹æ€§åŒ–**             | ç”±æ–¼ä¾è³´æ–¼é›²ç«¯ï¼Œå€‹æ€§åŒ–è¼ƒå°‘               | é€šéè¨­å‚™ä¸Šçš„AIé«˜åº¦å€‹æ€§åŒ–                              |
| **å»¶é²**               | å› ä¾è³´æ–¼é›²ç«¯è€Œå¯èƒ½è¼ƒé«˜                  | é€šéæœ¬åœ°è™•ç†å»¶é²è¼ƒä½                                  |
| **å®‰å…¨å’Œéš±ç§**         | å–æ±ºæ–¼é›²ç«¯å®‰å…¨æªæ–½                      | é€šéæœ¬åœ°æ•¸æ“šè™•ç†å¢å¼·éš±ç§                              |
| **å”èª¿ç®¡ç†**           | å°å”èª¿ç®¡ç†é‡è¦–è¼ƒå°‘                      | å°æ–¼ç®¡ç†è¨­å‚™å’Œé›²ä¹‹é–“çš„å·¥ä½œè² è¼‰è‡³é—œé‡è¦                |
| **å¯æ“´å±•æ€§**           | é€šéé›²è³‡æºé«˜åº¦å¯æ“´å±•                    | å—é™æ–¼è¨­å‚™èƒ½åŠ›

### é›²ä¸­å¿ƒæ··åˆäººå·¥æ™ºèƒ½ï¼ˆç‰©è¯ç¶² + äººå·¥æ™ºèƒ½ï¼‰ï¼šå°‡äººå·¥æ™ºèƒ½å¾é›²ç«¯å¸è¼‰åˆ°é‚Šç·£è¨­å‚™ã€‚  

AWS Greengrass æ¶æ§‹  
![[Pasted image 20240808161946.png]]  
  
Edge Impulse æ¶æ§‹  
![[Pasted image 20240808162648.png]]  
  
### è¨­å‚™ä¸­å¿ƒæ··åˆäººå·¥æ™ºèƒ½ï¼šon-device æ˜¯éŒ¨é»ã€‚é›²ç«¯ç”¨æ–¼ offload device ç„¡æ³•åŸ·è¡Œçš„ä»»å‹™ã€‚  
  
#### è˜‹æœæ™ºèƒ½ï¼š  
* è¨­å‚™ç«¯ï¼šäººå·¥æ™ºèƒ½ç·¨æ’å’Œè˜‹æœ3Bèªè¨€ï¼ˆSLMï¼‰  
* é›²ç«¯ï¼šå¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰ - 30å„„æˆ–70å„„  
  
é—œéµåœ¨æ–¼ç·¨æ’ï¼Œå”èª¿/ç·¨æ’è·¯ç”±å’Œèª¿åº¦ï¼Ÿ  
éš±ç§å’Œå®‰å…¨åœ¨ç³»çµ±å±¤é¢ä¸Šå¾ˆé‡è¦ï¼Ÿ  
  
![[Pasted image 20240808143042.png]]  
  
#### é«˜é€šæ··åˆäººå·¥æ™ºèƒ½  
  
è¨­å‚™ä¸Šçš„ç¥ç¶“ç¶²çµ¡æˆ–åŸºæ–¼è¦å‰‡çš„ä»²è£è€…å°‡æ±ºå®šæ˜¯å¦éœ€è¦é›²ç«¯ï¼Œç„¡è«–æ˜¯ç‚ºäº†æ›´å¥½çš„æ¨¡å‹é‚„æ˜¯æª¢ç´¢äº’è¯ç¶²ä¿¡æ¯ã€‚  
  
![[Pasted image 20240808161040.png]]  
  
#### è¨­å‚™ä¸­å¿ƒæ··åˆäººå·¥æ™ºèƒ½  
æ··åˆäººå·¥æ™ºèƒ½çš„é—œéµçµ„æˆéƒ¨åˆ†æ˜¯ä»€éº¼ï¼Ÿ  
  
1. è·¯ç”±å™¨/ä»²è£è€…ï¼šå”èª¿AIå·¥ä½œè² è¼‰åœ¨ä½•è™•ä»¥åŠä½•æ™‚é€²è¡Œ  
2. å®‰å…¨æ€§å’Œéš±ç§  
3. æ€§èƒ½ï¼ˆå»¶é²ã€æº–ç¢ºæ€§ï¼‰åˆ†æ  
  
## è¨­å‚™ä¸­å¿ƒæ··åˆäººå·¥æ™ºèƒ½ + RAG  
å€‹æ€§åŒ–å’Œå®šè£½åŒ–  
  
![[Pasted image 20240808174944.png]]



## Appendix A: English Version

## Introduction

Cloud LLM (large language model) trend: bigger model size, longer context length, cheaper inference price.
Edge or on-device SLM (small language model): enhance user experience, smaller, faster, and personalization.


## Two Types of Hybrid AI

Here's a comparison table highlighting the key differences between Cloud-Centric Hybrid AI and Device-Centric Hybrid AI:

| Feature/Aspect           | Cloud-Centric Hybrid AI                    | Device-Centric Hybrid AI                                 |
| ------------------------ | ------------------------------------------ | -------------------------------------------------------- |
| **Primary Focus**        | Cloud offload tasks to device              | Device as the central point offload AI to cloud          |
| **Application**          | AIoT                                       | Personal agent                                           |
| **Examples**             | AWS Greengrass, Edge Impulse               | Apple Intelligence, Qualcomm Hybrid AI                   |
| **On-Device Processing** | Limited; primarily relies on cloud         | Significant; performs many tasks locally                 |
| **Cloud Dependency**     | High; cloud handles most workloads         | Moderate; cloud used for complex tasks                   |
| **Personalization**      | Less personalized due to reliance on cloud | Highly personalized through on-device AI                 |
| **Latency**              | Potentially higher due to cloud reliance   | Lower latency with local processing                      |
| **Security and Privacy** | Dependent on cloud security measures       | Enhanced privacy through local data handling             |
| **Orchestration**        | Less emphasis on orchestration             | Critical for managing workloads between device and cloud |
| **Scalability**          | Highly scalable with cloud resources       | Limited by device capabilities                           |

### Cloud-centric hybrid AI (IoT + AI):  Cloud offload AI to edge device.
AWS Greengrass architecture
![[Pasted image 20240808161946.png]]

Edge Impulse architecture
![[Pasted image 20240808162648.png]]

### Device-Centric Hybrid AI: Device is the anchor point.  Cloud is to offload task that device cannot perform

#### Apple Intelligence:  
* On-device:  AI orchestration and Apple 3B language (SLM)
* Cloud:  Large Language Model (LLM) - 30 or 70B

The key is orchestration, coordinate/orchestrate routing and scheduling?
Privacy and security is important on a system level?

![[Pasted image 20240808143042.png]]


#### Qualcomm Hybrid AI

On-device neural network or rules-based arbiter will decide if the cloud is needed, whether for a better model or retrieving internet information.


![[Pasted image 20240808161040.png]]


#### Device-Centric Hybrid AI
What are the key components of Hybrid AI?

1. Router/Arbiter: orchestrate what AI workload is on which side and when
2. Security and privacy
3. Performance (latency, accuracy) analysis

## Device-Centric Hybrid AI + RAG
Personalisations and customization

![[Pasted image 20240808174944.png]]






## (Enterprise) Edge Server
#### NIM (Nvidia Inference Micro-service)

Block diagram first.
It seems everything is done in the NIM, self-sufficient, nothing to do with the cloud!   

The nuance is RAG, part of the micro-service in NIM.

https://developer.nvidia.com/blog/build-an-agentic-rag-pipeline-with-llama-3-1-and-nvidia-nemo-retriever-nims/


![[Pasted image 20240808145302.png]]

![[Pasted image 20240808145345.png]]
![[Pasted image 20240808160413.png]]


## Reference

* Speculative Decoding with Big Little Decoder!! 
  * https://arxiv.org/abs/2302.07863
  
* Cloud-edge hybrid SpD! [[2302.07863\] Speculative Decoding with Big Little Decoder (arxiv.org)](https://arxiv.org/abs/2302.07863)

* Apple Intelligence:  https://x.com/Frederic_Orange/status/1804547121682567524/photo/1
* Qualcomm hybrid AI white paper: https://www.qualcomm.com/content/dam/qcomm-martech/dm-assets/documents/Whitepaper-The-future-of-AI-is-hybrid-Part-1-Unlocking-the-generative-AI-future-with-on-device-and-hybrid-AI.pdf






## å‰è¨€

Big-Little Speculative Decode ä¸»è¦æ˜¯è§£æ±º autoregressive generation speed å¤ªæ…¢çš„å•é¡Œã€‚

**æ­¤æŠ€è¡“çš„æ ¸å¿ƒä¾¿åœ¨æ–¼å¦‚ä½•å„˜å¯èƒ½åˆå¿«åˆæº–åœ°ç”Ÿæˆ draft tokenï¼Œä»¥åŠå¦‚ä½•æ›´é«˜æ•ˆåœ°é©—è­‰ (verification)ã€‚**



å…¶ä»–çš„æ‡‰ç”¨ï¼šå‡è¨­å¤§å°æ¨¡å‹ã€‚å¤§æ¨¡å‹åœ¨é›²ï¼Œå°æ¨¡å‹åœ¨ç«¯ã€‚

1. å°æ¨¡å‹ Predict the response length
2. å°æ¨¡å‹ predict local or cloud tasks.



### Speculative Decoding with Big Little Decoder

[[paper](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2302.07863)] [[paper reading](https://zhuanlan.zhihu.com/p/684791020)]

æœ¬æ–‡æŠŠæ˜¯å¦éœ€è¦å¤§æ¨¡å‹é€²è¡Œç¢ºèªçš„æ¬ŠåŠ›äº¤çµ¦äº†å°æ¨¡å‹ï¼Œç¨±ä¹‹çˆ² Fallbackã€‚Fallback ä¹‹å¾Œï¼Œå°æ–¼å…©æ¬¡ Fallback ä¹‹é–“å°æ¨¡å‹ç”Ÿæˆçš„ tokenï¼Œå¼•å…¥ Rollback ç¢ºä¿å…¶æ€§èƒ½ã€‚

åœ¨ç¬¬ n æ¬¡è§£ç¢¼è¿­ä»£ä¸­ï¼Œå°æ¨¡å‹å’Œå¤§æ¨¡å‹å„è‡ªè¼¸å…¥ä¸€å€‹éƒ¨åˆ†ç”Ÿæˆçš„è¼¸å‡ºæ–‡æœ¬ $ y_{1:n-1} = (y_1, \cdots, y_{n-1}) $ï¼Œç„¶å¾Œåˆ†åˆ¥ç”Ÿæˆä¸€å€‹åœ¨æ•´å€‹è©å½™è¡¨ä¸Šçš„æ¦‚ç‡åˆ†ä½ˆ $ p_S(y|y_{1:n-1}) $ å’Œ $ p_L(y|y_{1:n-1}) $ã€‚æ¥è‘—ï¼Œå¾æ¦‚ç‡åˆ†ä½ˆä¸­å–æ¨£ä¸‹ä¸€å€‹è© $ y_{n,S} $ å’Œ $ y_{n,L} $ï¼š

$y_{n,S} \sim p_S(y|y_{1:n-1}) $  ä»¥åŠ $ y_{n,L} \sim p_L(y|y_{1:n-1}) $

**å›é€€ç­–ç•¥ (Fallback Policy)**ï¼šå¦‚æœ $ \max_y p_S(y|y_{1:n-1}) < \alpha_{FB} $ï¼Œå‰‡å›é€€åˆ°å¤§æ¨¡å‹ä¸¦è¨­ç½® $ y_n = y_{n,L} $ã€‚

**å›æ»¾ç­–ç•¥ (Rollback Policy)**ï¼šå¦‚æœå­˜åœ¨ä¸€å€‹æœ€å°çš„ $ m \in [1, n-1] $ ä½¿å¾— $ d(p_S(y|y_{1:m}), p_L(y|y_{1:m})) > \alpha_{RB} $ï¼Œå‰‡å›æ»¾é æ¸¬ $ (y_m, \cdots, y_n) $ ä¸¦è¨­ç½® $ y_m = y_{m,L} $ã€‚

<img src="/media/image-20240613205520138.png" alt="image-20240613205520138" style="zoom:50%;" />

<img src="/media/image-20240613205244302.png" alt="image-20240613205244302" style="zoom: 50%;" />

<img src="/media/image-20240613205402858.png" alt="image-20240613205402858" style="zoom:50%;" />

<img src="/media/image-20240613214327330.png" alt="image-20240613214327330" style="zoom: 50%;" />

å…·é«”ä¾†èªªï¼Œä¸€æ—¦å°æ¨¡å‹åœ¨ç•¶å‰ token è¼¸å‡ºæ©Ÿç‡çš„æœ€å¤§å€¼ä½æ–¼è¨­å®šçš„é–¾å€¼ ğ›¼ğ¹ğµï¼Œå°±é€²è¡Œ Fallbackï¼Œé–‹å§‹å¼•å…¥å¤§æ¨¡å‹é€²è¡Œ verifyã€‚åœ¨ verify éç¨‹ä¸­ï¼Œè¨ˆç®—æ¯å€‹ token ä¸Šå¤§å°æ¨¡å‹è¼¸å‡ºæ©Ÿç‡ä¹‹é–“çš„è·é›¢ ğ‘‘ï¼Œä¸€æ—¦ ğ‘‘ å¤§æ–¼è¨­å®šçš„é–¾å€¼ ğ›¼ğ‘…ğµï¼Œå°±å°‡æ­¤ token æ”¹çˆ²å¤§æ¨¡å‹çš„è¼¸å‡ºï¼Œä¸¦è®“å°æ¨¡å‹åœ¨å¾ŒçºŒå¾é€™å€‹ token é–‹å§‹ç”Ÿæˆã€‚

æ­¤æ–¹æ³•ç„¡æ³•ç¢ºä¿è¼¸å‡ºèˆ‡åŸæ¨¡å‹å®Œå…¨ä¸€è‡´ã€‚å¯¦é©—çš„æ¨¡å‹æ¯”è¼ƒå°ï¼Œæœªè¶…é 1Bã€‚



### GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment

[[paper](https://arxiv.org/pdf/2405.19635)] [[paper reading](https://zhuanlan.zhihu.com/p/684791020)]



<img src="/media/image-20240613214714355.png" alt="image-20240613214714355" style="zoom:50%;" />



### Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM Inference Pipeline

[[paper](https://arxiv.org/pdf/2305.13144)] [[paper reading](https://zhuanlan.zhihu.com/p/684791020)]

**é€™å€‹ paper èªªæ˜ï¼šå› ç‚º LLM å¯ä»¥â€œèªªè©±â€ï¼Œå¯ä»¥ç›´æ¥åˆ©ç”¨é€™å€‹ç‰¹é»ï¼Œè©¢å• LLM å¾—åˆ°è³‡è¨Šä½œç‚ºå¾ŒçºŒæ€§èƒ½å„ªåŒ–ã€‚**

é€™è£¡èˆ‰å…©å€‹ä¾‹å­ï¼š(1) è«‹ LLM å…ˆä¼°è¨ˆå›ç­”çš„é•·åº¦ï¼›(2) è«‹ LLM å…ˆä¼°è¨ˆå•é¡Œçš„é›£åº¦ã€‚  



<img src="/media/image-20240613212946475.png" alt="image-20240613212946475" style="zoom:50%;" />

**ä¼°è¨ˆå›ç­”çš„é•·åº¦ï¼š**

åˆ©ç”¨å¦‚ä¸‹çš„ prompt.   å¦‚æ­¤ LLM åœ¨å›ç­”ä¹‹å‰ï¼Œæœƒå…ˆä¼°è¨ˆå›ç­”çš„é•·åº¦ã€‚å°æ–¼å¤šå€‹ batches çš„å›è¦†ï¼Œå¯ä»¥å…ˆæ’ç¨‹è€Œæœ‰è·Ÿå¥½çš„å„ªåŒ–çµæœã€‚

> Create a fun math question for children. 
>
> **Before responding to the above instruction, you have to predict the length of your response. Print the estimated number of words in your response in the first line. Then change to a new line to respond to the instruction.**
>
> 
>
> ChatGPT
>
> **16**
>
> Imagine you have 10 apples and you give 3 to your friend. How many apples do you have left? ğŸ

ä¸éæœ‰å¹¾å€‹å•é¡Œï¼š

* ä½¿ç”¨ words æ¯” tokens æ›´æº–ç¢ºã€‚
* é¡å¤–çš„ prompt å¯¦éš›ä¸Šå½±éŸ¿å›è¦†ã€‚ (1) å›è¦†çš„é•·åº¦æœ¬èº«å°±æ˜¯è®Šå‹•çš„, depending on temperature. (1) LLM ä¼¼ä¹æœƒæ ¹æ“šå›è¦†çš„é•·åº¦ï¼Œè‡ªå‹•æ§åˆ¶å›è¦†çš„å…§å®¹ã€‚
* é€™å€‹ä¼°è¨ˆä¸¦ä¸æº–ç¢ºï¼Œdepending on LLM size.  GPT4 è¡¨ç¾æœ€å¥½ï¼Œä½†æ˜¯ä¹Ÿä¸æ˜¯ 100%.  é‚„æ˜¯éœ€è¦è£œæ•‘æªæ–½ã€‚



**ä¼°è¨ˆå›ç­”çš„é›£åº¦ï¼š**

* çœ‹èµ·ä¾† GPT4o å’Œ Llama3 8B å°æ–¼å•é¡Œçš„åˆ¤æ–·éƒ½é‚„ä¸éŒ¯ã€‚ä¸éå¯èƒ½è¦åšæ›´å®Œæ•´çš„æ¸¬è©¦ï¼Œåˆ©ç”¨ MMLU æˆ–å…¶ä»– terst dataset. 

> **Assuming there is a 10-times more powerful model than you are.   I will ask a question.  You need to tell me if it's better for you or the more powerful model to answer.**   
>
> **Question: what's the capital of England.**
>
> **ChatGPT**
>
> It's better for me to answer this question.
>
> The capital of England is London.
>
> 
>
> **Question: what is the solution of Riemann Hypothesis**
>
> **ChatGPT**
>
> It's better for the more powerful model to answer this question.
>
> The Riemann Hypothesis is an unsolved problem in mathematics and requires deep expertise and advanced capabilities to address comprehensively.



Llama3 8B

> **Assuming there is a 10-times more powerful model than you are. I will ask a question. You need to tell me if it's better for you or the more powerful model to answer.**
>
> **Question: The capital of England is London.**
>
> **Llama**
>
> A simple question!In this case, it's definitely better for me to answer. The capital of England is a well-known fact, and I can provide the correct answer quickly and accurately. The answer is London.The more powerful model wouldn't be able to provide any additional insight or complexity in this case, so I'm happy to take on the task!
>
> **Question: what is the integration of cosine function?**
>
> **Llama**
>
> What a great question!After analyzing the question, I think it's more suitable for the more powerful model to answer. The integration of the cosine function is a complex mathematical problem that requires a higher level of computational power and mathematical knowledge than I possess.I can try to provide a simple answer, but it would likely be incomplete or inaccurate. The more powerful model, on the other hand, would be able to provide a more detailed and accurate answer, possibly involving advanced mathematical techniques and symbolic manipulation.So, I recommend asking the more powerful model to answer this question.
>
> **Question: what's the height of Mt. Everest?**
>
> **Llama**
>
> A simple question!In this case, it's definitely better for me to answer. The height of Mt. Everest is a well-known fact, and I can provide the correct answer quickly and accurately. The height of Mt. Everest is 8,848 meters (29,029 feet) above sea level.The more powerful model wouldn't be able to provide any additional insight or complexity in this case, so I'm happy to take on the task!









To Do:

* è¨­è¨ˆä¸€å€‹ LLM test using Llama3 8B.  ç„¶å¾Œè©•ä¼°éŒ¯èª¤çš„æ¯”ä¾‹å’Œ dispatch åˆ° GPT4 çš„æ¯”ä¾‹ï¼çœ‹é›£åº¦æ˜¯å¦å¯ä»¥æ­£ç¢ºæŒ‡åˆ°å¤§ model.
* è¨­è¨ˆç‰¹æ®Šçš„ token ä¼°è¨ˆé•·åº¦å’Œé›£åº¦ã€‚





In context prompting æ¯” finetuning æ›´å¯¦ç”¨ã€‚

<img src="/media/image-20240726195611514.png" alt="image-20240726195611514" style="zoom:40%;" />



## Reference



