<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-08-14T18:22:51+08:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">NexT</title><author><name>Allen Lu (from John Doe)</name></author><entry><title type="html">Math AI - From EM to Variational Bayesian Inference</title><link href="http://localhost:4000/ai/2021/08/05/Math_AI_Baysian_variational/" rel="alternate" type="text/html" title="Math AI - From EM to Variational Bayesian Inference" /><published>2021-08-05T16:29:08+08:00</published><updated>2021-08-05T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/08/05/Math_AI_Baysian_variational</id><content type="html" xml:base="http://localhost:4000/ai/2021/08/05/Math_AI_Baysian_variational/">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&lt;/script&gt;

&lt;h2 id=&quot;major-reference&quot;&gt;Major Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;[@poczosCllusteringEM2015]&lt;/li&gt;
  &lt;li&gt;[@matasExpectationMaximization2018] good reference&lt;/li&gt;
  &lt;li&gt;[@choyExpectationMaximization2017]&lt;/li&gt;
  &lt;li&gt;[@tzikasVariationalApproximation2008] excellent introductory paper&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;em-algorithm&quot;&gt;EM Algorithm&lt;/h2&gt;
&lt;p&gt;EM 可以視為 MLE 的 extension to hidden state / data.&lt;/p&gt;

&lt;p&gt;Let’s start with EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x} ; \boldsymbol{\theta})&amp;=F(q, \boldsymbol{\theta})+K L(q \| p) \\
F(q, \boldsymbol{\theta})&amp;=\int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z} \\
\mathrm{KL}(q \| p)&amp;=-\int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z}
\end{align} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right) &amp;=\int p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\text {OLD }}\right) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) d \mathbf{z} \nonumber\\
&amp;=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{0 \mathrm{LD}}\right)} \label{eqQ}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;此時可以用 $\eqref{eqQ}$ 定義 EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\text{E-step : Compute}\quad &amp;p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\mathrm{OLD}}\right) \label{eqE}\\
\text{M-step : Evaluate}\quad &amp;\boldsymbol{\theta}^{\mathrm{NEW}}=\underset{\boldsymbol{\theta}}{\arg \max } Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right) \label{eqM}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;一般 $\eqref{eqQ}$ 的 joint distribution $p\left(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}\right)$ 包含完整的 data，容易計算或有 analytical solution.
大多的問題是 $\eqref{eqE}$ conditional or posterior distribution 是否容易計算，是否有 analytical solution.&lt;/p&gt;

&lt;h2 id=&quot;variational-em-framework&quot;&gt;Variational EM Framework&lt;/h2&gt;

&lt;p&gt;最簡單的話就是 hidden variable z = z1, z2, .., zM.  and p(z) = p(z1)…p(zM).
什麼時候會有這種 distribution product?  後面會說明。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q(\mathbf{z})=\prod_{i=1}^{M} q_{i}\left(z_{i}\right) \label{eqFactor}
\end{equation}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
F(q, \boldsymbol{\theta})=&amp; \int \prod_{i} q_{i}\left[\ln p (\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})-\sum_{i} \ln q_{i}\right] d \mathbf{z}\nonumber\\
=&amp; \int \prod_{i} q_{i} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i} d z_{i} - \sum_{i} \int \prod_{j} q_{j} \ln q_{i} d z_{i} \nonumber\\
=&amp; \int q_{j}\left[\int \ln p (\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i \neq j}\left(q_{i} d z_{i}\right)\right] d z_{j} -\int q_{j} \ln q_{j} d z_{j}-\sum_{i \neq j} \int q_{i} \ln q_{i} d z_{i} \nonumber\\
=&amp; \int q_{j} \ln \tilde{p} (\mathbf{x}, z_{j} ; \boldsymbol{\theta}) d z_{i}-\int q_{j} \ln q_{j} d z_{j} -\sum_{i \neq j} \int q_{i} \ln q_{i} d z_{i} \nonumber\\
=&amp;-\mathrm{KL}\left(q_{j} \| \tilde{p}\right)-\sum_{i \neq j} \int q_{i} \ln q_{i} d z \label{eqVarELBO}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\ln \tilde{p}\left(\mathbf{x}, z_{j} ; \boldsymbol{\theta}\right)=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{i \neq j}=\int \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i \neq j}\left(q_{i} d z_{i}\right) \label{eqVarJ}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqVarELBO}$ 是 (variational, 因為有 KL divergence) lower bound, KL divergence 必大於 0, 負號後必小於 0.  第二項加上負號是 self-entropy 必大於 0.&lt;br /&gt;
直觀看出讓 KL 為 0，就是 $q_j(z_j) = \tilde{p}(x, z_j; \theta)$, 似乎就是最大值 (how about the self-entropy?).
也就是 optimal distribution $q_j^* (z_j)$ 是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln q_j^* \left(z_{j}\right)=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{i \neq j} + \text{const.}&lt;/script&gt;

&lt;p&gt;上面的 const 可以由 distribution normalization 得到。所以我們可以得到一組 consistency conditions $\eqref{eqVarJ2}$ for the maximum of variational lower bound subject to $\eqref{eqFactor}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q_{j}^{*}\left(z_{j}\right)=\frac{\exp \left(\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{i \neq j}\right)}{\int \exp \left(\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{i \neq j}\right) d z_{j}} \quad\text{for}\,\, j=1,\cdots,M \label{eqVarJ2}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqVarJ2}$ 顯然不會有 explicit solution, 因為 $q_j$ factors 之間是相互 dependent.  A consistent solution 需要 cycling through these factors.  我們定義 Variational EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\text{Variational E-step : Evaluate}\quad &amp;q^{\mathrm{NEW}}(\mathbf{z})\quad\text{using above equations}\\
\text{Variational M-step : Find}\quad &amp;\boldsymbol{\theta}^{\mathrm{NEW}}=\underset{\boldsymbol{\theta}}{\arg \max } F\left(q^{\mathrm{NEW}}, \boldsymbol{\theta}\right) \label{eqM2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&quot;例一-linear-regression-filterestimate-a-noisy-signal&quot;&gt;例一： Linear Regression (filter/estimate a noisy signal)&lt;/h3&gt;
&lt;p&gt;我很喜歡這個例子。從簡單的 least-square error filter 進步到 Kalman filter.  類似的應用：deconvolution/equalization, channel estimation, speech recognition, frequency estimation, time series prediction, and
system identification.&lt;/p&gt;

&lt;h4 id=&quot;問題描述&quot;&gt;問題描述&lt;/h4&gt;
&lt;p&gt;考慮一個未知信號 $y(x) \in R, x \in \Omega ⊆ R^N$, i.e. $R^N \to R$. 
我們想要 predict its value $t_* = y(x_&lt;em&gt;)$ at an arbitrary location $x_&lt;/em&gt; \in \Omega$.&lt;/p&gt;

&lt;p&gt;我們用 vector 表示 $(t_1, \cdots, t_N)$
 using a vector t = (t1,…, tN)T of N noisy observations tn = y(xn) + εn, at locations x = (x1,…, xN)T, xn ∈ , n = 1,…, N. The additive noise εn is commonly assumed to be independent, zeromean, Gaussian distributed:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y(\mathbf{x})=\sum_{m=1}^{M} \omega_{m} \phi_{m}(\mathbf{x})&lt;/script&gt;

&lt;p&gt;注意 $y(x)$ 不是真正的 observables, 而是加上 noise 之後的 t 才是 observations.  我們的目標就是用 $\mathbf{t}$ 來 estimate $\mathbf{w}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{t}=\boldsymbol{\Phi} \mathbf{w}+\boldsymbol{\varepsilon}&lt;/script&gt;

&lt;p&gt;The likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
p(\mathbf{t} ; \mathbf{w}, \beta)&amp;=N\left(\mathbf{t} \mid \mathbf{\Phi} \mathbf{w}, \beta^{-1} \mathbf{I}\right)\\
&amp;=(2 \pi)^{-\frac{N}{2}} \beta^{\frac{N}{2}} \exp \left(-\frac{\beta}{2}\|\mathbf{t}-\Phi \mathbf{w}\|^{2}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;三種解法圖式&quot;&gt;三種解法圖式&lt;/h4&gt;

&lt;p&gt;以下我們用三種 methodologies 用 $\mathbf{t}$ 來 estimate $\mathbf{w}$ (i.e. signal) and $\beta$ (i.e. noise if needed).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 1:&lt;/em&gt; ML Estimation 
如果 number of parameters (w) is the same as the number of observations (t), the ML estimates are very sensitive to the model noise.  我們可以用 DAG (Directed Acyclic Graphic) 說明，如下圖 (a).  雙圓框 t 代表 observed random variable. 方框 (W, beta) 代表 parameter to be estimated.  單圓框（e.g. (b) W）代表 hidden random variable.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 2:&lt;/em&gt; 假設 weight W 是 random variable with imposed prior. 我們先用 a simple Bayesian model with stationary Gaussian prior on weight, 如下圖 (b).  以這個 model 而言，我們用 EM algorithm performs Bayesian inference.  結果 robust to noise, 類似 Kalman filter?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286850167880.jpg&quot; alt=&quot;-w414&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286850167880.jpg&quot; width=&quot;414&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 3:&lt;/em&gt; method 2 的一個缺點是假設 stationary Gaussian noise (i.e. $\beta$, a fixed value to be estimated, 無法 capture the local signal properties.  我們可以引入更複雜 spatially/temporally varying hierarchical model which is based on a non-stationary Gaussian prior for the weight, W and a hyperprior, $\beta$, 如下圖 (c).&lt;/p&gt;

&lt;p&gt;這麼複雜的 DAG 顯然無法用 EM algorithm 解，必須用本文的 “Variational EM Framework” infer values of the unknowns.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286850351205.jpg&quot; alt=&quot;-w245&quot; /&gt;
&lt;img src=&quot;/media/16286850351205.jpg&quot; width=&quot;245&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;method-1-ml-for-vanilla-linear-regression&quot;&gt;Method 1, ML for Vanilla Linear Regression&lt;/h4&gt;

&lt;p&gt;始於 likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
p(\mathbf{t} ; \mathbf{w}, \beta)=(2 \pi)^{-\frac{N}{2}} \beta^{\frac{N}{2}} \exp \left(-\frac{\beta}{2}\|\mathbf{t}-\Phi \mathbf{w}\|^{2}\right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;假設 $\mathbf{w}, \beta$ 為 constant parameters (to be estimated).  Maximize the likelihood or log-likelihood 等價於 minimize $|\mathbf{t}-\Phi \mathbf{w}|^{2}$.  因此**maximal likelihood (ML) estimate of w 等價 least squares (LS) estimate.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\mathbf{w}_{L S}=\underset{w}{\arg \max } p(\mathbf{t} ; \mathbf{w}, \beta)=\underset{w}{\arg \min } E_{L S}(\mathbf{w})=\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)^{-1} \boldsymbol{\Phi}^{T} \mathbf{t} \label{eqLS}
\end{equation}&lt;/script&gt;

&lt;p&gt;很多情況 $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)$ 可能是 “ill-conditioned” and difficult to invert.  意味如果 observation t 包含 noise $\varepsilon$, noise 會嚴重干擾 $\mathbf{w}_{L S}$ estimation.&lt;/p&gt;

&lt;h5 id=&quot;例-1acommunication-equalizationdeconvolution&quot;&gt;例 1A：Communication equalization/deconvolution&lt;/h5&gt;
&lt;p&gt;Assuming a lowpass channel $\Phi = 1 + 0.9 z^{-1}$.  The equalizer $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)^{-1} \boldsymbol{\Phi}^{T}$ 變成 highpass filter; zero-forcing equalizer (ZFE).  如果 noise $\varepsilon$ 是 broadband noise, high frequency noise 會被放大。&lt;/p&gt;

&lt;p&gt;In the case of ML, 我們必須小心選 basis functions to ensure matrix $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)$ can be inverted and avoid “ill-condition”.  通常使用 sparse model with few basis functions.&lt;/p&gt;

&lt;h4 id=&quot;method-2-em-algorithm-for-bayesian-linear-regression&quot;&gt;Method 2, EM algorithm for Bayesian Linear Regression&lt;/h4&gt;

&lt;p&gt;Method 2 放寬 $w$ 從定值 fixed value 變成 distribution (random variable). Voila，這就是 Bayesian 精神！&lt;/p&gt;

&lt;p&gt;A Bayesian treatment of the linear model begins by assigning a prior distribution to the weights of the model. This introduces bias in the estimation but also greatly reduces its variance, which is a major problem of the ML estimate.&lt;/p&gt;

&lt;p&gt;此處我們用 common choice of independent, zero-mean, Gaussian prior distribution for the weights of the linear model:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{w} ; \alpha)=\prod_{m=1}^{M} N\left(w_{m} \mid 0, \alpha^{-1}\right)&lt;/script&gt;

&lt;p&gt;當然假設 zero-mean 聽起來有點奇怪，有可能引入 bias, 但好處是有 regularization 的效果，儘量讓 $w_m$ 不要太大。&lt;/p&gt;

&lt;p&gt;Bayesian inference 接下來是計算 posterior distribution of the hidden variable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
p(\mathbf{w} \mid \mathbf{t} ; \alpha, \beta)=\frac{p(\mathrm{t} \mid \mathbf{w} ; \beta) p(\mathbf{w} ; \alpha)}{p(\mathbf{t} ; \alpha, \beta)} \label{eqMAP}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqMAP}$ 分母部分進一步展開：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{t} ; \alpha, \beta)=\int p(\mathbf{t} \mid \mathbf{w} ; \beta) p(\mathbf{w} ; \alpha) d \mathbf{w}=N\left(\mathbf{t} \mid 0, \beta^{-1} \mathbf{I}+\alpha^{-1} \mathbf{\Phi} \boldsymbol{\Phi}^{T}\right)&lt;/script&gt;

&lt;p&gt;$\eqref{eqMAP}$，posterior of the hidden variable，可以寫成：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation} 
p(\mathbf{w} \mid \mathbf{t} ; \alpha, \beta)=N(\mathbf{w} \mid \boldsymbol{\mu}, \boldsymbol{\mathbf{\Sigma}}) \label{eqPost}
\end{equation}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\boldsymbol{\mu} &amp;=\beta \boldsymbol{\Sigma} \Phi^{T} \mathbf{t} \label{eqMean}\\
\boldsymbol{\Sigma} &amp;=\left(\beta \boldsymbol{\Phi}^{T} \boldsymbol{\Phi}+\alpha \mathbf{I}\right)^{-1} \label{eqVar}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;可以證明，$\alpha, \beta$ 可以用以下的 maximum likelihood estimate.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\left(\alpha_{\mathrm{ML}}, \beta_{\mathrm{ML}}\right)=&amp; \underset{\alpha, \beta}{\arg \min }\left\{\log \left|\beta^{-1} \mathbf{I}+\alpha^{-1} \boldsymbol{\Phi} \boldsymbol{\Phi}^{T}\right|\right. \nonumber \\
&amp;\left.+\mathbf{t}^{T}\left(\beta^{-1} \mathbf{I}+\alpha^{-1} \boldsymbol{\Phi} \boldsymbol{\Phi}^{T}\right)^{-1} \mathbf{t}\right\} \label{eqab}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;直接計算 $\eqref{eqab}$ 非常困難。除了 $\eqref{eqab}$ 微分非常複雜。$\alpha, \beta \ge 0$ 是一個 constrained optimization 問題。 EM algorithm 提供一個有效的方法解 $\alpha, \beta$ and infer $\mathbf{w}$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;E-step&lt;/strong&gt; Compute the Q function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta) &amp;=\langle\ln p(\mathbf{t}, \mathbf{w} ; \alpha, \beta)\rangle_{p\left(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)}\right)} \\
&amp;=\langle\ln p(\mathbf{t} \mid \mathbf{w} ; \alpha, \beta) p(\mathbf{w} ; \alpha, \beta)\rangle_{p\left(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)}\right)} \\
&amp;=\left\langle\frac{N}{2} \ln \beta-\frac{\beta}{2}\left(\|\mathbf{t}-\boldsymbol{\Phi} \mathbf{w}\|^{2}\right)\right.\\
&amp;\left.+\frac{M}{2} \ln \alpha-\frac{\alpha}{2}\left(\|\mathbf{w}\|^{2}\right)\right\rangle+\text { const } \\
=&amp; \frac{N}{2} \ln \beta-\frac{\beta}{2}\left\langle\|\mathbf{t}-\boldsymbol{\Phi} \mathbf{w}\|^{2}\right\rangle+\frac{M}{2} \ln \alpha \\
&amp;-\frac{\alpha}{2}\left(\left\langle\|\mathbf{w}\|^{2}\right\rangle\right)+\text { const. }
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;三角括號是對 $p(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)})$ 的期望值。代入 $\eqref{eqPost}$ 得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)=&amp; \frac{N}{2} \ln \beta-\frac{\beta}{2}\left(\left\|\mathbf{t}-\boldsymbol{\Phi} \boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Phi}^{T} \boldsymbol{\Sigma}^{(t)} \boldsymbol{\Phi}\right]\right) \\
&amp;+\frac{M}{2} \ln \alpha-\frac{\alpha}{2}\left(\left\|\boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Sigma}^{(t)}\right]\right)+\mathrm{const}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\boldsymbol{\mu}^{(t)}$ and $\boldsymbol{\Sigma}^{(t)}$ are computed using the current estimates of the parameters $\alpha^{(t)}$ and $\beta^{(t)}$ :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\boldsymbol{\mu}^{(t)} &amp;=\beta^{(t)} \boldsymbol{\Sigma}^{(t)} \boldsymbol{\Phi}^{T} \mathbf{t} \\
\boldsymbol{\Sigma}^{(t)} &amp;=\left(\beta^{(t)} \mathbf{\Phi}^{T} \boldsymbol{\Phi}+\alpha^{(t)} \mathbf{I}\right)^{-1}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;M-step&lt;/strong&gt; Maximize $Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)$ with respect to $\alpha, \beta$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left(\alpha^{(t+1)}, \beta^{(t+1)}\right)=\underset{(\alpha, \beta)}{\arg \max } Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)&lt;/script&gt;

&lt;p&gt;結果很簡單&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\alpha^{(t+1)} &amp;=\frac{M}{\left\|\boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Sigma}^{(t)}\right]} \label{eqa}\\
\beta^{(t+1)} &amp;=\frac{N}{\left\|\mathbf{t}-\boldsymbol{\Phi} \boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Phi}^{T} \mathbf{\Sigma}^{(t)} \boldsymbol{\Phi}\right]} \label{eqb}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$\eqref{eqa}$ 和 $\eqref{eqb}$ 同時保證 $\alpha, \beta$ 永遠為正值。&lt;/p&gt;

&lt;p&gt;幾個重點：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;EM algorithm 有可能收斂到 local minimum; initial condition 很重要&lt;/li&gt;
  &lt;li&gt;注意 $\mathbf{w}$ 不是一個值，而是 distribution.  Inference of $\mathbf{w}$ 就是 posterior distribution $\eqref{eqPost}$.  Posterior distribution 的 mean $\eqref{eqMean}$ 稱為 Bayesian linear minimum mean squire error (LMMSE) inference for $\mathbf{w}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;method-3-variational-em-based-bayesian-linear-regression&quot;&gt;Method 3, Variational EM-based Bayesian Linear Regression&lt;/h4&gt;

&lt;p&gt;因為非常複雜，可以直接參考 [@tzikasVariationalApproximation2008].&lt;/p&gt;

&lt;h5 id=&quot;例-1bnoisy-signal-estimationfiltering&quot;&gt;例 1B：Noisy Signal Estimation/Filtering&lt;/h5&gt;

&lt;p&gt;如下圖，Original signal 是虛線。實際的 observations ‘x’ 是 N = 50 samples 包含 signal + Gaussian noise ($\sigma^2 = 4 \times 10^{-2}$), 大約 SNR = 6.6dB.&lt;/p&gt;

&lt;p&gt;這裡的 basis functions 使用 Gaussian kernels&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi_{i}(\mathbf{x})=K\left(\mathbf{x}, \mathbf{x}_{i}\right)=\exp \left(-\frac{1}{2 \sigma_{\phi}^{2}}\left\|\mathbf{x}-\mathbf{x}_{i}\right\|^{2}\right)&lt;/script&gt;

&lt;p&gt;接下來用上述三個方法 (1) ML estimation; (2) EM-based Bayesian inference, and (3) variational EM-based Bayesian inference.&lt;/p&gt;

&lt;p&gt;(1) ML 基本上完全 follow noisy input, 所以最糟。這也符合期待，因為沒有任何 constraint on the weight. 所以所有的 weights 和 Gaussian kernel 都用來 fit noisy observations.  也就是說 N=50 samples/observations 對應 50 個 Gaussian kernel functions.  這可以從下圖的綠線看出。&lt;/p&gt;

&lt;p&gt;(2) Weights are constrained by prior, 此處 prior 假設 zero-mean Gaussian, which regularise the weight to be minimum; otherwise it will incur penalty.&lt;/p&gt;

&lt;p&gt;(3) 我們可以通過 $a, b$ 選取控制 non-zero weights, 類似 supporting vectors in SVM.  我們稱為 relevance vectors (RV). 此例只有 5 個  non-zero RV.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16287874512211.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16287874512211.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;例二-bayesian-gmm&quot;&gt;例二： Bayesian GMM&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{x})=\sum_{j=1}^{M} \pi_{j} N\left(x ; \boldsymbol{\mu}_{j}, \mathbf{T}_{j}\right)&lt;/script&gt;

&lt;p&gt;where $\boldsymbol{\pi} = { \pi_j }$ 代表 weights or mixing coefficients.  $\boldsymbol{\mu} = { \boldsymbol{\mu}&lt;em&gt;{j} }$ 是 means of Gaussian distribution.  $\mathbf{T} = { \mathbf{T}&lt;/em&gt;{j} }$ 是 precision (inverse covariance) matrices.  在 Bayesian GMM 我們更常用 precision matrix.&lt;/p&gt;

&lt;p&gt;Bayesian GMM 和一般 GMM 有什麼不同？ 最大的差別就是 $\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T}$ 不再是 parameters for estimation, 而是 random variables. 這有什麼好處？我們可以 impose or embedded our priors on $\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T}$, 通常是 conjugate priors (i.e. no informative priors) &lt;sup id=&quot;fnref:prior&quot;&gt;&lt;a href=&quot;#fn:prior&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Bayesian GMM 的 graph model 如下。Hidden random variables 包含 $h = (\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T})$. Bayesian 的目標是找出 $p(h\mid x)$, 顯然不會有 analytic solution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285137362672.jpg&quot; alt=&quot;-w237&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285137362672.jpg&quot; width=&quot;237&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此我們 divide-and-conquer 利用 $\eqref{eqVarJ2}$
假設 mean-field approximation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
q(\mathrm{h}) &amp;= q_{Z}(\mathbf{Z}) q_{\pi}(\boldsymbol{\pi}) q_{\mu T}(\boldsymbol{\mu}, \mathbf{T}) \\
q_{Z}(\mathbf{Z}) &amp;=\prod_{n=1}^{N} \prod_{j=1}^{M} r_{j n}^{z_{j n}} \\
q_{\pi}(\boldsymbol{\pi}) &amp;=\operatorname{Dir}\left(\boldsymbol{\pi} \mid\left\{\lambda_{j}\right\}\right) \\
q_{\mu T}(\boldsymbol{\mu}, \mathbf{T}) &amp;=\prod_{j=1}^{M} q_{\mu}\left(\boldsymbol{\mu}_{j} \mid \mathbf{T}_{j}\right) q_{T}\left(\mathbf{T}_{j}\right) \\
q_{\mu}\left(\boldsymbol{\mu}_{j} \mid \mathbf{T}\right) &amp;=\prod_{j=1}^{M} N\left(\boldsymbol{\mu}_{j} ; \mathbf{m}_{j}, \beta_{j} \mathbf{T}_{j}\right) \\
q_{T}(\mathbf{T}) &amp;=\prod_{j=1}^{M} W\left(\mathbf{T}_{j} ; \eta_{j}, \mathrm{U}_{j}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;看起來還是很複雜，不過 [@tzikasVariationalApproximation2008] 的 reference [27] 有詳細的公式。可以用“簡單” iterative update procedure 得到 optimal approximation $q(h)$ to the true posterior $p(h\mid x)$, 這就是 variational E-step.  下一步就是 variation M-step, 不贅述。&lt;/p&gt;

&lt;p&gt;Bayesian-GMM 比起 EM-GMM 到底有什麼好處。前面提到可以 impose priors. 如果沒有 prior information (i.e. use conjugate prior), 還有好處嗎？[@tzikasVariationalApproximation2008] 的說法是 Bayesian-GMM 不會有 singular solution, i.e. single data point Gaussian.  然而在 EM-GMM 常常會發生，如下圖 20 Gaussian components。一般 EM-GMM 解決的方法就是多跑幾次 randomize initial conditions to avoid it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285679550223.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另一個好處是可以直接用 Bayesian GMM 決定 Gaussian component number, 而不需要用其他方法 (e.g. cross-validation)。實作如下圖。(a) 初始是 20 component Gaussians; (b), (c) model evolution; (d) 最終解只剩下 5 個 Gaussian components, 其餘 15 個 Gaussian components weight 為 0。注意收斂的過程中都沒有 singularity.&lt;/p&gt;

&lt;p&gt;這聽起來比較 significant, 不過有一個 catch, 就是 Dirichlet prior 不允許 component mixing weight 為 0.  因此如果要用 Bayesian-GMM 決定 Gaussian component number, 必須 remove $\boldsymbol{\pi} = { \pi_j }$ from priors.  也就是把 $\boldsymbol{\pi} = { \pi_j }$ 視為 parameter to be estimated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285916007272.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bayesian GMM 的 graph model 如下。注意此時的 $\pi$ 變成方框，代表 parameter to be estimated.  Hidden random variables 包含 $h = (\mathbf{Z}, \boldsymbol{\mu}, \mathbf{T})$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286002562443.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286002562443.jpg&quot; width=&quot;237&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根據新的 DAG, 我們可以分解如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;q(\mathrm{h})=q_{Z}(\mathbf{Z}) q_{\mu}(\boldsymbol{\mu}) q_{T}(\mathrm{T})\\
&amp;q_{Z}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{j=1}^{M} r_{j n}^{z_{j n}} \\
&amp;q_{\mu}(\boldsymbol{\mu})=\prod_{j=1}^{M} N\left(\boldsymbol{\mu}_{j} \mid \mathrm{m}_{j}, \mathbf{S}_{j}\right) \\
&amp;q_{T}(\mathbf{T})=\prod_{j=1}^{M} W\left(\mathbf{T}_{j} \mid \eta_{j}, \mathbf{U}_{j}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;同樣經過一番計算 variational E-step and M-step (此處省略)，可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi_{j}=\frac{\sum_{n=1}^{N} r_{j n}}{\sum_{k=1}^{M} \sum_{n=1}^{N} r_{k n}}&lt;/script&gt;

&lt;p&gt;在 iteration 過程中，有一些 mixing coefficients ${\pi_j}$ 收斂到 0. 定性來說，variational bound 可以視為兩項之和：第一項是 likelihood function, 第二項是 prior 造成的 penalty term to penalizes complex models.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:prior&quot;&gt;
      &lt;p&gt;Dirichlet for $\boldsymbol{\pi}$.  Gauss-Wishart for ($\boldsymbol{\mu}, \mathbf{T})$ &lt;a href=&quot;#fnref:prior&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><category term="EM" /><category term="Bayesian" /><category term="Variational" /><summary type="html"></summary></entry><entry><title type="html">English</title><link href="http://localhost:4000/2021/08/03/English/" rel="alternate" type="text/html" title="English" /><published>2021-08-03T00:00:00+08:00</published><updated>2021-08-03T00:00:00+08:00</updated><id>http://localhost:4000/2021/08/03/English</id><content type="html" xml:base="http://localhost:4000/2021/08/03/English/">&lt;h1 id=&quot;語音語調和節奏&quot;&gt;語音語調和節奏&lt;/h1&gt;

&lt;p&gt;語音：pronunciation (word)
語調：intonation (sentence)
節奏：rhymes: biggest problem!!! for Chinese&lt;/p&gt;

&lt;p&gt;Isochrone:  Chinese word is unit time!! syllable-timed
stress-timed language: english
mora-timed language: japanese&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=VMDhdaMkeBU&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><summary type="html">語音語調和節奏</summary></entry><entry><title type="html">Math AI - Maximum Likelihood Estimation Evolve To EM Algorithm For Incomplete/Hidden Data To Variational Bayesian Inference</title><link href="http://localhost:4000/ai/2021/06/30/MLE_to_EM/" rel="alternate" type="text/html" title="Math AI - Maximum Likelihood Estimation Evolve To EM Algorithm For Incomplete/Hidden Data To Variational Bayesian Inference" /><published>2021-06-30T16:29:08+08:00</published><updated>2021-06-30T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/06/30/MLE_to_EM</id><content type="html" xml:base="http://localhost:4000/ai/2021/06/30/MLE_to_EM/">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&lt;/script&gt;

&lt;h2 id=&quot;major-reference&quot;&gt;Major Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;[@poczosCllusteringEM2015]&lt;/li&gt;
  &lt;li&gt;[@matasExpectationMaximization2018] good reference&lt;/li&gt;
  &lt;li&gt;[@choyExpectationMaximization2017]&lt;/li&gt;
  &lt;li&gt;[@tzikasVariationalApproximation2008] excellent introductory paper&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation-mle-和應用&quot;&gt;Maximum Likelihood Estimation (MLE) 和應用&lt;/h2&gt;
&lt;p&gt;Maximum likelihood estimation (MLE) 最大概似估計是一種估計模型參數的方法。適用時機在於手邊有模型，但是模型參數有無限多種，透過真實觀察到的樣本資訊，想辦法導出最有可能產生這些樣本結果的模型參數，也就是挑選使其概似性(Likelihood)最高的一組模型參數，這系列找參數的過程稱為最大概似估計法。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bernoulli distribution&lt;/em&gt;：投擲硬幣正面的機率 $\theta$, 反面的機率 $1-\theta$. 連續投擲的正面/反面的次數分別是 H/T.  Likelihood function 為&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\theta, H, T)=\theta^{H}(1-\theta)^{T}&lt;/script&gt;

&lt;p&gt;MLE 在無限個 $\theta$ 中，找到一個使概似性最大的 $\theta$, i.e. $\widehat{\theta}_{\mathrm{MLE}} =\arg \max _{\theta} {\theta^{H}(1-\theta)^{T}}$&lt;/p&gt;

&lt;p&gt;只要 likelihood function 一次微分，可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\theta}_{M L E}=\frac{H}{T+H}&lt;/script&gt;

&lt;p&gt;就是平均值，推導出來的模型參數符合直覺。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Normal distribution&lt;/em&gt;： 假設 mean unknown, variance known, 我們可以用 maximum log-likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underset{\mu}{\operatorname{argmax}} f\left(x_{1}, \ldots, x_{n}\right) \Rightarrow \underset{\mu}{\operatorname{argmax}} \log f\left(x_{1}, \ldots, x_{n}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;\frac{\mathrm{d}}{d \mu}\left(\sum_{i=1}^{n}-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}\right)=\sum_{\mathrm{i}=1}^{\mathrm{n}} \frac{\left(x_{i}-\hat{\mu}\right)}{\sigma^{2}}=\sum_{i=1}^{n} x_{i}-n \hat{\mathrm{u}}=0 \\
&amp;\hat{\mu}=\overline{\mathrm{X}}=\frac{\sum_{i=1}^{n} x_{i}}{n}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;微分的結果告訴我們，樣本的平均值，其實就是母體平均值 $\mu$ 最好的估計！又是一個相當符合直覺的答案，似乎 MLE 只是用來驗證直覺的工具。&lt;/p&gt;

&lt;p&gt;這是一個錯覺，常見的 distribution (e.g. Bernoulli, normal distribution) 都是 exponential families.  可以證明 maximum log-likelihood functions of exponential families 都是 concave function, 沒有 local minimum. 非常容易用數值方法找到最佳解，而且大多有 analytical solution.&lt;/p&gt;

&lt;p&gt;但只要 distribution function 更複雜一點，例如兩個 normal/Gaussian distribution weighted sum to 1, MLE 就非常難解。稱為 Gaussian mixture model (GMM) with 2 groups, GMM(2).&lt;/p&gt;

&lt;p&gt;另一種情況：MLE 雖然直接明瞭，但現實常常會遇到 missing data 或是 hidden data/state (state 也視為 data). 此時就需要 Expectation Maximization (EM) algorithm.&lt;/p&gt;

&lt;p&gt;例如 GMM(2) 可以視為有一個 hidden state $z$ with binary value, $p(x) = p(x\mid z=0) p(z=0) + p(x\mid z=1) p(z=1)$. $p(x\mid z=0)$ 和 $p(x\mid z=1)$ 分別是不同 normal distributions.&lt;/p&gt;

&lt;p&gt;以下先 Q&amp;amp;A maximum likelihood estimation (MLE) vs. expectation maximization (EM) 兩種算法。其實是視 EM 為 MLE 的推廣。 接著用四個簡單例子 (toy example) 說明 MLE 如何推廣到 EM.&lt;/p&gt;

&lt;h2 id=&quot;qa-of-mle-versus-em&quot;&gt;Q&amp;amp;A of MLE Versus EM&lt;/h2&gt;

&lt;p&gt;Q: Why EM is a special case of MLE?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the problem can be formulated as MLE parameter estimation of incomplete/hidden data.  Then EM algorithm 的 E-step is guessing incomplete/hidden data; M-step 就對應 MLE parameter estimation with modification (見本文後段)。&lt;/li&gt;
  &lt;li&gt;EM M-Step is essentially a MLE parameter estimation with modification.&lt;/li&gt;
  &lt;li&gt;EM can be seen as an iterative MLE.  EM may converge at local minimum during iteration.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Q: How EM can be used for to parameter estimation and incomplete/hidden data estimation?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For Bayesian, 兩者可以視為同一類。Unknown parameters 亦可以視為 missing data with distribution.  此時 EM algorithm 相當于 2D &lt;strong&gt;coordinate descent&lt;/strong&gt; (energy) optimization [@wikiCoordinateDescent2021], different from &lt;strong&gt;gradient descent&lt;/strong&gt;.  EM 的 E-step 對應 (conditional) distribution coordinate descent; M-step 對應 parameter coordinate descent.&lt;/li&gt;
  &lt;li&gt;For Frequentist (古典統計), E-step is guessing incomplete/hidden data; M-step 就對應 MLE parameter estimation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;toy-example-matasexpectationmaximization2018&quot;&gt;Toy Example [@matasExpectationMaximization2018]&lt;/h2&gt;

&lt;h3 id=&quot;前提摘要&quot;&gt;前提摘要&lt;/h3&gt;
&lt;p&gt;一個簡單例子觀察 temperature and amount of snow (溫度和雪量, both are binary input) 的 joint probability depending on two “scalar factors” $a$ and $b$ as $p(t, s | a, b)$&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$a$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$5a$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$3b$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$b$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;注意 $a$ and $b$ are parameters, 不是 conditional probability.
另外因為機率和為 1 做為一個 constraint: $6a + 4b = 1$&lt;/p&gt;

&lt;h3 id=&quot;例一-mle&quot;&gt;例一: MLE&lt;/h3&gt;
&lt;p&gt;一個 ski-center 觀察 $N$ 天的溫度和雪量得到以下的統計，$N_{ij} \in \mathbf{I}$, 如何估計 $a$ and $b$?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{00}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{01}$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{10}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{11}$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Likelihood function (就是 joint pdf of $N$ repeat experiments)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathcal{T} \mid a, b)= C a^{N_{00}}(5 a)^{N_{01}}(3 b)^{N_{10}}(b)^{N_{11}}&lt;/script&gt;

&lt;p&gt;where $C = (\Sigma N_{ij})! / \Pi (N_{ij}!)$ 是 MLE 無關的常數&lt;/p&gt;

&lt;p&gt;問題改成 maximum log-likelihood with constraint and $C’ = \ln C$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(a, b, \lambda) = C' + N_{00} \ln a+N_{01} \ln 5 a+N_{10} \ln 3 b+N_{11} \ln b+\lambda(6 a+4 b-1)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{gathered}
\frac{\partial L}{\partial a}=N_{00} \frac{1}{a}+N_{01} \frac{1}{a}+6 \lambda=0 \\
\frac{\partial L}{\partial b}=N_{10} \frac{1}{b}+N_{11} \frac{1}{b}+4 \lambda=0 \\
\frac{\partial L}{\partial \lambda}=6 a+4 b - 1 = 0
\end{gathered}&lt;/script&gt;

&lt;p&gt;上述方程式的解為
&lt;script type=&quot;math/tex&quot;&gt;a=\frac{N_{00}+N_{01}}{6 N} \quad b=\frac{N_{10}+N_{11}}{4 N} \quad \lambda = -(N_{00}+N_{01}+N_{10}+N_{11})=-N&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;結果很直觀。其實就是利用大數法則： $a\cdot N \sim N_{00}; 5a\cdot N\sim N_{01}; 3b\cdot N\sim N_{10}; b\cdot N\sim N_{11}$
再來大數法則 (a+5a)N~N00+N01; (3b+b)N~N10+N11 =&amp;gt; a = .. ; b = …&lt;/p&gt;

&lt;h3 id=&quot;例二-incompletehidden-data&quot;&gt;例二 incomplete/hidden Data&lt;/h3&gt;
&lt;p&gt;假設我們無法觀察到完整的”溫度和雪量“；而是“溫度或雪量”，有時“溫度”，有時“雪量”，但不是同時。對應的不是 joint pdf, 而是 marginal pdf 如下：
&lt;img src=&quot;/media/16247543929429/16265417789274.jpg&quot; alt=&quot;-w451&quot; /&gt;&lt;/p&gt;

&lt;p&gt;觀察如下：
&lt;img src=&quot;/media/16247543929429/16265418866309.jpg&quot; alt=&quot;-w274&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Lagrangian (log-likelihood with constraint)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(a, b, \lambda)=T_{0} \ln 6 a+T_{1} \ln 4 b+S_{0} \ln (a+3 b)+S_{1} \ln (5 a+b)+\lambda(6 a+4 b-1)&lt;/script&gt;

&lt;p&gt;此時的方程式比起之前複雜的多，不一定有 close-form solution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{gathered}
\frac{\partial L}{\partial a}=\frac{T_{0}}{a}+\frac{S_{0}}{a+3 b}+\frac{5 S_{1}}{5 a+b}+6 \lambda=0 \\
\frac{\partial L}{\partial b}=\frac{T_{1}}{b}+\frac{3 S_{0}}{a+3 b}+\frac{S_{1}}{5 a+b}+4 \lambda=0 \\
6 a+4 b=1
\end{gathered}&lt;/script&gt;

&lt;p&gt;如果用大數法則：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$6a \cdot(T_0+T_1) \sim T0; \, 4b\cdot(T_0+T_1) \sim T_1$&lt;/li&gt;
  &lt;li&gt;$(a+3b) \cdot (S_0+S_1)\sim S_0; \, (5a+b)\cdot(S_0+S_1) \sim S_1$ 
注意不論 1. or 2. 都滿足 $6a+4b = 1$ constraint, 可以用來估計 $a$ and $b$.
問題是我們要用那一組 $(a, b)$?  單獨用一組都會損失一些 information, 應該要 combine 1 and 2 的 information, how?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;思路一&lt;/strong&gt; 平均 (a, b) from 1 and 2.  但這不是好的策略，因為平均 (a,b) 不一定滿足 constraint. 在這個 case 因為 linear constraint, 所以平均 (a,b) 仍然滿足 constraint.  但對於更複雜 constraint, 平均並非好的方法。&lt;/p&gt;

&lt;p&gt;更重要的是平均並無法代表 maximum likelihood in the above equation.  我們的目標是 maximum likelihood, 平均 (a, b) 完全無法保證會得到更好的 likelihood value!&lt;/p&gt;

&lt;p&gt;或者把 (a,b) from 1 or 2 代入上述 likelihood function 取大值。顯然這也不是最好的策略。因為一半的資訊被捨棄了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思路二&lt;/strong&gt; 比較好的方法是想辦法用迭代法解微分後的 Lagrange multiplier 聯立方程式。 (a, b) from 1. or 2. 只作為 initial solution, 想辦法從聯立方程式找出 iterative formula.  這似乎是對的方向，問題是 Lagrange multiplier optimization 是解聯立(level 1)微分方程式。不一定有 close form as in this example.  同時也無法保證收斂。另外如何找出 iterative formula 似乎是 case-by-case, 沒有一致的方式。
&lt;strong&gt;=&amp;gt; iterative solution is one of the key, but NOT on Lagrange multiplier (level 1)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思路三&lt;/strong&gt; 既然是 missing data, 我們是否可以假設 $(a, b) \to$  fill missing data $\to$ update $(a, b) \to$  update missing data $\cdots$ 具體做法 
$N_{00} = T_0 \cdot \frac{1}{6} + S_0 \cdot \frac{a}{a+3b}$
$N_{01} = T_0 \cdot \frac{5}{6} + S_1 \cdot \frac{5a}{5a+b}$
$N_{10} = T_1 \cdot \frac{3}{4} + S_0 \cdot \frac{3b}{a+3b}$
$N_{11} = T_1 \cdot \frac{1}{4} + S_1 \cdot \frac{b}{5a+b}$&lt;/p&gt;

&lt;p&gt;有了 $N_{00},N_{01},N_{10},N_{11}$ 可以重新估計 $(a, b)$ using joint pdf&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a'=\frac{N_{00}+N_{01}}{6 N} \quad b'=\frac{N_{10}+N_{11}}{4 N}&lt;/script&gt;

&lt;p&gt;Q: 如何證明這個方法是最佳或是對應 complete data MLE or incomplete/hidden data MLE? 甚至會收斂？&lt;/p&gt;

&lt;h4 id=&quot;em-algorithm-邏輯&quot;&gt;EM algorithm 邏輯&lt;/h4&gt;

&lt;h3 id=&quot;前提摘要-1&quot;&gt;前提摘要&lt;/h3&gt;
&lt;h3 id=&quot;gmm-特例estimate-means-of-two-gaussian-distributions-known-variance-and-ratio-unknown-means&quot;&gt;GMM 特例：Estimate Means of Two Gaussian Distributions (known variance and ratio; unknown means)&lt;/h3&gt;

&lt;p&gt;We measure lengths of vehicles. The observation space is two-dimensional, with $x$ capturing vehicle type (binary) and $y$ capturing length (Gaussian).&lt;/p&gt;

&lt;p&gt;$p(x, y)$  $x\in$ {car, truck},  $y \in \mathbb{R}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\text {car}, y)=\pi_{\mathrm{c}} \mathcal{N}\left(y \mid \mu_{\mathrm{c}}, \sigma_{\mathrm{c}}=1\right)=\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y-\mu_{\mathrm{c}}\right)^{2}\right\},\left(\kappa_{\mathrm{c}}=\frac{\pi_{\mathrm{c}}}{\sqrt{2 \pi}}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\text {truck,} y)=\pi_{\mathrm{t}} \mathcal{N}\left(y \mid \mu_{\mathrm{t}}, \sigma_{\mathrm{t}}=2\right)=\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y-\mu_{\mathrm{t}}\right)^{2}\right\},\left(\kappa_{\mathrm{t}}=\frac{\pi_{\mathrm{t}}}{\sqrt{8 \pi}}\right)&lt;/script&gt;

&lt;p&gt;where $\pi_c + \pi_t = 1$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16247543929429/16266210341198.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;例三-complete-data-easy-case&quot;&gt;例三 Complete Data (Easy case)&lt;/h3&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;T=\{\underbrace{\left(\operatorname{car}, y_{1}^{(c)}\right),\left(\operatorname{car}, y_{2}^{(c)}\right), \ldots,\left(\operatorname{car}, y_{C}^{(c)}\right)}_{C \text { car observations }}, \underbrace{\left(\text {truck}, y_{1}^{(\mathrm{t})}\right),\left(\text {truck}, y_{2}^{(\mathrm{t})}\right), \ldots,\left(\text {truck}, y_{T}^{(\mathrm{t})}\right)}_{T \text { truck observations }}\}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Log-likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(\mathcal{T})=\sum_{i=1}^{N} \ln p\left(x_{i}, y_{i} \mid \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)=C \ln \kappa_{\mathrm{c}}-\frac{1}{2} \sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{\mathrm{c}}\right)^{2}+T \ln \kappa_{\mathrm{t}}-\frac{1}{8} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)^{2}&lt;/script&gt;

&lt;p&gt;很容易用 MLE 估計 $\mu_1, \mu_2$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{c}}}=\sum_{i=1}^{C}\left(y_{i}^{(\mathrm{c})}-\mu_{\mathrm{c}}\right)=0 \quad \Rightarrow \quad \mu_{\mathrm{c}}=\frac{1}{C} \sum_{i=1}^{C} y_{i}^{(c)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{t}}}=\frac{1}{4} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)=0 \quad \Rightarrow \quad \mu_{\mathrm{t}}=\frac{1}{T} \sum_{i=1}^{T} y_{i}^{(\mathrm{t})}&lt;/script&gt;

&lt;p&gt;直觀上很容易理解。如果 observations 已經分組，求 mean 只要做 sample 的平均即可。&lt;/p&gt;

&lt;p&gt;以這個例子，ratio $\pi_c, \pi_t$ 不論已知或未知，都不影響結果。&lt;/p&gt;

&lt;h3 id=&quot;例四-incompletehidden-data&quot;&gt;例四 incomplete/hidden Data&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{T}=\{\left(\operatorname{car}, y_{1}^{(c)}\right), \ldots,\left(\operatorname{car}, y_{C}^{(c)}\right),\left(\text {truck}, y_{1}^{(\mathrm{t})}\right), \ldots,\left(\text {truck}, y_{T}^{(\mathrm{t})}\right), \underbrace{\left(\bullet, y_{1}^{\bullet}\right), \ldots,\left(\bullet, y_{M}^{\bullet}\right)}_{\begin{array}{l}
\text { data with uknown } \\
\text { vehicle type }
\end{array}}\}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p\left(y^{\bullet}\right)=p\left(\text {car}, y^{\bullet}\right)+p\left(\text {truck}, y^{\bullet}\right)&lt;/script&gt;

&lt;p&gt;Log-likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(\mathcal{T})=\sum_{i=1}^{N} \ln p\left(x_{i}, y_{i} \mid \mu_{c}, \mu_{\mathrm{t}}\right)=\overbrace{C \ln \kappa_{\mathrm{c}}-\frac{1}{2} \sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{\mathrm{c}}\right)^{2}+T \ln \kappa_{\mathrm{t}}-\frac{1}{8} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)^{2}}^{\text {same term as before }} \\
+\sum_{i=1}^{M} \ln \left(\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}+\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)^{2}\right\}\right)&lt;/script&gt;

&lt;p&gt;不用微分也知道非常難解 MLE. 我們必須用另外的方法，就是 EM 算法。
不過我們還是微分一下，得到更多的 insights.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
0=\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{c}}} &amp;=\sum_{i=1}^{C}\left(y_{\mathrm{c}}^{(\mathrm{c})}-\mu_{\mathrm{c}}\right) \\
&amp;+ \sum_{i=1}^{M} \overbrace{\frac{\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}}{\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}+\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)^{2}\right\}}}^{p\left(\operatorname{car} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0=4 \frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{t}}}=\sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)+\sum_{i=1}^{M} p\left(\text {truck} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)&lt;/script&gt;

&lt;p&gt;上兩式非常有物理意義。基本是 easy case 的延伸：已知分類的平均值，加上未知分類的機率平均值。一個簡單的方法是只取前面已知的部分平均，不過這不是最佳，因為丟失部分的資訊。&lt;/p&gt;

&lt;h4 id=&quot;missing-values-em-approach&quot;&gt;Missing Values, EM Approach&lt;/h4&gt;
&lt;p&gt;重新 summarize optimality conditions&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{c}\right)+\sum_{i=1}^{M} p\left(\operatorname{car} \mid y_{i}^{\bullet}, \mu_{c}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)=0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)+\sum_{i=1}^{M} p\left(\text {truck } \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)=0&lt;/script&gt;

&lt;p&gt;如果 $p(\text {truck} \mid y_{i}^{\bullet}, \mu_c, \mu_t)$ 和 $p(\text {car} \mid y_{i}^{\bullet}, \mu_c, \mu_t)$ 已知，上式非常容易解 $\mu_c$ and $\mu_t$。實際這是一個雞生蛋、蛋生雞的問題，因為這兩個機率又和 $\mu_c$ and $\mu_t$ 相關。&lt;/p&gt;

&lt;p&gt;EM algorithm 剛好用來打破這個迴圈。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Let $z_i \,(i=1, 2, \cdots, M), z_i \in \text{{car, truck}}$ denote the &lt;strong&gt;missing data&lt;/strong&gt;.  Define $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$&lt;/li&gt;
  &lt;li&gt;上述 optimality equations 可以得到&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{\mathrm{c}}=\frac{\sum_{i=1}^{C} y_{i}^{(\mathrm{c})}+\sum_{i=1}^{M} q\left(z_{i}=\mathrm{car}\right) y_{i}^{\bullet}}{C+\sum_{i=1}^{M} q\left(z_{i}=\mathrm{car}\right)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{\mathrm{t}}=\frac{\sum_{i=1}^{T} y_{i}^{(\mathrm{t})}+\sum_{i=1}^{M} q\left(z_{i}=\text { truck }\right) y_{i}^{\bullet}}{T+\sum_{i=1}^{M} q\left(z_{i}=\text { truck }\right)}&lt;/script&gt;

&lt;p&gt;EM Algorithm 可以用以下四步驟表示&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize $\mu_c$, $\mu_t$&lt;/li&gt;
  &lt;li&gt;Compute $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$ for $i = 1, 2, \cdots, M$&lt;/li&gt;
  &lt;li&gt;Recompute $\mu_c$, $\mu_t$ according to the above equations.&lt;/li&gt;
  &lt;li&gt;If termination condition is met, finish.  Otherwise, goto 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述步驟 2 稱為 Expectation (E) Step, 步驟 3 稱為 Maximization (M) Step.  統稱為 EM algorithm.&lt;/p&gt;

&lt;p&gt;Q. Why Step 2 稱為 Expectation? not clear.  Maximization 比較容易理解，因為 optimality condition 就是 maximization (微分為 0).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In summary&lt;/strong&gt;, EM algorithm 的一個關鍵點是：讓 incomplete/hidden data 變成 complete (Expectation?).  有了完整的 data, 就容易用 MLE 找到 maximal likelihood estimation ($\mu_c$ and $\mu_t$ in this case).&lt;/p&gt;

&lt;h2 id=&quot;clustering-soft-assignment-vs-hard-assignment-k-means&quot;&gt;Clustering: Soft Assignment Vs. Hard Assignment (K-means)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/media/16270144925547/16270374215686.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;em-algorithm-derivation&quot;&gt;EM Algorithm Derivation&lt;/h2&gt;

&lt;p&gt;EM algorithm 如果只是 heuristic algorithm, 可能有用度減半。這裡討論數學上的 justification.  先定義 terminologies&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbf{o}$: all observed values&lt;/li&gt;
  &lt;li&gt;$\mathbf{z}$: all unobserved values (i.e. hidden variable)&lt;/li&gt;
  &lt;li&gt;$\mathbf{\theta}$: model parameters to be estimated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目標：Find $\theta^*$ using the Maximum Likelihood approach&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ell(\boldsymbol{\theta})=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{o} \mid \boldsymbol{\theta})
\end{equation}\label{eqMLE}&lt;/script&gt;

&lt;p&gt;思路：假設解下列完整 data 很容易解 (例如例一和例三)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})
\end{equation}\label{eqMLE2}&lt;/script&gt;

&lt;p&gt;我們的想法是把 $\eqref{eqMLE}$ 先變形成上式 $\eqref{eqMLE2}$，再想辦法優化&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{equation}
\begin{aligned}
\ln p(\mathbf{o} \mid \boldsymbol{\theta}) &amp;=\ln \sum_{\mathbf{z}} p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}) \\
&amp;=\ln \sum_{\mathbf{z}} q(\mathbf{z}) \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}
\end{aligned}
\end{equation}\label{eqMLE3} %]]&gt;&lt;/script&gt;

&lt;p&gt;這裡引入看似任意 probability distribution $q(\mathbf{z})$ with $\sum_{\mathbf{z}} q(\mathbf{z})=1$. 後面會說明如何選 $q(\mathbf{z})$.&lt;/p&gt;

&lt;h3 id=&quot;log-likelihood-with-hidden-variable-lower-bound&quot;&gt;Log-Likelihood with Hidden Variable Lower Bound&lt;/h3&gt;

&lt;p&gt;上式 $\eqref{eqMLE3}$ 利用 Jensen’s inequality 可以導出
&lt;script type=&quot;math/tex&quot;&gt;\geq \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;我們定義 $\ln p(\mathbf{o} \mid \boldsymbol{\theta})$ 的 lower bound or ELBO (Evidence Lower BOund) 為 $\mathcal{L}(q, \boldsymbol{\theta})$, for any distribution $q$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\mathcal{L}(q, \boldsymbol{\theta})=\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}
\end{equation}\label{eqELBO}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;這已經非常接近思路！我們的思路修正成把有 hidden data 的 MLE 變成用完整 data 的 MLE 做為 lower bound.  再通過 $q(\mathbf{z})$ 提高 lower bound 逼近原來的目標。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Maximizing $\mathcal{L}(q, \boldsymbol{\theta})$ by choosing $q(z)$ 就可以 push the log likelihood $\ln p(\mathbf{o} \mid \boldsymbol{\theta})$ upwards.&lt;/p&gt;

&lt;p&gt;反過來我們可以計算和 lower bound 之間的 gap.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\mathcal{L}(q, \boldsymbol{\theta}) &amp;=\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})} \nonumber\\
&amp;=\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln \underbrace{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}_{p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) p(\mathbf{o} \mid \boldsymbol{\theta})}-\ln q(\mathbf{z})\} \nonumber\\
&amp;=\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})+\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\ln q(\mathbf{z})\} \nonumber\\
&amp;=\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\underbrace{\sum_{\mathbf{z}} q(\mathbf{z})}_{1} \ln p(\mathbf{o} \mid \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})-\ln q(\mathbf{z})\} \nonumber\\
&amp;=-\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})}{q(\mathbf{z})} \label{eqGAP} \\
&amp;= D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \ge 0 \label{eqKL}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;這個 gap $\eqref{eqKL}$ 就是 KL divergence between $q(\mathbf{z})$ and $p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$, 永遠大於 0. 這和 Jensen Inequality 的結論一致！&lt;/p&gt;

&lt;p&gt;以下是關鍵：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果能找到 $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$ 的 analytical solution，就可以讓 gap 變成 0.  Lower bound $\eqref{eqELBO}$ 就是我們要 maximize 目標，voila!
    &lt;ul&gt;
      &lt;li&gt;例如例四 GMM 的 $p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$ 就是 softmax function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;即使 $q(\mathbf{z})$ 有 analytical solution, e.g. softmax, 不代表容易解 maximum 以及對應的 parameter.  EM algorithm 就是用來處理這個問題，見下文。&lt;/li&gt;
  &lt;li&gt;假如 $q(\mathbf{z})$ 本身就非常複雜，還有另一個方法：variational approximation; 稱為 Bayesian inference. 本文不討論。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;em-algorithm-push-the-lower-bound-upwards&quot;&gt;EM Algorithm Push the Lower Bound Upwards&lt;/h3&gt;
&lt;p&gt;Log likelihood function 可以分為兩個部分： lower bound + gap&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\ln p(\mathbf{o} \mid \boldsymbol{\theta})=\mathcal{L}(q, \boldsymbol{\theta})+D_{\mathrm{KL}}(q \| p)
\end{equation}\label{eqSUM}&lt;/script&gt;

&lt;p&gt;從 Jensen’s inequality 得到 $\mathcal{L}(q, \boldsymbol{\theta})$ 是 lower bound.  同樣從 KL divergence $\ge$ 0 再度驗證。&lt;/p&gt;

&lt;p&gt;如果 $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$, the bound is tight.&lt;/p&gt;

&lt;p&gt;接下來看兩個極端的 examples.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Trivial Case:&lt;/strong&gt;&lt;/em&gt;  Hidden variable $\mathbf{z}$ does NOT provide any information of $\mathbf{o}$&lt;/p&gt;

&lt;p&gt;如果 $\mathbf{o}$ 和 $\mathbf{z}$ 完全無關，$p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) = p(\mathbf{z} \mid \boldsymbol{\theta})$.  We can make $q(\mathbf{z}) = p(\mathbf{z} \mid \boldsymbol{\theta})$
such that $D_{\mathrm{KL}}(q(\mathbf{z}) | p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})) = 0$, 也就是 gap = 0.&lt;/p&gt;

&lt;p&gt;Lower bound 就變成原來的 log-likelihood function, trivial case.
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(q, \boldsymbol{\theta}) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}\\ 
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o} \mid \boldsymbol{\theta}) p(\mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})} \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{o} \mid \boldsymbol{\theta})\\
&amp;= \ln p(\mathbf{o} \mid \boldsymbol{\theta})
\end{aligned} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Case 2:&lt;/strong&gt;&lt;/em&gt; 如果  $p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$ 有 analytical solution, let $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta})$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(q, \boldsymbol{\theta}) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}\\ 
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) p(\mathbf{o} \mid \boldsymbol{\theta})}{q(\mathbf{z})} \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{o} \mid \boldsymbol{\theta})\\
&amp;= \ln p(\mathbf{o} \mid \boldsymbol{\theta})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;其實這就是 EM algorithm 的精髓&lt;/p&gt;

&lt;h2 id=&quot;em-具體步驟&quot;&gt;EM 具體步驟&lt;/h2&gt;

&lt;p&gt;Recap EM algorithm:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gap 可以視為從 observables 推論出 unobservables, i.e. incomplete/hidden data, &lt;strong&gt;對應 EM algorithm 的 E-Step.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Lower bound 其實可以視為 MLE of complete data， &lt;strong&gt;對應 EM algorithm 的 M-Step.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recap lower bound $\eqref{eqELBO}$ 包含兩個部分：(i) $q(\mathbf{z})$ distribution and (ii) log-likelihood of complete data, $\ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})$.&lt;/p&gt;

&lt;p&gt;這兩個部分剛好對應 EM algorithm 的 E-step (i) and M-step (ii).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Initialize $\boldsymbol{\theta}=\boldsymbol{\theta}^{(0)}$&lt;/li&gt;
  &lt;li&gt;E-step (Expectation):&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q^{(t+1)}=\underset{q}{\operatorname{argmax}} \mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right)
\end{equation}\label{eqEstep}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;M-step (Maximization):&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \mathcal{L}\left(q^{(t+1)}, \boldsymbol{\theta}\right)
\end{equation}\label{eqMstep}&lt;/script&gt;

&lt;h3 id=&quot;m-step-qt1-is-fixed&quot;&gt;M-step: $q^{(t+1)}$ is fixed&lt;/h3&gt;
&lt;p&gt;我們先看 M-step $\eqref{eqMstep}$, 因為這和 MLE estimate $\theta$ 非常相似。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}\left(q^{(t+1)}, \boldsymbol{\theta}\right) &amp;=\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q^{(t+1)}(\mathbf{z})} \\
&amp;=\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})-\underbrace{\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln q^{(t+1)}(\mathbf{z})}_{\text {const. }}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}^{(t)})
\end{equation}\label{eqMstep2}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;注意 M-Step 和完整 data 的 MLE 思路如下非常接近，只加了對 $q(\mathbf{z})$ 的 weighted sum.&lt;/strong&gt;
&lt;script type=&quot;math/tex&quot;&gt;\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;上式微分等於 0 就可以解 $\theta^{t+1}$。上面例四以及例二就是很好的例子。&lt;/p&gt;

&lt;p&gt;另一個常見的寫法&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} E_{q(z)} \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}^{(t)})
\end{equation}\label{eqMstep3}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;注意 M-Step 是 maximize lower bound, 並不等於 maximize 不完整 data 的 MLE，因為還差了一個 gap function (i.e. KL divergence).  E-Step 的目標才是縮小 gap function, which is also $\boldsymbol{\theta}$ dependent.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;e-step-boldsymbolthetat-is-fixed&quot;&gt;E-step: $\boldsymbol{\theta}^{(t)}$ is fixed&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^{(t+1)}=\underset{q}{\operatorname{argmax}} \mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right)=\underbrace{\ln p\left(\mathbf{o} \mid \boldsymbol{\theta}^{(t)}\right)}_{\text {const. }}-D_{\mathrm{KL}}(q \| p)&lt;/script&gt;

&lt;p&gt;以上 KL divergence 大於等於 0，所以 maximize lower bound 就要讓 要選擇 $q(z)$ 儘量縮小 gap  (i.e. KL divergence) 到 0.  Gap 等於 0 的條件就是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q^{(t+1)}(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}^{(t)})
\end{equation}\label{eqEstep2}&lt;/script&gt;

&lt;p&gt;同樣 E-Step 深具物理意義，就是猜 incomplete/hidden data distribution based on 已知的 observables 和 iterative $\theta$.&lt;/p&gt;

&lt;p&gt;例如例四 E-Step 就是計算 $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$ for $i = 1, 2, \cdots, M$.  結果是 softmax function.&lt;/p&gt;

&lt;h4 id=&quot;conditional-vs-joint-distribution&quot;&gt;Conditional Vs. Joint Distribution&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;我們可以把 conditional distribution 改成 joint distribution 如下。兩者都可以用來解 E-Step.&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}^{(t)}) = p(\mathbf{z}, \mathbf{o} \mid \boldsymbol{\theta}^{(t)}) / p(\mathbf{o} \mid \boldsymbol{\theta}^{(t)})&lt;/script&gt;

&lt;h3 id=&quot;em-精髓-結合-e-step-and-m-step&quot;&gt;EM 精髓: 結合 E-Step and M-Step&lt;/h3&gt;

&lt;p&gt;如果 E-Step $\eqref{eqEstep2}$ 有 analytic solution, 可以代入 M-Step $\eqref{eqMstep2}$ 得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\theta^{t+1} | \theta^{t}) &amp;=  \sum_{\mathbf{z}} p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}^{(t)}) \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}^{t+1}) \\
&amp;= \int d \mathbf{z} \, p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}^{(t)}) \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}^{t+1})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;New EM algorithm with fixed $\boldsymbol{\theta}^{t}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} Q(\boldsymbol{\theta}^{t+1} | \boldsymbol{\theta}^{t})
\end{equation}\label{eqQ}&lt;/script&gt;

&lt;h2 id=&quot;free-energy-interpretation-poczoscllusteringem2015&quot;&gt;Free Energy Interpretation [@poczosCllusteringEM2015]&lt;/h2&gt;
&lt;p&gt;搞 machine learning 很多是物理學家 (e.g. Max Welling), 習慣用物理觀念套用於 machine learning.  常見的例子是 training 的 &lt;em&gt;momentum&lt;/em&gt; method.  另一個是 &lt;em&gt;energy/entropy&lt;/em&gt; loss function.  此處我們看的是類似 energy loss function.&lt;/p&gt;

&lt;p&gt;我們從 gap 開始&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln p(\mathbf{o} \mid \boldsymbol{\theta})-\mathcal{L}(q, \boldsymbol{\theta}) = D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \ge 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\ln p(\mathbf{o} \mid \boldsymbol{\theta}) &amp;= \mathcal{L}(q, \boldsymbol{\theta}) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})} + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}) + \sum_{\mathbf{z}} -q(\mathbf{z}) \ln {q(\mathbf{z})}+ D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \\
&amp;= E_{q(z)} \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}) + H(q) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}) ) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where H(q) is the entropy of q,  第一項是負的，第二項和第三項是正的。
我們用一個例子來驗證
q = {0 or 1} with 50% chance, =&amp;gt; 
H(q) = 1 (bit) or ln (?) &amp;gt; 0
Eq(z) ln p(o, z) = -(0.5 (o-u1)^2 + 0.5 (o-u2)^2 ) / sqrt(2pi) &amp;lt; 0&lt;/p&gt;

&lt;p&gt;此處我們 switch to [@poczosCllusteringEM2015] notation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Observed data: $D = {x_1, \cdots, x_n}$&lt;/li&gt;
  &lt;li&gt;Unobserved/hidden variable: $z = {z_1, \cdots, z_n}$&lt;/li&gt;
  &lt;li&gt;Parameter: $\theta = [\mu_1, \cdots, \mu_K, \pi_1, \cdots, \pi_K, \Sigma_1, \cdots, \Sigma_K]$&lt;/li&gt;
  &lt;li&gt;Goal: $\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(D \mid \theta)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;重寫上式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\ln p(D \mid \boldsymbol{\theta}^t) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(D, \mathbf{z} \mid \boldsymbol{\theta}^t) + \sum_{\mathbf{z}} -q(\mathbf{z}) \ln {q(\mathbf{z})}+ D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D, \boldsymbol{\theta}^t) ) \\
&amp;= E_{q(z)} \ln p(D, \mathbf{z} \mid \boldsymbol{\theta}) + H(q) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D, \boldsymbol{\theta}) ) \\
&amp;= F_{\theta^t} (q(\cdot), D) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D, \boldsymbol{\theta}) )
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;$F_{\theta^t} (q(\cdot), D)$ 稱為 free energy, 包含 joint distribution expectation 和 self-entropy.  或是稱為 ELBO (Evidence lower bound)&lt;/p&gt;

&lt;p&gt;如果 $p(z\mid x; \theta)$ is analytically available (e.g. GMM, this is just a softmax!).  The ELBO becomes a Q(theta, theta^old) function + H(q)&lt;/p&gt;

&lt;p&gt;The EM algorithm can be summzied as argmax Q!!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;E-step: $p(z\mid x)$&lt;/li&gt;
  &lt;li&gt;M-step; argmax …&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can prove&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;log likelihood is always increasing!&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;img src=&quot;/media/16270144925547/16274030539044.jpg&quot; alt=&quot;-w400&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/media/16270144925547/16274031504070.jpg&quot; alt=&quot;-w408&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Use multiple, randomized initialization in practice.&lt;/p&gt;

&lt;h2 id=&quot;variational-expectation-maximization&quot;&gt;Variational Expectation Maximization&lt;/h2&gt;
&lt;p&gt;EM algorithm 一個問題是對於複雜的問題沒有 close from p(z|x), then toast!&lt;/p&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h4 id=&quot;例二的-conditional-vs-joint-distribution-解法&quot;&gt;例二的 Conditional Vs. Joint Distribution 解法&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;我們之前的 E-Step 是猜 joint distribution, $p(t, s | a, b)$.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3b&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;b&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如果用上述的 conditional distribution 可以細膩的看每一個 data.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(\bullet, s_0)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(t \mid s_0, a, b)=\left\{\begin{array}{l}
q\left(t_{0}\right)=p\left(t_{0} \mid s_{0}, a, b\right)=\frac{a}{a+3 b} \\
q\left(t_{1}\right)=p\left(t_{1} \mid s_{0}, a, b\right)=\frac{3 b}{a+3 b}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(\bullet, s_1)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(t \mid s_1, a, b)=\left\{\begin{array}{l}
q\left(t_{0}\right)=p\left(t_{0} \mid s_{1}, a, b\right)=\frac{5a}{5 a+ b} \\
q\left(t_{1}\right)=p\left(t_{1} \mid s_{1}, a, b\right)=\frac{b}{5 a+ b}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(t_0, \bullet)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(s \mid t_0, a, b)=\left\{\begin{array}{l}
q\left(s_{0}\right)=p\left(s_{0} \mid t_{0}, a, b\right)=\frac{1}{6} \\
q\left(s_{1}\right)=p\left(s_{1} \mid t_{0}, a, b\right)=\frac{5}{6}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(t_1, \bullet)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(s \mid t_1, a, b)=\left\{\begin{array}{l}
q\left(s_{0}\right)=p\left(s_{0} \mid t_{1}, a, b\right)=\frac{3}{4} \\
q\left(s_{1}\right)=p\left(s_{1} \mid t_{1}, a, b\right)=\frac{1}{4}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;再來是例二的 M-Step&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最後再把所有 dataset 的 weighted sum $(t_i, s_j)$ 統計出來，例如
$S_0$ 個 $(\bullet, s_0) \to \frac{a}{a+3b}S_0$ 個 $(t_0, s_0)$ 和 $\frac{3b}{a+3b}S_0$ 個 $(t_1, s_0)$
$S_1$ 個 $(\bullet, s_1) \to \frac{5a}{5a+b}S_1$ 個 $(t_0, s_1)$ 和 $\frac{b}{5a+b}S_1$ 個 $(t_1, s_1)$
$T_0$ 個 $(t_0, \bullet) \to \frac{1}{6}T_0$ 個 $(t_0, s_0)$ 和 $\frac{5}{6}T_0$ 個 $(t_0, s_1)$
$T_1$ 個 $(t_1, \bullet) \to \frac{3}{4}T_1$ 個 $(t_1, s_0)$ 和 $\frac{1}{4}T_1$ 個 $(t_1, s_1)$&lt;/p&gt;

&lt;p&gt;$(t_0, s_0)$ 個數 $\to N_{00} = \frac{1}{6}T_0+\frac{a}{a+3b}S_0$
$(t_0, s_1)$ 個數 $\to N_{01} = \frac{5}{6}T_0+\frac{5a}{5a+b}S_1$
$(t_1, s_0)$ 個數 $\to N_{10} = \frac{3}{4}T_1+\frac{3b}{a+3b}S_0$
$(t_1, s_1)$ 個數 $\to N_{11} = \frac{1}{4}T_1+\frac{b}{5a+b}S_1$&lt;/p&gt;

&lt;p&gt;因此可以使用完整 data 的 MLE estimation:
&lt;script type=&quot;math/tex&quot;&gt;a'=\frac{N_{00}+N_{01}}{6 N} \quad b'=\frac{N_{10}+N_{11}}{4 N}&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;to-do-next&quot;&gt;To Do Next&lt;/h2&gt;
&lt;p&gt;Go through GMM example.&lt;/p&gt;

&lt;p&gt;下一步 go through HMM model or simplest z -&amp;gt; o graph model.&lt;/p&gt;

&lt;p&gt;What is the mutual information of $o$ and $z$ in this case?&lt;/p&gt;

&lt;p&gt;假設可以有一個 close from Q function, e.g. GMM
&lt;strong&gt;In summary:  M-Step maximize the lower bound;  E-Step close the gap&lt;/strong&gt; 
E-Step
&lt;script type=&quot;math/tex&quot;&gt;q^{(t+1)}(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{o}, \boldsymbol{\theta}^{(t)})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;M-Step 
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} E_{q(z)} \ln p(\mathbf{o}, \mathbf{z} \mid \boldsymbol{\theta}^{(t)})&lt;/script&gt;&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><category term="EM" /><summary type="html"></summary></entry><entry><title type="html">Jekyll Memo for Github Blog</title><link href="http://localhost:4000/language/2021/06/30/Jekyll-Memo/" rel="alternate" type="text/html" title="Jekyll Memo for Github Blog" /><published>2021-06-30T16:29:08+08:00</published><updated>2021-06-30T16:29:08+08:00</updated><id>http://localhost:4000/language/2021/06/30/Jekyll-Memo</id><content type="html" xml:base="http://localhost:4000/language/2021/06/30/Jekyll-Memo/">&lt;p&gt;幾個重點&lt;/p&gt;

&lt;p&gt;Header&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;title line:  no other :,  wrong example:  title: Math AI : xxx =&amp;gt; the second : to be removed!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;tags: [xxx, xxx, xxx]&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Table&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;目前 Jekyll + Next theme 造成 table column width 非常寬。 I don’t know the exact reason.  I changed the xxx/xxx.github.io/_sass/_common/scaffolding/tables.scss
    &lt;ul&gt;
      &lt;li&gt;width: 300px;&lt;/li&gt;
      &lt;li&gt;table-layout: auto;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Equation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$$ math equation $$ =&amp;gt; leave empty lines “before” and “after” $$ $$! 也就是上下各要空一行！&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;${{ }}$  =&amp;gt; ${ \{ \}}$.  如果要打 {, 一定要加 \{.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Equation number:  必須先加上 header 如下。Reference: https://jdhao.github.io/2018/01/25/hexo-mathjax-equation-number/&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/x-mathjax-config&quot;&amp;gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Equation 本體&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$$\begin{equation}
E=mc^2
\end{equation}\label{eq1}$$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Equation citation use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$\eqref{eq1}$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Image&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;resize image 似乎有問題，需要另外的 plug-in&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="Jekyll" /><category term="Github" /><summary type="html">幾個重點</summary></entry><entry><title type="html">Edge AI- Object Detection History</title><link href="http://localhost:4000/ai/2021/02/16/Typora-Mermaid/" rel="alternate" type="text/html" title="Edge AI- Object Detection History" /><published>2021-02-16T16:29:08+08:00</published><updated>2021-02-16T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/02/16/Typora-Mermaid</id><content type="html" xml:base="http://localhost:4000/ai/2021/02/16/Typora-Mermaid/">&lt;h1 id=&quot;edge-ai-object-detection-history-2-pass-vs-1-pass-anchor-vs-anchor-less&quot;&gt;Edge AI: Object Detection History: 2-Pass Vs. 1-Pass; Anchor Vs. Anchor-less&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;sequenceDiagram
    participant Alice
    participant Bob
    Alice-&amp;gt;John: Hello John, how are you?
    loop Healthcheck
        John-&amp;gt;John: Fight against hypochondria
    end
    Note right of John: Rational thoughts &amp;lt;br/&amp;gt;prevail...
    John--&amp;gt;Alice: Great!
    John-&amp;gt;Bob: How about you?
    Bob--&amp;gt;John: Jolly good!
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
A[方形] --&amp;gt;B(圆角)
    B --&amp;gt; C{条件a}
    C --&amp;gt;|a=1| D[结果1]
    C --&amp;gt;|a=2| E[结果2]
    F[横向流程图]
&lt;/code&gt;&lt;/pre&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><summary type="html">Edge AI: Object Detection History: 2-Pass Vs. 1-Pass; Anchor Vs. Anchor-less</summary></entry><entry><title type="html">Math ML - Modified Softmax w/ Margin</title><link href="http://localhost:4000/ai/2021/01/16/softmax/" rel="alternate" type="text/html" title="Math ML - Modified Softmax w/ Margin" /><published>2021-01-16T16:29:08+08:00</published><updated>2021-01-16T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/01/16/softmax</id><content type="html" xml:base="http://localhost:4000/ai/2021/01/16/softmax/">&lt;h1 id=&quot;math-ml---modified-softmax-w-margin&quot;&gt;Math ML - Modified Softmax w/ Margin&lt;/h1&gt;
&lt;p&gt;[@rashadAdditiveMargin2020] and [@liuLargeMarginSoftmax2017]
Softmax classification 是陳年技術，可還是有人在老幹上長出新枝。其中一類是在 softmax 加上 maximum margin 概念 (sometimes refers to metric learning), 另一類是在 softmax 所有 dataset 中找出 “supporting vectors” 減少 computation 卻不失準確率。實際做法都是從修改 loss function 著手。本文聚焦在第一類增加 margin 的 算法。&lt;/p&gt;

&lt;h2 id=&quot;softmax-in-dl-or-ml-recap&quot;&gt;Softmax in DL or ML Recap&lt;/h2&gt;
&lt;p&gt;Softmax 最常用於 DL (i.e. deep layers) 神經網絡最後一層(幾層)的 multi-class classification 如下圖。
&lt;script type=&quot;math/tex&quot;&gt;\sigma(j)=\frac{\exp \left(\mathbf{w}_{j}^{\top} \mathbf{x}\right)}{\sum_{k=1}^{K} \exp \left(\mathbf{w}_{k}^{\top} \mathbf{x}\right)}=\frac{\exp \left(z_{j}\right)}{\sum_{k=1}^{K} \exp \left(z_{k}\right)}&lt;/script&gt;
and
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial}{\partial z_{i}} \sigma\left(z_{j}\right)=\sigma\left(z_{j}\right)\left(\delta_{i j}-\sigma\left(z_{i}\right)\right)&lt;/script&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input vector, $\mathbf{x}$, dimension $n\times 1$.&lt;/li&gt;
  &lt;li&gt;Weight matrix, $\mathbf[w_1’, w_2’, .., w_K’]’$, dimension $K\times n$&lt;/li&gt;
  &lt;li&gt;Output vector, $\mathbf{z}$, dimension $K\times 1$.&lt;/li&gt;
  &lt;li&gt;Softmax output vector, $0\le\sigma(j)\le 1, j=[1:K]$, dimension $K\times 1$.&lt;/li&gt;
  &lt;li&gt;注意 bias 如果是一個 fixed number, $b$, softmax 分子分母會抵銷。bias 如果不同 $b_1, b_2, …, b_n$，可以擴展 $\mathbf{x’ = [x, }1]$ and $\mathbf{w’_j = [w_j}, b_j]$, 同樣如前適用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16103750431293.jpg&quot; alt=&quot;-w718&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Softmax 也常用於 ML (i.e. shallow layers) 的 multi-class classification, 常和 SVM 一起比較。為了處理 nonlinear dataset or decision boundary, Softmax + kernel method 是一個選項。&lt;/p&gt;

&lt;p&gt;Softmax 另外用於 attention network, TBD.&lt;/p&gt;

&lt;h3 id=&quot;parameter-notation-and-range-for-ml-and-dl&quot;&gt;Parameter Notation and Range for ML and DL&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;$N$: number of data points.  100 to 10,000 for ML, &amp;gt; 1M for DL.&lt;/li&gt;
  &lt;li&gt;$n$: input vector dimension. maybe from 1~ to 100~ for ML, 1000-4000 for DL.&lt;/li&gt;
  &lt;li&gt;$K$ or $m$ or $C$: output vector dimension, number of classes, maybe from 1 (binary) to 100 (Imaginet)&lt;/li&gt;
  &lt;li&gt;$k$: kernel feature space dimension, maybe from 10s’ - $\infty$ for ML.  Usually not use for DL.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Summarize the result in table.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;n&lt;/th&gt;
      &lt;th&gt;k&lt;/th&gt;
      &lt;th&gt;K&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;ML&lt;/td&gt;
      &lt;td&gt;100-10,000&lt;/td&gt;
      &lt;td&gt;1s’- 100s’&lt;/td&gt;
      &lt;td&gt;10s’- $\infty$&lt;/td&gt;
      &lt;td&gt;1s’-10s’&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DL&lt;/td&gt;
      &lt;td&gt;&amp;gt; 1M&lt;/td&gt;
      &lt;td&gt;1000-4000&lt;/td&gt;
      &lt;td&gt;NA&lt;/td&gt;
      &lt;td&gt;10-100&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;softmax-w-margin-via-training&quot;&gt;Softmax w/ Margin Via Training&lt;/h2&gt;
&lt;p&gt;根據前文討論，$w_i$ vectors 代表和 class &lt;em&gt;i&lt;/em&gt; data 的&lt;strong&gt;相似性&lt;/strong&gt;。&lt;br /&gt;
普通的 softmax classification 如下圖左所示。&lt;/p&gt;

&lt;p&gt;Decision boundary 是 data point 和 $w_1$ and $w_2$ 的機率一樣。
因為 softmax (or logistic regression) 只要求 $\sigma_1(x) &amp;gt; \sigma_2(x)$ or vice versa to classify $x \in$ class 1 (or class 2).  &lt;strong&gt;這裡完全沒有 margin 的觀念。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16103799219592.jpg&quot; alt=&quot;-w480&quot; /&gt;&lt;/p&gt;

&lt;p&gt;推廣到 multiple class 更是如此，如下圖。因為是取 $\sigma(j)$ 的最大值。除了 $\sigma(j) &amp;gt; 0.5$ 有明顯的歸類。但在三不管地帶，很可能雜錯在一起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;因爲 training 是基於 loss function, 解法是在 loss function 加入 margin term 做為 driving force (check the back-prop gradient!), 讓 training process 竭盡所能 “擠出” margin, 如上圖右。&lt;/strong&gt;
&lt;img src=&quot;/media/16102567367645/16103795147028.jpg&quot; alt=&quot;-w528&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;如何在-softmax-加入-margin-for-training&quot;&gt;如何在 softmax 加入 margin for training&lt;/h2&gt;
&lt;p&gt;SVM 是從 decision boundary 的平行線距離著手（margin = 1/|w|, minimize |w| ~ maximum margin)。
本文討論 Softmax 加上 margin 有三種方式，都是從&lt;strong&gt;角度&lt;/strong&gt; $\theta$ 著手，概念如圖二右 (平面角度)，或是下圖右 (球面角度)。maximize $\theta$ 剛好和 minimize |w| 正交 (orthogonal). 這是巧合嗎？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16105488389665.jpg&quot; alt=&quot;-w475&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我們先看 Softmax 的 loss function 如下圖。先是 softmax function, inference/test 只要 再來通過 cross-entropy loss.  Cross-entropy loss 對應 log likelihood. 
&lt;script type=&quot;math/tex&quot;&gt;L=\frac{1}{N} \sum_{i} L_{i}=\frac{1}{N} \sum_{i}-\log \left(\frac{e^{f_{y_{i}}}}{\sum_{j} e^{f_{j}}}\right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where $f_{y_{i}}=\boldsymbol{W}&lt;em&gt;{y&lt;/em&gt;{i}}^{T} \boldsymbol{x}&lt;em&gt;{i}$ 代表 data $x_i$ 和 $W&lt;/em&gt;{y_i}$ 的相似性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16104627418371.jpg&quot; alt=&quot;-w300&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;三種用角度增加-softmax-inter-class-margin&quot;&gt;三種用角度增加 SoftMax inter-class margin&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;L-Softmax (Large Margin Softmax) [@liuLargeMarginSoftmax2017]&lt;/li&gt;
  &lt;li&gt;A-Softmax (Angular Softmax) [@liuSphereFaceDeep2018]&lt;/li&gt;
  &lt;li&gt;AM-Softmax (Additive Margin Softmax)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;l-softmax-large-margin-softmax-cos-theta-to-cos-mtheta&quot;&gt;L-Softmax (Large Margin Softmax): $\cos \theta \to \cos (m\theta)$&lt;/h4&gt;
&lt;p&gt;因為 $f_{j}=\left| \boldsymbol{W_j} \right|\left| \boldsymbol{x_i} \right|\cos\left(\theta_{j}\right)$.  如何在 $x_i$ 和 $W_j$ 加上 margin？  一個方法就是把 $\cos \theta$ 改成 $\cos m\theta$, why?&lt;/p&gt;

&lt;p&gt;從相似性來看，$\cos(m\theta)$ 在同樣的角度”相似性”掉的比較快。因此在 training 時會強迫把同一 feature 的 data 擠壓在一起, &lt;strong&gt;reduce the intra-class distance. 達到增加 inter-class margin 的目的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;另外可以從 decision boundary 理解。Softmax 的 decision boundary,&lt;/p&gt;

&lt;p&gt;$x\in$ Class 1:  $\left|\boldsymbol{W_1}\right||\boldsymbol{x}| \cos \left( \theta_{1}\right)&amp;gt;\left|\boldsymbol{W_2}\right||\boldsymbol{x}| \cos \left(\theta_{2}\right)$&lt;/p&gt;

&lt;p&gt;$x\in$ Class 2:  $\left|\boldsymbol{W_1}\right||\boldsymbol{x}| \cos \left( \theta_{1}\right) &amp;lt; \left|\boldsymbol{W_2}\right||\boldsymbol{x}| \cos \left(\theta_{2}\right)$&lt;/p&gt;

&lt;p&gt;and $\theta_1 + \theta_2 = \theta$ which is the angle between $W_1$ and $W_2$&lt;/p&gt;

&lt;p&gt;如果把 $\cos \theta \to \cos (m\theta)$,&lt;/p&gt;

&lt;p&gt;$x\in$ Class 1:  $\left|\boldsymbol{W_1}\right||\boldsymbol{x}| \cos \left( m\theta_{1}\right)&amp;gt;\left|\boldsymbol{W_2}\right||\boldsymbol{x}| \cos \left(\theta_{2}\right)$.
 &lt;/p&gt;

&lt;p&gt;Assuming $|W_1| = |W_2| \to \theta_1 &amp;lt; \theta_2/m$, 因為 $\cos\theta$ 是遞減函數。&lt;/p&gt;

&lt;p&gt;$x\in$ Class 2:  $\left|\boldsymbol{W_1}\right||\boldsymbol{x}| \cos \left( \theta_{1}\right) &amp;lt; \left|\boldsymbol{W_2}\right||\boldsymbol{x}| \cos \left(m\theta_{2}\right)$.&lt;/p&gt;

&lt;p&gt;Assuming $|W_1| = |W_2| \to \theta_1/m &amp;gt; \theta_2$.&lt;/p&gt;

&lt;p&gt;此時我們有兩個 decision boundaries, 兩個 boundaries 之間可以視為 decision margin, 如下圖。
&lt;img src=&quot;/media/16102567367645/16107219487390.jpg&quot; alt=&quot;-w400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In summary, 就是在 labelled $c$ class 的 data 時，就把對應的 $\cos\theta_c$ 改成 $\cos (m\theta_c)$. $m$ 愈大，margin 就愈大。但過之猶如不及，如果 $m$ 太大，可能無法正確 capture features (TBC)? $m$ 應該有一個 optimal value.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{i}=-\log \left(\frac{e^{\left\|\boldsymbol{W}_{y_{i}}\right\|\left\|\boldsymbol{x}_{i}\right\| \psi\left(\theta_{y_{i}}\right)}}{e^{\left\|\boldsymbol{W}_{y_{i}}\right\|\left\|\boldsymbol{x}_{i}\right\| \psi\left(\theta_{y_{i}}\right)}+\sum_{j \neq y_{i}} e^{\left\|\boldsymbol{W}_{j}\right\|\left\|\boldsymbol{x}_{i}\right\| \cos \left(\theta_{j}\right)}}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\psi(\theta)=\left\{\begin{array}{l}
\cos (m \theta), \quad 0 \leq \theta \leq \frac{\pi}{m} \\
\mathcal{D}(\theta), \quad \frac{\pi}{m}&lt;\theta \leq \pi
\end{array}\right. %]]&gt;&lt;/script&gt;

&lt;p&gt;為什麼會有 $D(\theta)$？ 原因是要維持 $\psi(\theta)$ 的&lt;strong&gt;遞減性，連續性，和可微分性&lt;/strong&gt; over $[0, \pi]$.  一旦定義出 $\psi(\theta)$ over $[0, \pi]$. 左右 flip (y 軸對稱) 得到 $\theta\in[-\pi, 0]$. 其他的 $\theta$ 都可以移到 $[-\pi, \pi]$.&lt;/p&gt;

&lt;p&gt;舉一個例子如下式，$\psi(\theta)$ 的 curve 如下圖。
&lt;script type=&quot;math/tex&quot;&gt;\psi(\theta)=(-1)^{k} \cos (m \theta)-2 k, \quad \theta \in\left[\frac{k \pi}{m}, \frac{(k+1) \pi}{m}\right]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16107278677656.jpg&quot; alt=&quot;-w386&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;a-softmax-angular-softmax-cos-theta-to-cos-mtheta-and-w1&quot;&gt;A-Softmax (Angular Softmax): $\cos \theta \to \cos (m\theta)$ and $|W|=1$&lt;/h4&gt;
&lt;p&gt;在 L-Softmax 可以同時調整 $|W|$ and $\theta$, 在 A-Softmax 進一步限制 $|W|=1$, 其他都和 L-Softmax 相同。A-Soft 的 Loss function 如下， 
&lt;script type=&quot;math/tex&quot;&gt;L_{\mathrm{ang}}=\frac{1}{N} \sum_{i}-\log \left(\frac{e^{\left\|\boldsymbol{x}_{i}\right\| \cos \left(m \theta_{y_{i}, i}\right)}}{e^{\left\|\boldsymbol{x}_{i}\right\| \cos \left(m \theta_{y_{i}, i}\right)}+\sum_{j \neq y_{i}} e^{\left\|\boldsymbol{x}_{i}\right\| \cos \left(\theta_{j, i}\right)}}\right)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;後來有再修正 $\psi(\theta)$, 多加一個 hyper-parameter $\lambda$, angle similarity curve 如下圖。注意 A-Softmax 的 $\psi(0)=1.$
&lt;script type=&quot;math/tex&quot;&gt;\psi(\theta)=\frac{(-1)^{k} \cos (m \theta)-2 k+\lambda \cos (\theta)}{1+\lambda}&lt;/script&gt;
&lt;img src=&quot;/media/16102567367645/16108061480853.jpg&quot; alt=&quot;-w427&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因為 $|W|=1$, A-Softmax 一個用途是 hyper-sphere explanation 如下圖。理論上 L-Softmax 包含 A-Softmax, 但在某一些情況下，A-Softmax 似乎效果更好，less is more? (同一作者，2017 L-SoftMax; 2018 A-Softmax).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16108029553353.jpg&quot; alt=&quot;-w648&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;am-softmax-additive-margin-softmax-cos-theta-to-cos-theta--m&quot;&gt;AM-Softmax (Additive Margin Softmax): $\cos \theta \to \cos \theta -m$&lt;/h4&gt;
&lt;p&gt;AM-Softmax 非常有趣，它把 $\cos\theta \to \cos(m\theta) \to \cos\theta -m$, 也就是，
&lt;script type=&quot;math/tex&quot;&gt;\psi(\theta)=\cos \theta-m&lt;/script&gt;
AM-Softmax 的 loss function, 但多了一個 hyper-parameter $s$(?)
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}_{A M S} &amp;=-\frac{1}{n} \sum_{i=1}^{n} \log \frac{e^{s \cdot\left(\cos \theta_{y_{i}}-m\right)}}{e^{s \cdot\left(\cos \theta_{y_{i}}-m\right)}+\sum_{j=1, j \neq y_{i}}^{c} e^{s \cdot \cos \theta_{j}}} \\
&amp;=-\frac{1}{n} \sum_{i=1}^{n} \log \frac{e^{s \cdot\left(W_{y_{i}}^{T} \boldsymbol{f}_{i}-m\right)}}{e^{s \cdot\left(W_{y_{i}}^{T} \boldsymbol{f}_{i}-m\right)}+\sum_{j=1, j \neq y_{i}}^{c} e^{s W_{j}^{T} \boldsymbol{f}_{i}}} .
\end{aligned} %]]&gt;&lt;/script&gt;
這有很多好處：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;不用再分段算 $\psi(\theta)$, forward and backward 計算變成很容易。&lt;/li&gt;
  &lt;li&gt;$m$ 是 continuous variable, 不是 discrete variable in A-Softmax. $m$ 可以 fine-grain optimized hyper-parameter. 而且是 differentiable, 我認為可以是 trainable variable.&lt;/li&gt;
  &lt;li&gt;AM-Softmax 同時 push angle and magnitude?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;qa&quot;&gt;Q&amp;amp;A&lt;/h2&gt;
&lt;p&gt;Q. Data 不是固定的嗎？為什麼會隨 loss function 改變？
A. 此處是假設 CNN network 的最後一層是 Softmax, 因此 input data 對應的 feature extraction 並非固定而且會隨 loss function 改變如下圖。如果 input data 直接進入 Softmax with or without margin, the input data 顯然不會改變，但是 decision boundary may change? (next Q)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16102567367645/16107599078389.jpg&quot; alt=&quot;-w456&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Q. 在 inference/test 時，以上的公式 (check class $c$) 加起來不等於 1？ 如何解決？
A: 以上的公式只用於 training 增加 margin? 在 inference/test 時，仍然用原來的 softmax 公式，因此機率仍然為 1.&lt;/p&gt;

&lt;p&gt;Q. 以上 $cos(m \theta)$ 的 $m$ 一定要整數嗎？
A. 整數可以定義 continuous and differentiable loss function in $0-\pi$ 角度。上上圖的角度顯示 $0-\pi/2$ 角度，$\pi/2 - \pi$ 是 $0-\pi/2$ 的左右 flip curve.  如果 $m$ 不是整數，在 $\pi/2$ is non-differentiable.  另外也讓 loss function 的分段比較麻煩。不過我認為這都不是什麼問題。重點是 $m$ 不是整數有沒有用？ 我認為有用，可以視為另一個 hyper-parameter, or trainable parameter for optimization!  $m$ 太小沒有 margin, $m$ 太大會 filter out some features (under-fit)?&lt;/p&gt;

&lt;h2 id=&quot;策略同時使用角度-maximize-theta-and-magnitude-minimize-w&quot;&gt;策略：同時使用角度 maximize $\theta$ and Magnitude minimize $|w|$！&lt;/h2&gt;
&lt;p&gt;Magnitude margin: 增加 inter-class margin?
Angle margin: compress intra-class?
先 push 角度，再 push w, 再角度, ….
角度 m, make it differentiable!&lt;/p&gt;

&lt;h2 id=&quot;to-do&quot;&gt;To Do&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;check the SVM, check the logistic regression, check import vector&lt;/li&gt;
  &lt;li&gt;Use binary classification as an example&lt;/li&gt;
  &lt;li&gt;Pro and Con of the three types.&lt;/li&gt;
  &lt;li&gt;Most importantly, try to use both amplitude and angle for learning!!  TBD&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Liu, Weiyang, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le
Song. 2018. “SphereFace: Deep Hypersphere Embedding for Face
Recognition.” January 29, 2018. &lt;a href=&quot;http://arxiv.org/abs/1704.08063&quot;&gt;http://arxiv.org/abs/1704.08063&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Liu, Weiyang, Yandong Wen, Zhiding Yu, and Meng Yang. 2017.
“Large-Margin Softmax Loss for Convolutional Neural Networks.” November
17, 2017. &lt;a href=&quot;http://arxiv.org/abs/1612.02295&quot;&gt;http://arxiv.org/abs/1612.02295&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Rashad, Fathy. n.d. “Additive Margin Softmax Loss (AM-Softmax).” Medium.
Accessed December 27, 2020.
&lt;a href=&quot;https://towardsdatascience.com/additive-margin-softmax-loss-am-softmax-912e11ce1c6b&quot;&gt;https://towardsdatascience.com/additive-margin-softmax-loss-am-softmax-912e11ce1c6b&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Wang, Feng, Weiyang Liu, Haijun Liu, and Jian Cheng. 2018. “Additive
Margin Softmax for Face Verification.” May 30, 2018.
&lt;a href=&quot;https://doi.org/10.1109/LSP.2018.2822810&quot;&gt;https://doi.org/10.1109/LSP.2018.2822810&lt;/a&gt;.&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><summary type="html">Math ML - Modified Softmax w/ Margin [@rashadAdditiveMargin2020] and [@liuLargeMarginSoftmax2017] Softmax classification 是陳年技術，可還是有人在老幹上長出新枝。其中一類是在 softmax 加上 maximum margin 概念 (sometimes refers to metric learning), 另一類是在 softmax 所有 dataset 中找出 “supporting vectors” 減少 computation 卻不失準確率。實際做法都是從修改 loss function 著手。本文聚焦在第一類增加 margin 的 算法。</summary></entry><entry><title type="html">Math AI - G-CNN (Group + CNN)</title><link href="http://localhost:4000/ai/2020/05/08/G-CNN/" rel="alternate" type="text/html" title="Math AI - G-CNN (Group + CNN)" /><published>2020-05-08T16:29:08+08:00</published><updated>2020-05-08T16:29:08+08:00</updated><id>http://localhost:4000/ai/2020/05/08/G-CNN</id><content type="html" xml:base="http://localhost:4000/ai/2020/05/08/G-CNN/">&lt;h1 id=&quot;math-ai---g-cnn-group--cnn&quot;&gt;Math AI - G-CNN (Group + CNN)&lt;/h1&gt;
&lt;p&gt;Where is group theory (G-CNN) + Curved Space (Spherical CNN)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Manifold learning 是機器學習的分支，屬於淺層學習 (shallow learning).  Manifold learning 的技巧 (kernel PCA?, Laplacian Eigenmap, etc.) 是否能用於&lt;strong&gt;深度學習&lt;/strong&gt;？ Yes, via kernel!   PCA =&amp;gt; CNN kernel;  LE etc. =&amp;gt; geometric kernel?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Why 結合深度學習和 manifold learning?
    &lt;ul&gt;
      &lt;li&gt;深度學習 based on CNN kernel =&amp;gt; translation covariant (not invariant, invariant 是指純量 independent of coordinate system, e.g. Lagrangian, action, or $ds^2$.  Covariant means coordinate …) on 2D Euclidean plane,  Need based on ??? kernel  =&amp;gt; translation/rotation covariant on manifold  =&amp;gt; 結合深度學習和 manifold learning&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;可以減少 training set!&lt;/strong&gt;  因為 manifold learning 自帶 translation/rotation covariant, 甚至可以 extend to manifold deformation (e.g.姿體移動?)  可以結合 prior information? (姿體移動，蛋白質移動,旋轉,鏡像 …)&lt;/li&gt;
      &lt;li&gt;Can this resist adversarial attack?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;translation equivariant - CNN, plus rotation/mirror equivariant - g-CNN&lt;/li&gt;
  &lt;li&gt;then sphere equivariant - sphere CNN (non-flat); finally ??&lt;/li&gt;
  &lt;li&gt;How about scale invariant or equivariant?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;終於了解 G-CNN 的意義，就是把 kernel 2D convolution (Z2 commutative group) expand to a 4D G-convolution (p4m: Di4 non-commutative group).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;只有 input image 是 (x, y) base, 經過 layer-1 G-convolution 轉為 p4m g space.  所有之後的 layers’ convolution 都是在 g space 做, i.e. input and output activation 都是在 {4D g space + 1D Depth=5D} space instead of {2D (x,y) + 1D depth = 3D} space.  到了最後 fully connected 再變成分類網路。  這真是 particle physicist 才會有的高維思維！一般人還是習慣每一層 input output activation 老老實實在 2D (x,y) space.  (example: https://arxiv.org/pdf/1807.11156.pdf).  I like this idea: Go high dimension all the way!  In some sense, channel or depth dimension 也是一個人造的 dimension!&lt;/li&gt;
  &lt;li&gt;More parameters?  Should be.&lt;/li&gt;
  &lt;li&gt;Still can find the (x,y) for location?  Yes, it is a superset!&lt;/li&gt;
  &lt;li&gt;Use 1D convolution with mirror group as an example.&lt;/li&gt;
  &lt;li&gt;How about broken symmetry? 或是 miss some kernel?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;再推廣-group-equivariance-estevespolartransformer2018&quot;&gt;再推廣 Group Equivariance [@estevesPOLARTRANSFORMER2018]&lt;/h2&gt;
&lt;p&gt;Equivariant representations are highly sought after as they encode both class and deformation information in a predictable way. Let $G$ be a transformation group and $L_g I$ be the group action applied to an image $I$. A mapping $\Phi : E \to F$ is said to be equivariant to the group action $L_g$, $g \in G$ if&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Phi\left(L_{g} I\right)=L_{g}^{\prime}(\Phi(I))&lt;/script&gt;

&lt;p&gt;where $L_g$ and $L’&lt;em&gt;g$ correspond to application of $g$ to $E$ and $F$ respectively and satisfy $L&lt;/em&gt;{gh} = L_g L_h$ and $L’_{gh} = L’_g L’_h$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Invariance is a special case of equivariance where $L’_g = I$.&lt;/li&gt;
  &lt;li&gt;Another special case is $L_g = L’_g$.&lt;/li&gt;
  &lt;li&gt;Image classification and CNN, $g \in G$ can be thought of as an image deformation and $\Phi$ a mapping from the image to a feature map.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next step:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Image $I$ is a function of coordinate, x, $I = f(x)$ at first layer.&lt;/li&gt;
  &lt;li&gt;Group operation on f(x) is 
 $L_g f(x) = f(g^{-1}x)$.  原因很簡單，就是在 $x = gx’$ 會得到原來的 $f(x’)$.&lt;/li&gt;
  &lt;li&gt;2D discrete convolution, $L_g f(x) = &lt;a href=&quot;g^{-1}x&quot;&gt;f\circ \phi&lt;/a&gt; $ 定義如下。$x, y \in Z^2$&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;[f * \phi](x)=\sum_{y \in \mathbb{Z}^{2}} f(y) \phi(x-y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;[f \star \phi](x)=\sum_{y \in \mathbb{Z}^{2}} f(y) \phi(y-x)&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;CNN 3D convolution, $L_g f(x) = &lt;a href=&quot;g^{-1}x&quot;&gt;f\circ \phi&lt;/a&gt; $ 定義如下。$x, y \in Z^2$; $k$ and $i$ 分別代表 input/output channel depth&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;[f * \phi^i](x)=\sum_{y \in \mathbb{Z}^{2}} \sum_{k=1}^{K^{l}} f_{k}(y) \phi^i_{k}(x-y)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;[f \star \phi^i](x)=\sum_{y \in \mathbb{Z}^{2}} \sum_{k=1}^{K^{l}} f_{k}(y) \phi^i_{k}(y-x)&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;推廣到 2D group convolution.  $g, h \in G$&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(f *_{G} \phi)(g)=\int_{h \in G} f(h) \phi(h^{-1} g) d h&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(f \star_{G} \phi)(g)=\int_{h \in G} f(h) \phi(g^{-1} h) d h&lt;/script&gt;

&lt;ol&gt;
  &lt;li&gt;推廣到 3D Group CNN or G-CNN.  $g, h \in G$, $k$ and $i$ 分別代表 input/output channel depth
&lt;script type=&quot;math/tex&quot;&gt;\begin{array}{l}
{\left[f * \phi^i\right](g)=\sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \phi^i_{k}(h^{-1}g)} \\
{\left[f \star \phi^i\right](g)=\sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \phi^i_{k}(g^{-1}h)}
\end{array}&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Convolution and CNN 具有 translational equivariance and independent of kernel $\phi$.  直觀而言，就是把 input image (or feature map) 和 kernel filter 的 symmetry group (e.g. translation, rotation, reflection) 做 similarity (inner product), 但保留印記 (coordinate (x,y), reflection (m=1, -1), rotation (r=0, 1, 2, 3)) 到 output feature map.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;2D convolution or 3D CNN 的 $g^{-1} h = y-x$  and $h^{-1} g = (g^{-1} h)^{-1} = x-y$ 是 $Z^2$ 反元素。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;其中 layer1 的 input image 因為只有 2D coordinate (x,y) + 1D depth (c=3, e.g. RGB) = 3D tensor, 但是 output feature map 變成 2D coordinate (x,y) + 1D reflection(m) + 1D rotation(r) + 1D depth (c) = 5D tensor.&lt;/li&gt;
  &lt;li&gt;其他 layers 的 input and output 都是 5D tensors.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;group-equivariant-operation&quot;&gt;Group Equivariant Operation&lt;/h2&gt;

&lt;p&gt;參考 [@prismGroupEquivariant2019] and [@cohenGroupEquivariant2019].&lt;/p&gt;

&lt;p&gt;在這篇文章中，作者以初學者的角度，從最基本的概念開始，解釋對稱性並通俗地引入群論的理論框架。所謂對稱性，就是目標在經歷一定變換以後保持不變的性質。而這裡用到的對稱性群（symmetry group），可理解為一系列滿足某些限制條件的對稱性變換的集合。下面是文中對對稱性群的定義：&lt;/p&gt;

&lt;p&gt;而在卷積網絡裡面涉及到的，最簡單的例子就是二維整數平移操作所組成的群 $\mathbb{Z}^2$。&lt;/p&gt;

&lt;p&gt;接下來，我們簡單回顧一下傳統卷積網絡的等變（Equivariance）性質。平移等變性質是CNN對目標的響應能夠不受目標在圖像中的位置影響的基礎。《深度學習》花書裡面是這樣描述等變性質：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果一個函數滿足，輸入改變而輸出也以同樣的方式改變的這一性質，我們就說它是等變的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;簡單的例子，就是當目標出現在輸入圖片中的不同位置，輸出的feature map應該是只是進行了平移變換。
&lt;img src=&quot;media/15790137525682/15866188574631.jpg&quot; alt=&quot;-w600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而從數學上，從算符対易性的角度，等變性質可以這樣定義：對於群對稱 $g \in G$ ，其算符 $L_g$ 和函數 $f(x)$，有 $f(L_g x) = L_g(f(x))$ ，也就是 $f$ 與 $L_g$ 対易，則稱$f(x)$ 對於變換 $g$ 有等變性。&lt;/p&gt;

&lt;p&gt;在深度學習當中，我們更希望卷積網絡具有等變性，而不是不變性（Invariance）:
&lt;img src=&quot;media/15790137525682/15866220196651.jpg&quot; alt=&quot;-w600&quot; /&gt;
在畢卡索的這幅畫中，臉部五官都在，但是顯然被解構和調整。如果神經網絡對目標的響應具有「不變性」，顯然仍然會認為這就是一張普通人臉。&lt;/p&gt;

&lt;p&gt;接下來作者引入一個結論：&lt;/p&gt;

&lt;p&gt;這個公式的含義是：要得到經過 [公式] 變換的feature map [公式] 在 [公式] 處的值，可以通過計算在 [公式] 位置上面 [公式] 的值。舉例來說，如果 [公式] 是平移操作t，則 [公式] ，那我們只需計算在 [公式] 這一點feature的值便可得到。這個公式將在推到等變性的時候用到。&lt;/p&gt;

&lt;p&gt;對於傳統卷積網絡， [公式] 則對應平移操作 [公式] 。也就是說，由於平移操作雖然會對卷積操作的輸出產生改變，但是這種改變是線性的，可以預測的。反之，不等變的操作則會對輸出帶來非線性的影響。&lt;/p&gt;

&lt;p&gt;為了證明傳統卷積網絡裡面，平移與卷積操作対易，首先明確定義傳統卷積操作和互相關操作：&lt;/p&gt;

&lt;p&gt;在這裡，filter對輸入層的滑動掃描被看做對其平移操作。需要注意的是在傳統的卷積網絡裡面，前向過程事實上用的是互相關操作卻被泛泛稱為「卷積操作」。&lt;/p&gt;

&lt;p&gt;然後文章中很容易證明瞭互相關操作( [公式] )和卷積（ [公式] ）操作都與平移操作 [公式] 対易（commute）:&lt;/p&gt;

&lt;p&gt;[公式]&lt;/p&gt;

&lt;p&gt;[公式]&lt;/p&gt;

&lt;p&gt;由這兩個操作対易，從而得出結論：卷積是平移操作的等變映射。&lt;/p&gt;

&lt;p&gt;另外一方面，作者發現旋轉操作與卷積操作是不対易的，「correlation is not an equivariant map for the rotation group」，但是feature map的堆疊卻可能是等變的。也正是因為旋轉操作不是卷積的等變映射，往傳統的CNN裡面輸入旋轉了的圖像，圖像識別的效果則會大打折扣。為瞭解決這個問題，最傳統直接的方法是數據增強，直接把圖像旋轉再輸入網絡進行訓練，但是這種方法顯然不是最優的。為了改進網絡本身來解決這個問題，考慮一個簡單的具有四重旋轉對稱軸的對稱性群 [公式] (wiki). 對於這個群，有四種對稱性操作：平移，旋轉90°，旋轉180°，旋轉270°。我們要設計一個新的CNN結構，使得當輸入圖像有以上變換時，網絡仍然具有等變性質。&lt;/p&gt;

&lt;p&gt;為了這個目的，仿照(2)(3)，根據(1)的結論，作者提出的 G-correlation，其定義為：&lt;/p&gt;

&lt;p&gt;對於第一層G-CNN（first-layer G-correlation）， [公式] 和[公式] 定義在平面 [公式] 上：&lt;/p&gt;

&lt;p&gt;[公式]&lt;/p&gt;

&lt;p&gt;對於接下來的G-CNN層（full G-correlation）， [公式] 和[公式] 定義在群G上：&lt;/p&gt;

&lt;p&gt;[公式]&lt;/p&gt;

&lt;p&gt;由此帶來的改變是，作者很容易證明瞭G-CNN對於群G的變換操作是等變的（「G-correlation is an equivariant map for the translation group」）: [公式]&lt;/p&gt;

&lt;p&gt;詳細推導見文章。值得注意的是， 經師弟提醒，對第一層G-CNN的等變性推到，需要把 [公式] 和 [公式] 拓展到群 [公式] 上，否則將無法推導（因為 [公式] 顯然不再屬於群 [公式] ）。&lt;/p&gt;

&lt;p&gt;也就是說，G-CNN推廣了對feature map的變換操作，從傳統的只有平移變換的群 [公式] 到某個對稱性群 [公式] 。而且推廣以後，G-CNN卷積層對於該群的對稱性變換操作具有等變性質。&lt;/p&gt;

&lt;p&gt;雖然作者在文中沒有提及，不難看到，G-CNN可以自然退化到傳統的CNN。當對稱性群G只有平移 [公式] 一種對稱性操作，也就是 [公式] 時，則G-CNN也就是傳統的CNN。&lt;/p&gt;

&lt;p&gt;總而言之，當輸入圖像是按照特定角度旋轉的，G-CNN網絡的輸出結果應該是按照預定規律變化的。因此，G-CNN具備了更強的旋轉輸入圖像特徵提取的能力。&lt;/p&gt;

&lt;p&gt;可以完全從 math 角度來看深度學習。
CNN 的核心是 convolution, math 抽象來看是 Euclidean translation invariance (Z^2).  更進一步的是 Euclidean rotation invariance (U(1), SO(2) group?).  或者 manifold (sphere) translation/rotation invariance.&lt;/p&gt;

&lt;p&gt;Gauge Convolutional Networks
[@xinzhiyuanGeometricalDeep2020] and [@pavlusIdeaPhysics2020]
https://kknews.cc/tech/gpkgx3e.html&lt;/p&gt;

&lt;h2 id=&quot;math-formulation&quot;&gt;Math Formulation&lt;/h2&gt;
&lt;p&gt;前面說的都是描述性的語言，再來是干貨。
先澄清一些&lt;em&gt;無關&lt;/em&gt;的 ideas.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Symmetric Group&lt;/strong&gt; 
Group theory 中的 symmetric group 有明確的定義，就是 n symbol 所有 permutation (i.e. self bijections) 形成的 group, 稱為 $S_n$, with $n!$ group element. 下圖是 $S_4$ 的 Cayley graph, total 4! = 24 elements. 所有的 finite group 可以證明都是某個 symmetric group 的子群。&lt;strong&gt;不過這裡的 symmetric group 和本文無關。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15790137525682/15873110898403.jpg&quot; alt=&quot;-w400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Symmetry Brings Conservation (Noether Theorem)&lt;/strong&gt; (check 廣義相對論 article)
A physic law is invariant of different observer.  For example the Lagrangian is invariant (or covariant?) under certain coordinate transformation (different observers).  We called these coordinate transformation as symmetry operation.  These symmetry operation corresponds to a specific conservation law.&lt;/p&gt;

&lt;p&gt;再來進入主題。&lt;/p&gt;

&lt;h3 id=&quot;equivariance-math-formulation-of-neural-network&quot;&gt;Equivariance Math Formulation of Neural Network&lt;/h3&gt;

&lt;p&gt;$y = \Phi(x)$ where $\Phi$ represents (part of) the neural network. $y$ is network output feature tensor; x is input image tensor.  Tensor can be viewed as a high dimension matrix.&lt;br /&gt;
$\Phi$ 可以是一個複雜的 cascaded nonlinear function (with CNN, ReLU, Pooling, etc.) or a simple linear function with tensor input and tensor output.&lt;/p&gt;

&lt;p&gt;$\Phi$ 可以是 injective/bijective or non-injective.  例如，input image tensor 是 WxHxCin, 如果 output tensor 是 WxHxCout (stride=1) and Cout $\ge$ Cin, 一般是 injective or bijective.  如果 stride &amp;gt; 1 or Cout &amp;lt; Cin, 則是 non-injective, 也就是存在 $x’\ne x$, and $\Phi(x’) = \Phi(x)$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15790137525682/15873841531452.jpg&quot; alt=&quot;-w766&quot; /&gt;&lt;/p&gt;

&lt;p&gt;$x’ = T x$ where $T$ is a linear transformation (&lt;strong&gt;a multi-dimension matrix&lt;/strong&gt;) corresponding to a new observer (coordinate).  此處 T 是 bijective transform, or full rank transformation, 例如 translation, rotation, affine transformation.&lt;/p&gt;

&lt;p&gt;The new observer obtains the new output feature tensor 
$y’ = \Phi(x’) = \Phi(T x)$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Our goal is to explore the relationship between $\Phi(T x)$ and $\Phi(x)$.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In general, $\Phi(T x)$ 和 $\Phi(x)$ 可能有各種不同的關係。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果 $\Phi(T x) = \Phi(x) \; \forall x$, 滿足的所有 $T$ 稱為 $\Phi$ 的 invariant group.
    &lt;ul&gt;
      &lt;li&gt;Ex. $\Phi$ is norm of x, $T_g$ 是所有 metric-perserve transformation (translation, rotation, mirror, etc.)&lt;/li&gt;
      &lt;li&gt;It losses all T information, all completely independent of coordinate.&lt;/li&gt;
      &lt;li&gt;Usually for scalar.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果 $\Phi(T x) = T \Phi(x) \; \forall x$, 滿足的所有 $T$ 稱為 $\Phi$ 的 equivariant group.
    &lt;ul&gt;
      &lt;li&gt;Keep spatial information&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;equivariant-group-phi-is-linear-and-bijective-full-rank&quot;&gt;Equivariant Group: $\Phi$ is Linear and Bijective (full rank)&lt;/h3&gt;

&lt;p&gt;If $\Phi$ is a linear network, 可視為一個 matrix $\Phi$, i.e. $\Phi(T x) = \Phi T x$.  為了簡化，假設 $\Phi$ and $T$ 是 2D matrix.&lt;/p&gt;

&lt;p&gt;現在需要找到 given $\Phi$, 什麼 $T$ 可以得到 
$\Phi(T x) = \Phi T x = T \Phi x = T \Phi(x)$ for $\forall x$
$\Rightarrow \Phi T = T \Phi$, 也就是 $\Phi$ and $T$ commute, 因此變成 commuting matrices problem, 可以參考 [@wikiCommutingMatrices2019].&lt;/p&gt;

&lt;p&gt;One sufficient (not a necessary) condition: $\Phi$ and $T$ are simultaneously diagonalizable, i.e. 
$\Phi = P^{-1} D P$ and $T = P^{-1} Q P$ where $D$ and $Q$ 都是 diagonal matrix. 
$\Phi T = P^{-1} D Q P = P^{-1} Q D P = T \Phi$&lt;/p&gt;

&lt;p&gt;也就是只要 $T = P^{-1} Q P$ where P comes from eigenvectors of $\Phi$,  $\Phi T x = T \Phi x \; \forall x$.  Commuting matrices preserve each other’s eigenspaces.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;這樣的 $T$ form a commuting (Abelian) group $T_g$ (assuming T is full rank, exclude 0 in the eigenvalues of T and Q)&lt;/strong&gt;, 因為 $T_1  T_2 = P^{-1} Q_1 P P^{-1} Q_2 P = P^{-1} (Q_1 Q_2) P = P^{-1} (Q_2 Q_1) P = T_2 T_1 = T_3$ (multiplication closure and commuting), 並且每一個 $T$ 都存在唯一的反元素 $P^{-1} Q^{-1} P$ (inverse closure).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In summary, given a linear and bijective network $\Phi$, 可以定義一個 equivarient commutative group $T_g$ such that $\Phi(T x) = T \Phi(x) \; \forall x$.  這個群的元素(matrix) 的 eigenvectors 都和 $\Phi$ eigenvectors 一致。&lt;/strong&gt;  也可以把 $\Phi$ 視為這個 group, $T_g$ 的一個 element.&lt;/p&gt;

&lt;h4 id=&quot;simple-phi-2d-matrix-equivariant-group-example&quot;&gt;Simple $\Phi$: 2D Matrix Equivariant Group Example&lt;/h4&gt;
&lt;p&gt;Ex1: $\Phi$ = [1, 0; 0, 2]  $\Rightarrow T_g =[k_1, 0; 0, k_2]$. 所有 &lt;strong&gt;unequal scaling 都是 equivariant group.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ex2: $\Phi$ = [2, 1; 1, 2]  $\Rightarrow T_g =[c, s; s, c]$.  所有 &lt;strong&gt;hyperbolic rotation 都是 equivariant group (with a normalization constant).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ex3: $\Phi$ = [2, -1; 1, 2]  $\Rightarrow T_g =[c, -s; s, c]$.  所有 &lt;strong&gt;rotation 都是 equivariant group (with a normalization constant).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Ex4: &lt;strong&gt;Horizontal shear 也是一個 equivariant group.&lt;/strong&gt;&lt;br /&gt;
Proof: $[1, k_1; 0, 1] \times [1, k_2; 0, 1] = [1, k_1+k_2; 0, 1] \to$ multiplication closure and 反元素是 $[1, -k; 0, 1] \to$ inverse closure.&lt;/p&gt;

&lt;p&gt;Ex5: Uniform scaling 也是一個 (trivial) equivariant group.&lt;/p&gt;

&lt;p&gt;下圖摘自 [@wikiEigenvaluesEigenvectors2020].
&lt;img src=&quot;media/15790137525682/15875295928215.jpg&quot; alt=&quot;-w700&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;discrete-convolution-wikitoeplitzmatrix2020&quot;&gt;Discrete Convolution: [@wikiToeplitzMatrix2020]&lt;/h4&gt;
&lt;p&gt;Discrete convolution (離散卷積) 廣泛用於數位訊號處理和深度學習 for audio and video.  Discrete convolution 基本是 linear bijective operation, 同樣適用 equivariant group 的結論。我們用 1D discrete convolution 為例如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
y=h * x=\left[\begin{array}{ccccc}
h_{1} &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \\
h_{2} &amp; h_{1} &amp; &amp; \vdots &amp; \vdots \\
h_{3} &amp; h_{2} &amp; \cdots &amp; 0 &amp; 0 \\
\vdots &amp; h_{3} &amp; \cdots &amp; h_{1} &amp; 0 \\
h_{m-1} &amp; \vdots &amp; \ddots &amp; h_{2} &amp; h_{1} \\
h_{m} &amp; h_{m-1} &amp; &amp; \vdots &amp; h_{2} \\
0 &amp; h_{m} &amp; \ddots &amp; h_{m-2} &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; h_{m-1} &amp; h_{m-2} \\
\vdots &amp; \vdots &amp; &amp; h_{m} &amp; h_{m-1} \\
0 &amp; 0 &amp; 0 &amp; \cdots &amp; h_{m}
\end{array}\right]\left[\begin{array}{c}
x_{1} \\
x_{2} \\
x_{3} \\
\vdots \\
x_{n}
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;$y = h * x = \Phi x$ where $\Phi$ is a $n\times n$ matrix, 就是把 m-tap kernel filter $[h_1, h_2, …, h_m]$ &lt;strong&gt;shift (平移)&lt;/strong&gt; n 次造出的 matrix, 稱為 Toeplitz matrix. 一般 n » m, 因此是 “band matrix” with high sparsity. 後面會看到 $\Phi$ 的 equivariant group $T_g$ 和這個操作直接相關。&lt;/p&gt;

&lt;p&gt;下一步是要找出 $\Phi$ 的 eigenvectors 以及構成的 commutative group. 可以參考 [@grayToeplitzCirculant1971], excel article about Toeplitz matrix.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有一個 “trick” 就是用 Circulant matrix 取代 Toeplitz matrix by using cyclic shift to replace regular shift!&lt;/strong&gt;  因為 n » m, 實務上Toeplitz 和 Circulant matrix 得到的 $y$ 差異很小。但 Circulant matrix 好求解而且具有物理意義。&lt;/p&gt;

&lt;p&gt;Follow [@grayToeplitzCirculant1971] 的 notation on p.31, 我們用 $C$ 代替 $\Phi$.&lt;/p&gt;

&lt;p&gt;A $n\times n$ circulant matrix $C$ has the form 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
C=\left[\begin{array}{cccccc}
c_{0} &amp; c_{1} &amp; c_{2} &amp; &amp; \cdots &amp; c_{n-1} \\
c_{n-1} &amp; c_{0} &amp; c_{1} &amp; c_{2} &amp; &amp; \vdots \\
&amp; &amp; c_{n-1} &amp; c_{0} &amp; c_{1} &amp; \ddots &amp; \\
\vdots &amp; \ddots &amp; \ddots &amp; \ddots &amp; &amp; c_{2} \\
&amp; &amp; &amp; &amp; &amp; c_{1} \\
c_{1} &amp; \cdots &amp; &amp; c_{n-1} &amp; &amp; c_{0}
\end{array}\right] %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;circulant-matrix-eigenvalues-and-eigenvectors&quot;&gt;Circulant matrix eigenvalues and eigenvectors&lt;/h4&gt;
&lt;p&gt;The eigenvalues $\psi_m$ and the eigenvectors $y^{(m)}$ are the solution of
&lt;script type=&quot;math/tex&quot;&gt;C y = \psi y&lt;/script&gt;
我們引入一個 variable $\rho$, which is one of the n distinct complex root of unity ($\rho_m = e^{-2\pi i m/n}$, $m = 0, … n-1$), we have the eigenvalue and eigenvector
&lt;script type=&quot;math/tex&quot;&gt;\psi=\sum_{k=0}^{n-1} c_{k} \rho^{k}&lt;/script&gt; 
and 
&lt;script type=&quot;math/tex&quot;&gt;y=n^{-1 / 2}\left(1, \rho, \rho^{2}, \ldots, \rho^{n-1}\right)^{\prime}&lt;/script&gt;
帶入 $\rho_m$, we have eigenvalue $(m = 0, … n)$
&lt;script type=&quot;math/tex&quot;&gt;\psi_{m}=\sum_{k=0}^{n-1} c_{k} e^{-2 \pi i m k / n}&lt;/script&gt;
&lt;strong&gt;!!注意：$\psi_{m}$ is the DFT of $c_k$&lt;/strong&gt;, i.e. $\psi = DFT(c)$.  反之，$c = IDFT(\psi)$
&lt;script type=&quot;math/tex&quot;&gt;c_{m}= \frac{1}{n} \sum_{k=0}^{n-1} \psi_{k} e^{2 \pi i m k / n}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;$\psi_{m}$ 對應的 (column) eigenvector 
&lt;script type=&quot;math/tex&quot;&gt;y^{(m)}=\frac{1}{\sqrt{n}}\left(1, e^{-2 \pi i m / n}, \cdots, e^{-2 \pi i m(n-1) / n}\right)^{\prime}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;檢查幾個 eigenvalue. First, $m=0$ is the DC component of $c_k$
&lt;script type=&quot;math/tex&quot;&gt;\psi_{0}=\sum_{k=0}^{n-1} c_{k}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;對應的 (column) eigenvector
&lt;script type=&quot;math/tex&quot;&gt;y^{(0)}=\frac{1}{\sqrt{n}}\left(1, 1, \cdots, 1\right)^{\prime}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;帶入驗證  $ C y^{(0)} = \psi_{0} y^{(0)}  $.&lt;/p&gt;

&lt;p&gt;Next $m=1$ is the 1st fundamental component of $c_k$
&lt;script type=&quot;math/tex&quot;&gt;\psi_{1}=\sum_{k=0}^{n-1} c_{k} e^{-2 \pi i k / n}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;對應的 (column) eigenvector 
&lt;script type=&quot;math/tex&quot;&gt;y^{(1)}=\frac{1}{\sqrt{n}}\left(1, e^{-2 \pi i / n}, \cdots, e^{-2 \pi i (n-1) / n}\right)^{\prime}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Next $m=2$ is the 2nd fundamental component of $c_k$
&lt;script type=&quot;math/tex&quot;&gt;\psi_{2}=\sum_{k=0}^{n-1} c_{k} (e^{-2 \pi i k / n})^2&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;對應的 (column) eigenvector 
&lt;script type=&quot;math/tex&quot;&gt;y^{(2)}=\frac{1}{\sqrt{n}}\left(1, (e^{-2 \pi i / n})^2, \cdots, (e^{-2 \pi i (n-1) / n})^2\right)^{\prime}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;可以驗證  $ C y^{(m)} = \psi_{m} y^{(m)}  $.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我們用 one equation to summarize the results. 其實就是 $C$ 的 eigenvalue decomposition 如下。$\Psi$ 是 diagonal matrix with eigenvalues, 剛好就是 $C$ matrix 第一列 (row 1) 的 DFT 結果。&lt;/strong&gt;
&lt;script type=&quot;math/tex&quot;&gt;CU = U \Psi \quad\quad C = U \Psi U^{-1} = U \Psi U^{*}&lt;/script&gt;  where
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
U &amp;=\left[y^{(0)}\left|y^{(1)}\right| \cdots | y^{(n-1)}\right] \\
&amp;=n^{-1 / 2}\left[e^{-2 \pi i m k / n} ; m, k=0,1, \ldots, n-1\right]
\end{aligned} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
= n^{-1/2} \left[\begin{array}{cccccc}
1 &amp; 1 &amp; 1 &amp;  \cdots &amp; 1 \\
1 &amp; \omega &amp; \omega^{2}  &amp;  \cdots &amp; \omega^{n-1} \\
1 &amp; \omega^2 &amp; (\omega^{2})^2  &amp;  \cdots &amp; (\omega^{n-1})^2 \\
\vdots &amp; \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\
1 &amp; \omega^{n-1} &amp; (\omega^{2})^{n-1} &amp; \cdots &amp; (\omega^{n-1})^{n-1}
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
U^{-1} = U^{*} = n^{-1/2} \left[\begin{array}{cccccc}
1 &amp; 1 &amp; 1 &amp;  \cdots &amp; 1 \\
1 &amp; \bar{\omega} &amp; \bar{\omega}^{2}  &amp;  \cdots &amp; \bar{\omega}^{n-1} \\
1 &amp; \bar{\omega}^2 &amp; (\bar{\omega}^{2})^2  &amp;  \cdots &amp; (\bar{\omega}^{n-1})^2 \\
\vdots &amp; \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\
1 &amp; \bar{\omega}^{n-1} &amp; (\bar{\omega}^{2})^{n-1} &amp; \cdots &amp; (\bar{\omega}^{n-1})^{n-1}
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;with $\omega = e^{-2 \pi i / n}$ and $\bar{\omega} = \omega^{*} = e^{+2 \pi i / n}$&lt;/p&gt;

&lt;p&gt;Complex conjugate frequency sequence
另一種的順序是 complex conjugate (Nyquist) frequency sequence, 就是 [DC, +f, -f, +2f, -2f, …, AC]  如果 n 是偶數，AC = [1, -1, 1, -1…].  如果 n 是奇數，….&lt;/p&gt;

&lt;h4 id=&quot;equivariant-phi-is-circulant-matrix-for-discrete-convolution&quot;&gt;Equivariant: $\Phi$ is Circulant Matrix for Discrete Convolution&lt;/h4&gt;
&lt;p&gt;Given $\Phi = C$, a circulant matrix, 現在需要找到 equivariant group $T$ to make $\Phi(T x) = \Phi T x = T \Phi x = T \Phi(x)$.  答案是  $T_g= U Q U^{&lt;em&gt;}$ where $U$ and $U^{&lt;/em&gt;}$ 就是以上的 matrices (n 點分圓函數) and $Q$ is a diagonal matrix.&lt;/p&gt;

&lt;p&gt;注意 $U$ and $U^{&lt;em&gt;}$ 是 complex matrix, Q in general 也是 complex matrix.  但實際應用會限制 $T_g = U Q U^{&lt;/em&gt;}$ 必須是 real matrix.  因此會要求 Q matrix 滿足一些特性。因為 Q matrix 其實是另一個 circulant matrix 的 row 1 FFT 結果。&lt;/p&gt;

&lt;p&gt;In summary, circulant matrix 本身 forms a commutative group, i.e. $A B = B A = C$ (multiplication closure and commuting) is circulant matrix, $A^{-1}$ 也是 circulant matrix, 甚至 $A + B$ 也是 circulant matrix [@wikiCirculantMatrix2020].&lt;/p&gt;

&lt;p&gt;整理一下：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$y = \Phi(x) = h * x$ performs discrete convolution (i.e. 1D CNN) where $x$ and $y$ are input and output signals of n-dimension.  $h$ is the kernel filter of m dimension. 一般 n » m.  可以用 $n\times n$ Circulant matrix multiplication 近似 discrete convolution by zero padding, i.e. $y = C x$.  $C$ 是把 $h$ 放在 $C$ 的 row1, 再 cyclic right shift by 1 放在 row 2, and so on.  &lt;strong&gt;In summary, discrete convolution is equivalent to Circulant matrix multiplication.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;$n \times n$ Circulant matrices form a commutative group, $T_g$, i.e. $\Phi(T_g x) = T_g \Phi(x)$ as long as $T_g$ is a $n\times n$ Circulant matrix.  Actually, $\Phi \in T_g$.  $T_g$ is equivariant operation.&lt;/li&gt;
  &lt;li&gt;Circulant group 的 generating element is $g$ = [0, 1, 0…, 0; 0, 0, 1, …,0,; ….; 1, 0, 0, …, 0]‘ 代表 right cyclic shift by 1; $g^2 = g&lt;em&gt;g, g^k = g&lt;/em&gt;g&lt;em&gt;..&lt;/em&gt;g$. Therefore, $I, g^2, g^3, ..g^{n-1}$ 構成 basis for 所有 $n\times n$ Circulant matrix.  For any Circulant matrix by $[a_0, a_1, …, a_{n-1}] = a_0 I + a_1 g^2 + …, + a_{n-1} g^{n-1}$.  也就是說，Circulant matrix can be decomposed to translation matrix superposition.&lt;/li&gt;
  &lt;li&gt;Discrete convolution is therefore translation multiplication commutable =&amp;gt; translation equivariant, i.e. $\Phi ( T_g x) = T_g (\Phi x)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A discrete convolution example in appendix A.&lt;/p&gt;

&lt;h4 id=&quot;equivariant-phi-is-circulant-matrix-for-2d-discrete-convolution&quot;&gt;Equivariant: $\Phi$ is Circulant Matrix for 2D Discrete Convolution&lt;/h4&gt;
&lt;p&gt;$y(t) = h(t) * x(t)$ 可以直接推廣到 2D,  $y(u, v) = h(u, v) * x(u, v)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;因為 $u$ and $v$ are independent on the Cartesian coordinate.  注意這並不代表 $y, h, x$ are $u, v$ separable.&lt;/li&gt;
  &lt;li&gt;Circulant group 是兩個 Circulant group 的 &lt;strong&gt;direct sum&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Generator 是 $g_u$ and $g_v$.&lt;/li&gt;
  &lt;li&gt;The DFT core is exp(-2piinu/.) exp(-2pimv/.)&lt;/li&gt;
  &lt;li&gt;How about eigenvalue and eigenvectors?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;how-about-other-equivariant-for-1d-signal-processing&quot;&gt;How about other equivariant for 1D signal processing?&lt;/h4&gt;
&lt;p&gt;Mirror, scale equivariant?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\Phi(x)$ 
condition of Q?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;use-cohens-paper-notation-and-concept&quot;&gt;Use Cohen’s paper notation and concept&lt;/h2&gt;
&lt;p&gt;以上的推導太狹隘，接下來採用 Cohen’s paper notation and ideas.&lt;/p&gt;

&lt;h3 id=&quot;the-group-p4m-non-commutative-group&quot;&gt;The group $p4m$ (non-commutative group)&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g(m, r, u, v)=\left[\begin{array}{ccc}
(-1)^{m} \cos \left(\frac{r \pi}{2}\right) &amp; -(-1)^{m} \sin \left(\frac{r \pi}{2}\right) &amp; u \\
\sin \left(\frac{r \pi}{2}\right) &amp; \cos \left(\frac{r \pi}{2}\right) &amp; v \\
0 &amp; 0 &amp; 1
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;以上是 2D Cartesian coordinate (+1D depth) generates to 4D symmetry G space (+1D depth).  分為兩種 case: (1) input 仍然是 3D tensor, but output is converted to 5D tensor.  僅用於神經網絡的第一層。之後就轉換成 (2) both input/output 都是 5D tensors.  原文有簡化版 p4 (no mirror reflection) and 2D translation only.&lt;/p&gt;

&lt;p&gt;此處考慮更簡單的 case, 1D translation and 1D translation + mirror reflection.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g(m, u)=\left[\begin{array}{ccc}
(-1)^{m} &amp; u \\
0 &amp; 1
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
g^{-1}(m, u)=\left[\begin{array}{ccc}
(-1)^{m} &amp; (-u)(-1)^m \\
0 &amp; 1
\end{array}\right] %]]&gt;&lt;/script&gt;

&lt;p&gt;Next step:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Function f(x)&lt;/li&gt;
  &lt;li&gt;Group operation on f(x) is 
 $L_g f(x) = f(g^{-1}x)$.  原因很簡單，就是在 $x‘=gx$ 會得到原來的函數。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;考慮 CNN convolution 函數，定義如下。$x, y \in Z^2$
&lt;script type=&quot;math/tex&quot;&gt;\begin{array}{l}
{\left[f * \psi^{i}\right](x)=\sum_{y \in \mathbb{Z}^{2}} \sum_{k=1}^{K^{l}} f_{k}(y) \psi_{k}^{i}(x-y)} \\
{\left[f \star \psi^{i}\right](x)=\sum_{y \in \mathbb{Z}^{2}} \sum_{k=1}^{K^{l}} f_{k}(y) \psi_{k}^{i}(y-x)}
\end{array}&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;推廣到 G-CNN convolution.  $g, h \in G$
&lt;script type=&quot;math/tex&quot;&gt;\begin{array}{l}
{\left[f * \psi^{i}\right](g)=\sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(h^{-1}g)} \\
{\left[f \star \psi^{i}\right](g)=\sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(g^{-1}h)}
\end{array}&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上式是 forward pass 的 convolution ($\ast$).  下式是 backward pass 的 correlation ($\star$).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Combine 2 and 3, $L_u &lt;a href=&quot;g&quot;&gt;f \star \psi&lt;/a&gt; = &lt;a href=&quot;u^{-1}g&quot;&gt;f \star \psi&lt;/a&gt; \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}((u^{-1}g)^{-1}h) \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(g^{-1}uh)   \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(u^{-1}h) \psi_{k}^{i}(g^{-1}h) \  = &lt;a href=&quot;g&quot;&gt;[L_u f] \star \psi&lt;/a&gt;$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Combine 2 and 3, $L_u &lt;a href=&quot;g&quot;&gt;f * \psi&lt;/a&gt; = &lt;a href=&quot;u^{-1}g&quot;&gt;f * \psi&lt;/a&gt; \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(h^{-1} (u^{-1}g)) \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(h^{-1}u^{-1}g)   \ = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(u^{-1}h) \psi_{k}^{i}(h^{-1}g) \  = &lt;a href=&quot;g&quot;&gt;[L_u f] * \psi&lt;/a&gt;$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我們用一個 1D convolution 來驗證。 
Example: g = [(-1)^m, u; 0, 1]   g^-1 = [(-1)^m, -u*(-1)^m; 0 , 1]
&lt;script type=&quot;math/tex&quot;&gt;[f \star \psi^{i}](g) = [f \star \psi^{i}](x, m) = \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(h) \psi_{k}^{i}(g^{-1}h) \\
= \sum_{h \in G} \sum_{k=1}^{K^{l}} f_{k}(y) \psi_{k}^{i}((-1)^{m}(y-x))\\ \ne \sum_{y \in \mathbb{Z}^{2}} \sum_{k=1}^{K^{l}} f_{k}(y) (\psi_{k}^{i}(x-y) +  \psi_{k}^{i}(y-x) )&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Does it make sense?   If $\psi$ is an odd function, $f \star \psi^{i} =0$?
No, g = (x, m) =&amp;gt; m should be kept instead of disappear after summation!!&lt;/p&gt;

&lt;p&gt;Let’s look at another example, polar transform. [@estevesPOLARTRANSFORMER2018]&lt;/p&gt;

&lt;h3 id=&quot;polar-coordinate&quot;&gt;Polar Coordinate&lt;/h3&gt;

&lt;p&gt;A similarity transformation, i.e. conformal mapping, 旋轉(R)+scaling(s)+平移(t), $\rho \in $ SIM(2), acts on a point in $x \in R^2$ by
&lt;script type=&quot;math/tex&quot;&gt;\rho x \to s Rx + t \quad s \in R^+, R \in SO(2), t \in R^2&lt;/script&gt;
where &lt;em&gt;SO(2)&lt;/em&gt; is the rotation group.&lt;/p&gt;

&lt;p&gt;Equivariance to SIM(2) is achieved by (1) learning the center of the dilated rotation, (2) shifting the original image accordingly then (3) transforming the image to canonical coordinates.&lt;/p&gt;

&lt;p&gt;Q1: How to find the center of rotation? Need an origin predictor.&lt;/p&gt;

&lt;p&gt;Transformation of the image $L_t I = I(t-t_o)$ reduces the SIM(2) deformation to a dilated-rotation if $t_o$ is the true translation. After centering, we perform $SO(2) \times R^+$ convolutions on the new image $I_o = I(x-t_o)$.&lt;/p&gt;

&lt;p&gt;Layer 1 convolution 變成：
&lt;script type=&quot;math/tex&quot;&gt;f(r)=\int_{x \in \mathbb{R}^{2}} I_{o}(x) \phi\left(r^{-1} x\right) d x&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{s} f(s) \phi\left(s^{-1} r\right) d s=\int_{s} \lambda(\xi, \theta) \phi\left(\xi_{r}-\xi, \theta_{r}-\theta\right) d \xi d \theta&lt;/script&gt;

&lt;p&gt;In summary,
本文 (polar transformation) 比較像是 coordinate transformation instead of adding group dimension.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;No. 從原始的 $t \in R^2$, 多了 rotation and scale dimension $SO(2) \times R^+$.&lt;/li&gt;
  &lt;li&gt;But yes, 就 convolution 而言，feature extraction 已經不是 (x,y) convolution, 而是 $\epsilon, \theta$&lt;/li&gt;
  &lt;li&gt;location information 仍然存在，但用 origin predictor 取代 (x,y) convolution learning.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;media/15884328451601/15890439753317.jpg&quot; alt=&quot;-w907&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;equivariant-phi-is-cnn-and-bijective-reversible-stride1-ignore-boundary&quot;&gt;Equivariant: $\Phi$ is CNN and Bijective (reversible, stride=1, ignore boundary)&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;(Translation) Equivariant:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;= T’y = T’f(x)&lt;/strong&gt; where T’ is another coordinate which could be different from T because of scaling, etc.   But both T and T’ are linear operators. This orange part is the crucial step assuming translation equivariant!!   However, T is translation equivariant, but NOT rotational equivariant. 
y’ = T’y = T’ f(x) = T’ f(T^-1 x’)  assuming linear inversible operation.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Use [@cohenGroupEquivariant2019] notation $f \to \Phi$ and $T \to T_g$ 
Original output feature is $\Phi(x)$, where $\Phi$ can be a nonlinear (complicated) mapping, such as convolution + pooling + ReLU.&lt;/p&gt;

&lt;p&gt;Given input image x is transformed by $T_g$ operator/transform, new output feature is $\Phi(T_g x)$.
如果具有 translation equivariant =&amp;gt; $\Phi(T_g x) = T’_g \Phi(x)$ where T’_g 是同樣的 translation operator/transform, but may have different scaling factor (stride &amp;gt; 1).&lt;/p&gt;

&lt;p&gt;所以 $T_g$ and $T’_g$ 需要有什麼特性？只需要 linear, i.e. $T(gh) = T(g)T(h)$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果 $T’_g = I$ for all g&lt;/strong&gt;, 是 special case, 稱為 invariant.  這和一般物理定義的 invariant 似乎不同?  對於&lt;strong&gt;深度學習 invariant 會失去 spatial information, $T’_g$ 而變得無用&lt;/strong&gt;, equivariance 是更有用。&lt;/p&gt;

&lt;p&gt;另一個極端是沒有 equivariant, 也就是 $\Phi(T_g x)$ 和 $\Phi(x)$ 沒有簡單的 linear mapping, 例如 Multi-layer Perceptron (MLP).&lt;/p&gt;

&lt;p&gt;Paper 另外一段話如下，似乎和 invariant 相抵觸? No, 是擴充到 non-injective (降維) network.
A network $\Phi$ &lt;strong&gt;can be&lt;/strong&gt; non-injective, meaning that non-identical vectors $x$ and $y$ in the input space become identical in the output space.  (for example, two instances of a face may be mapped onto a single vector indicating the presence of any face, e.g. 人臉偵測而非識別，兩個不同的人臉對應到相同的 feature map or bounding box).  If $\Phi$ is equivariant, then the G-transformed inputs $T_g x$ and $T_g y$ must also mapped to the same output.  Their “sameness” is preserved under symmetry transformations.&lt;/p&gt;

&lt;p&gt;數學表示：
Non-injective network: $\Phi(x) = \Phi(y)$ with $x \ne y$ 
If $\Phi$ is equivariant, then the G-transform (symmetry transform) has:
$\Phi(T_g x)  = T’_g \Phi(x) = T’_g \Phi(y) = \Phi(T_g y)$ with $x \ne y$&lt;/p&gt;

&lt;p&gt;g represents general group, in the paper considering three groups: Z2, p4, p4m.  Conclusion.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;On MNIST and CIFAR, G-CNN performs better than CNN at about same parameter number.&lt;/li&gt;
  &lt;li&gt;G-CNN also benefit from data augment.&lt;/li&gt;
  &lt;li&gt;Step 1: G-CNN to include translation, rotation, mirror on grid&lt;/li&gt;
  &lt;li&gt;Step 2: G-CNN on hexagon grid&lt;/li&gt;
  &lt;li&gt;Step 3: On 3D sphere and use G-FFT to compute sphere convolution for 3D application.&lt;/li&gt;
  &lt;li&gt;Step 4: Gauge CNN?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CNN, pooling, ReLU are translation equivariant (up to edge effect); but MLP is &lt;em&gt;NOT&lt;/em&gt; translation equivariant.&lt;/p&gt;

&lt;p&gt;Translation Equivariant:  There is a function (e.g. CNN)&lt;/p&gt;

&lt;p&gt;1D =&amp;gt; 2D convolution =&amp;gt; high dimension tensor convolution&lt;/p&gt;

&lt;p&gt;Step 1: Define the network operator $\Phi$
 Step 2: Find the commuting operator $T$, actually, a commutative group $T_g$.  $\Phi$ 可以視為 $T_g$ 的一個 element.
 Step 3: Find the group generator for the commutative group.&lt;/p&gt;

&lt;p&gt;What is the fundamental element of a group? =&amp;gt; generator &amp;lt;g, ..&amp;gt;!
所有的 group element 都可以從 generator &amp;lt;g, ..&amp;gt; 產生。
All Abelian group is isomorphic to direct sum of primed cycle group =&amp;gt; generator g, gg, ggg, …&lt;/p&gt;

&lt;h3 id=&quot;group-examples&quot;&gt;Group Examples&lt;/h3&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;Bronstein, Michael M., Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre
Vandergheynst. 2017. “Geometric Deep Learning: Going Beyond Euclidean
Data.” &lt;em&gt;IEEE Signal Processing Magazine&lt;/em&gt; 34 (4): 18–42.
&lt;a href=&quot;https://doi.org/10.1109/MSP.2017.2693418&quot;&gt;https://doi.org/10.1109/MSP.2017.2693418&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Cohen, Taco S, T S Cohen, and Uva Nl. 2019. “Group Equivariant Convolutional Networks,” 10.&lt;/p&gt;

&lt;p&gt;Cohen, Taco S., Maurice Weiler, Berkay Kicanaoglu, and Max Welling.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;“Gauge Equivariant Convolutional Networks and the Icosahedral
CNN,” May. &lt;a href=&quot;http://arxiv.org/abs/1902.04615&quot;&gt;http://arxiv.org/abs/1902.04615&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pavlus, John. 2020. “An Idea from Physics Helps AI See in Higher
Dimensions.” Quanta Magazine. January 9, 2020.
&lt;a href=&quot;https://www.quantamagazine.org/an-idea-from-physics-helps-ai-see-in-higher-dimensions-20200109/&quot;&gt;https://www.quantamagazine.org/an-idea-from-physics-helps-ai-see-in-higher-dimensions-20200109/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;prism. 2019. 「Group Equivariant CNN to Spherical CNNs: 從群等變卷積網絡到球面卷積網絡.」 知乎專欄. 2019.
&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34042888&quot;&gt;https://zhuanlan.zhihu.com/p/34042888&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Winkels, Marysia, and Taco S. Cohen. 2018. 「3D G-CNNs for Pulmonary
Nodule Detection,」 April. &lt;a href=&quot;http://arxiv.org/abs/1804.04656&quot;&gt;http://arxiv.org/abs/1804.04656&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;XinZhiYuan. 2020. 「Geometrical Deep Learning 受愛因斯坦啟示：讓AI擺脫平面看到更高的維度.」 2020. &lt;a href=&quot;https://kknews.cc/tech/gpkgx3e.html&quot;&gt;https://kknews.cc/tech/gpkgx3e.html&lt;/a&gt;.&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="python" /><category term="quantization" /><category term="model compression" /><category term="pruning" /><category term="distillation" /><summary type="html">Math AI - G-CNN (Group + CNN) Where is group theory (G-CNN) + Curved Space (Spherical CNN)</summary></entry><entry><title type="html">增進工程師效率 Julia Linear Algebra</title><link href="http://localhost:4000/2020/04/21/matrix-julia/" rel="alternate" type="text/html" title="增進工程師效率 Julia Linear Algebra" /><published>2020-04-21T00:00:00+08:00</published><updated>2020-04-21T00:00:00+08:00</updated><id>http://localhost:4000/2020/04/21/matrix-julia</id><content type="html" xml:base="http://localhost:4000/2020/04/21/matrix-julia/">&lt;h1 id=&quot;use-julia-for-linear-algebra&quot;&gt;Use Julia for Linear Algebra&lt;/h1&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearAlgebra&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;x&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3×3 Array{Int64,2}:
 1  2  3
 2  3  4
 4  5  6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;eigvals&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3-element Array{Float64,1}:
 10.830951894845311     
 -0.8309518948453025    
  1.0148608166285778e-16
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;det&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0.0:0.01001001001001001:10.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PyPlot&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/media/output_6_0.png&quot; alt=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1-element Array{PyCall.PyObject,1}:
 PyObject &amp;lt;matplotlib.lines.Line2D object at 0x140288630&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;discrete-convolution-using-circulant-matrix&quot;&gt;Discrete Convolution Using Circulant Matrix&lt;/h1&gt;
&lt;p&gt;$y[t] = h[t] * x[t]$  where $x[t] = [1, 2, 3, 0, -3, -1, 1, -2]$, $h[t] = [1, 3, 1]$&lt;/p&gt;

&lt;p&gt;Use Julia LinearAlgebra for matrix/vector operation.  &lt;br /&gt;
Use two space for new line.&lt;br /&gt;
Use DSP.conv to perform discrete convolution.  &lt;br /&gt;
x: length=8; h: length=3; y: length=8+3-1=10 (padding two 0’s at x)&lt;/p&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pkg&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pkg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;SpecialMatrices&quot;&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearAlgebra&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SpecialMatrices&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DSP&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FFTW&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[32m[1m Resolving[22m[39m package versions...
[32m[1m  Updating[22m[39m `~/.julia/environments/v1.1/Project.toml`
[90m [no changes][39m
[32m[1m  Updating[22m[39m `~/.julia/environments/v1.1/Manifest.toml`
[90m [no changes][39m
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;x&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;x&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;];&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×12 Adjoint{Int64,Array{Int64,1}}:
 1  5  10  11  0  -10  -5  0  -5  -2  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;circulant-matrix-multiplication-approximates-dicrete-convolution&quot;&gt;Circulant Matrix Multiplication Approximates Dicrete Convolution&lt;/h2&gt;
&lt;p&gt;First extend $h[t]$ by padding seven 0’s (10-3=7).&lt;br /&gt;
Use SpecialMatrices.Cirlulant to cyclic shift $h[t]$ and form a 10x10 Circulant matrix $\Phi$.
Use SpecialMatrices.Matrix to convert special matrix type to normal Array&lt;/p&gt;

&lt;p&gt;$y = \Phi x$&lt;/p&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Matrix&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Circulant&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Int64,2}:
 1  0  0  0  0  0  0  0  1  3
 3  1  0  0  0  0  0  0  0  1
 1  3  1  0  0  0  0  0  0  0
 0  1  3  1  0  0  0  0  0  0
 0  0  1  3  1  0  0  0  0  0
 0  0  0  1  3  1  0  0  0  0
 0  0  0  0  1  3  1  0  0  0
 0  0  0  0  0  1  3  1  0  0
 0  0  0  0  0  0  1  3  1  0
 0  0  0  0  0  0  0  1  3  1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 1  5  10  11  0  -10  -5  0  -5  -2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;find-eigenvalues-and-eigenvectors-of-phi&quot;&gt;Find eigenvalues and eigenvectors of $\Phi$&lt;/h2&gt;
&lt;p&gt;$\Phi$ is a Circulant matrix, its eigenvalue array s[n] is “equivalent” to DFT($h[t]$), sort of,&lt;br /&gt;
up to frequency sequence difference.&lt;/p&gt;

&lt;p&gt;For example, DFT frequency sequence is always defined counter clockwise on the unit circle (0,1,2,..,9) for n=10.&lt;br /&gt;
The eigenvalue/eigenvector decomposition: $\Phi = U P U^{*}$ 
In this eigvals implementation frequency is defined as conjugate first on the unit circle (0,1,9,2,8…,5)&lt;/p&gt;

&lt;p&gt;The first eigenvalue of $\Phi$ corresponds to Nyquist frequency = 0 (DC: 1+1+3=5)&lt;br /&gt;
The last eigenvalue of $\Phi$ corresponds to Nyquist frequency = $\pi$ (highest AC: 1+1-3=-1)&lt;/p&gt;

&lt;p&gt;Its eigenvector array P cosists of eigenvectors in column sequences.&lt;br /&gt;
The first column corresponds to DC eigenvector: [1, 1, …, 1]’.&lt;br /&gt;
The last column corresponds to DC eigenvector: [1, -1, …, -1]’.&lt;br /&gt;
&lt;img src=&quot;attachment:image.png&quot; alt=&quot;image.png&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvals&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10-element Array{Complex{Float64},1}:
                 5.0 + 0.0im               
  3.7360679774997863 + 2.7144122731725697im
  3.7360679774997863 - 2.7144122731725697im
   1.118033988749894 + 3.440954801177931im 
   1.118033988749894 - 3.440954801177931im 
 -0.7360679774997894 + 2.265384296592988im 
 -0.7360679774997894 - 2.265384296592988im 
 -1.1180339887498945 + 0.8122992405822655im
 -1.1180339887498945 - 0.8122992405822655im
 -1.0000000000000002 + 0.0im               
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×1 Adjoint{Complex{Float64},Array{Complex{Float64},2}}:
                 5.0 - 0.0im               
    3.73606797749979 + 2.714412273172573im 
   1.118033988749895 + 3.4409548011779334im
 -0.7360679774997898 + 2.2653842965929876im
  -1.118033988749895 + 0.8122992405822659im
                -1.0 - 0.0im               
  -1.118033988749895 - 0.8122992405822659im
 -0.7360679774997898 - 2.2653842965929876im
   1.118033988749895 - 3.4409548011779334im
    3.73606797749979 - 2.714412273172573im 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Diagonal&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Diagonal{Complex{Float64},Array{Complex{Float64},1}}:
 5.0+0.0im          ⋅          …           ⋅                ⋅    
     ⋅      3.73607+2.71441im              ⋅                ⋅    
     ⋅              ⋅                      ⋅                ⋅    
     ⋅              ⋅                      ⋅                ⋅    
     ⋅              ⋅                      ⋅                ⋅    
     ⋅              ⋅          …           ⋅                ⋅    
     ⋅              ⋅                      ⋅                ⋅    
     ⋅              ⋅                      ⋅                ⋅    
     ⋅              ⋅             -1.11803-0.812299im       ⋅    
     ⋅              ⋅                      ⋅           -1.0+0.0im
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigvecs&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Complex{Float64},2}:
 1.0+0.0im   0.809+0.588im   0.809-0.588im  …  -0.809-0.588im   1.0+0.0im
 1.0+0.0im     1.0+0.0im       1.0-0.0im          1.0-0.0im    -1.0+0.0im
 1.0+0.0im   0.809-0.588im   0.809+0.588im     -0.809+0.588im   1.0+0.0im
 1.0+0.0im   0.309-0.951im   0.309+0.951im      0.309-0.951im  -1.0+0.0im
 1.0+0.0im  -0.309-0.951im  -0.309+0.951im      0.309+0.951im   1.0+0.0im
 1.0+0.0im  -0.809-0.588im  -0.809+0.588im  …  -0.809-0.588im  -1.0+0.0im
 1.0+0.0im    -1.0-0.0im      -1.0+0.0im          1.0-0.0im     1.0+0.0im
 1.0+0.0im  -0.809+0.588im  -0.809-0.588im     -0.809+0.588im  -1.0+0.0im
 1.0+0.0im  -0.309+0.951im  -0.309-0.951im      0.309-0.951im   1.0+0.0im
 1.0+0.0im   0.309+0.951im   0.309-0.951im      0.309+0.951im  -1.0+0.0im
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;U_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U_b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Complex{Float64},2}:
    1.0+0.0im       1.0-0.0im    …     1.0+0.0im       1.0-0.0im  
  0.809-0.588im     1.0-0.0im       -0.309-0.951im   0.309-0.951im
  0.809+0.588im     1.0+0.0im       -0.309+0.951im   0.309+0.951im
 -0.809-0.588im   0.309-0.951im      0.309+0.951im  -0.809+0.588im
 -0.809+0.588im   0.309+0.951im      0.309-0.951im  -0.809-0.588im
 -0.809+0.588im  -0.309-0.951im  …   0.309-0.951im   0.809+0.588im
 -0.809-0.588im  -0.309+0.951im      0.309+0.951im   0.809-0.588im
 -0.809-0.588im     1.0+0.0im        0.309-0.951im   0.309+0.951im
 -0.809+0.588im     1.0-0.0im        0.309+0.951im   0.309-0.951im
    1.0-0.0im      -1.0+0.0im          1.0+0.0im      -1.0-0.0im  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U_b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# U_b is the same as conjugate transpose&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Complex{Float64},2}:
  0.0+0.0im   0.0-0.0im   0.0-0.0im  …  -0.0-0.0im  -0.0+0.0im   0.0-0.0im
  0.0+0.0im  -0.0-0.0im   0.0-0.0im      0.0+0.0im   0.0+0.0im   0.0+0.0im
  0.0-0.0im  -0.0+0.0im   0.0+0.0im     -0.0+0.0im   0.0-0.0im   0.0-0.0im
  0.0+0.0im  -0.0+0.0im  -0.0-0.0im      0.0-0.0im  -0.0+0.0im  -0.0+0.0im
  0.0-0.0im  -0.0-0.0im  -0.0+0.0im     -0.0+0.0im  -0.0-0.0im  -0.0-0.0im
  0.0-0.0im   0.0+0.0im   0.0+0.0im  …   0.0-0.0im  -0.0-0.0im   0.0+0.0im
  0.0+0.0im   0.0-0.0im   0.0-0.0im     -0.0+0.0im  -0.0+0.0im   0.0-0.0im
  0.0+0.0im  -0.0+0.0im   0.0-0.0im      0.0-0.0im   0.0-0.0im  -0.0+0.0im
  0.0+0.0im  -0.0-0.0im   0.0+0.0im      0.0+0.0im  -0.0+0.0im   0.0-0.0im
 -0.0-0.0im   0.0+0.0im  -0.0+0.0im     -0.0-0.0im   0.0+0.0im   0.0-0.0im
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Phi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;U_b&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# verify U*P*U_b is the eigen value decompostion of Φ&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Phi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Float64,2}:
  1.0  -0.0   0.0   0.0   0.0   0.0   0.0  -0.0   1.0   3.0
  3.0   1.0   0.0   0.0  -0.0  -0.0  -0.0   0.0  -0.0   1.0
  1.0   3.0   1.0   0.0   0.0   0.0   0.0   0.0  -0.0  -0.0
  0.0   1.0   3.0   1.0   0.0   0.0   0.0  -0.0  -0.0   0.0
  0.0   0.0   1.0   3.0   1.0   0.0   0.0  -0.0  -0.0   0.0
  0.0   0.0   0.0   1.0   3.0   1.0  -0.0   0.0   0.0   0.0
  0.0   0.0   0.0   0.0   1.0   3.0   1.0   0.0   0.0   0.0
  0.0   0.0   0.0  -0.0  -0.0   1.0   3.0   1.0  -0.0   0.0
 -0.0   0.0   0.0  -0.0   0.0   0.0   1.0   3.0   1.0  -0.0
  0.0   0.0  -0.0   0.0   0.0   0.0   0.0   1.0   3.0   1.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;commutative-group---translation-equivariant&quot;&gt;Commutative Group - Translation Equivariant&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Discrete convolution is equivalent to Circulant matrix multiplication.&lt;/li&gt;
  &lt;li&gt;Circulant matrix is itself commutative/Abelian group.&lt;/li&gt;
  &lt;li&gt;All Cirulant matrix multiplication can be decomposed into translation matrix multiplication’s superposition.&lt;/li&gt;
  &lt;li&gt;Discrete convolution is therefore translation multiplication commutable =&amp;gt; translation equivariant&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# Random matrix multiplication does NOT commutate with Circulant matrix&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Float64,2}:
 -1.58559   -0.237127  -0.129967  …   0.066688  -1.72504    -1.40459 
  1.04033    1.08089    0.34026      -0.782441  -1.91891    -1.63573 
  3.35632    0.831891   0.805718     -0.849477   1.18107     0.183805
  0.815998  -1.54383   -0.38105      -1.00838   -0.141359   -0.176457
 -0.915783   0.225814  -1.14518       0.5001     0.128517    1.68327 
 -2.07181    1.04074   -2.12622   …   1.62098    0.348925    1.07887 
  0.313094   1.84738   -0.894152      0.282517  -2.32041    -0.039078
  1.11406   -0.71119   -1.059        -0.981632  -0.0110641   0.999691
  1.42449   -1.50675   -1.53478       1.06594    0.590891    2.41234 
 -2.2159    -2.33044   -1.29612       0.626618  -0.119957    0.743334
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Tg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Circulant&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Verify Circulant matrix multiplication is a commutative group&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Circulant{Int64}:
  1  10   9   8   7   6   5   4   3   2
  2   1  10   9   8   7   6   5   4   3
  3   2   1  10   9   8   7   6   5   4
  4   3   2   1  10   9   8   7   6   5
  5   4   3   2   1  10   9   8   7   6
  6   5   4   3   2   1  10   9   8   7
  7   6   5   4   3   2   1  10   9   8
  8   7   6   5   4   3   2   1  10   9
  9   8   7   6   5   4   3   2   1  10
 10   9   8   7   6   5   4   3   2   1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Int64,2}:
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
 0  0  0  0  0  0  0  0  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Circulant&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Circulant matrix group generator: right cyclic shift by 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Circulant{Int64}:
 0  0  0  0  0  0  0  0  0  1
 1  0  0  0  0  0  0  0  0  0
 0  1  0  0  0  0  0  0  0  0
 0  0  1  0  0  0  0  0  0  0
 0  0  0  1  0  0  0  0  0  0
 0  0  0  0  1  0  0  0  0  0
 0  0  0  0  0  1  0  0  0  0
 0  0  0  0  0  0  1  0  0  0
 0  0  0  0  0  0  0  1  0  0
 0  0  0  0  0  0  0  0  1  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# right cyclic shift by 2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Int64,2}:
 0  0  0  0  0  0  0  0  1  0
 0  0  0  0  0  0  0  0  0  1
 1  0  0  0  0  0  0  0  0  0
 0  1  0  0  0  0  0  0  0  0
 0  0  1  0  0  0  0  0  0  0
 0  0  0  1  0  0  0  0  0  0
 0  0  0  0  1  0  0  0  0  0
 0  0  0  0  0  1  0  0  0  0
 0  0  0  0  0  0  1  0  0  0
 0  0  0  0  0  0  0  1  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Matrix&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# Verify Circulant Tg is decomposed into group generator superposition&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10×10 Array{Float64,2}:
  1.0  10.0   9.0   8.0   7.0   6.0   5.0   4.0   3.0   2.0
  2.0   1.0  10.0   9.0   8.0   7.0   6.0   5.0   4.0   3.0
  3.0   2.0   1.0  10.0   9.0   8.0   7.0   6.0   5.0   4.0
  4.0   3.0   2.0   1.0  10.0   9.0   8.0   7.0   6.0   5.0
  5.0   4.0   3.0   2.0   1.0  10.0   9.0   8.0   7.0   6.0
  6.0   5.0   4.0   3.0   2.0   1.0  10.0   9.0   8.0   7.0
  7.0   6.0   5.0   4.0   3.0   2.0   1.0  10.0   9.0   8.0
  8.0   7.0   6.0   5.0   4.0   3.0   2.0   1.0  10.0   9.0
  9.0   8.0   7.0   6.0   5.0   4.0   3.0   2.0   1.0  10.0
 10.0   9.0   8.0   7.0   6.0   5.0   4.0   3.0   2.0   1.0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# Φ and Tg are commutative on input signal x as expected&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 0  0  0  0  0  0  0  0  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# normal discrete convolution&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 1  5  10  11  0  -10  -5  0  -5  -2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# group generator causes discrete convolution right cyclic translation&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 -2  1  5  10  11  0  -10  -5  0  -5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# group generator's action on x[t] is to right cyclic shift by 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 0  1  2  3  0  -3  -1  1  -2  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# discrete convolution of the right cyclic shift signal&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 -2  1  5  10  11  0  -10  -5  0  -5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Φ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;x&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;x&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# discrete convolution is translation (i.e. g or g*g or g*g*g ...) eqivaraint (commutative)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1×10 Adjoint{Int64,Array{Int64,1}}:
 0  0  0  0  0  0  0  0  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-julia highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Allen Lu (from John Doe)</name></author><summary type="html">Use Julia for Linear Algebra</summary></entry><entry><title type="html">Edge AI Trilogy III - Model Compression</title><link href="http://localhost:4000/ai/2020/04/05/EdgeAI-Compression/" rel="alternate" type="text/html" title="Edge AI Trilogy III - Model Compression" /><published>2020-04-05T16:29:08+08:00</published><updated>2020-04-05T16:29:08+08:00</updated><id>http://localhost:4000/ai/2020/04/05/EdgeAI-Compression</id><content type="html" xml:base="http://localhost:4000/ai/2020/04/05/EdgeAI-Compression/">&lt;h1 id=&quot;edge-ai-trilogy-iii---model-compression&quot;&gt;Edge AI Trilogy III - Model Compression&lt;/h1&gt;

&lt;p&gt;Edge AI 三部曲的最終篇是 model compression.  之後還會有番外篇 on advance topics such as NAS, etc.  為什麼 model compression 放在最終篇？可以用 Han Song 的 deep compression [@hanDeepCompression2016; @hanLearningBoth2015] 為例。下圖架構正好對應三部曲：pruning, quantization, and (parameter) compression.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15842339623232.jpg&quot; alt=&quot;-w687&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基本上 parameter compression 可以收割之前 sparsity, quantization, weight sharing 帶來的 storage and memory bandwidth reduction (35x-49x) 的好處。當然隨著 parameter reduction, 額外還有 computation and energy reduction 的好處，例如 zero-skipping for sparsity 和 low bitwidth MAC computation for quantization and weight sharing.&lt;/p&gt;

&lt;p&gt;Model compression 包含 parameter compression 以及其他的技巧減少 parameter, 甚至改變 model structure。最後的 model size (in MB) and MAC (in GFlop) 就是 “moment of the truth”.  就像 SNR or BER 是通訊系統的整體檢驗。除了 parameter pruning (sparsity) and sharing (clustering and quantizing) 之外，[@chengSurveyModel2019] 把 model compression 作法分為四類：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Theme Name&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Applications&lt;/th&gt;
      &lt;th&gt;Details&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Parameter pruning and sharing&lt;/td&gt;
      &lt;td&gt;Reducing redundant parameters not sensitive to the performance&lt;/td&gt;
      &lt;td&gt;CONV and FC layer&lt;/td&gt;
      &lt;td&gt;Robust to various settings, can achieve good performance, support both train from scratch and pre-trained model&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Low-rank factorization&lt;/td&gt;
      &lt;td&gt;Using matrix/tensor decomposition to estimate the informative parameters&lt;/td&gt;
      &lt;td&gt;CONV and FC layer&lt;/td&gt;
      &lt;td&gt;Standardized pipeline, easily to implement, support both train from scratch and pre-trained model&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transferred/compact convolutional filters&lt;/td&gt;
      &lt;td&gt;Designing special structural convolutional filters to save parameters&lt;/td&gt;
      &lt;td&gt;CONV layer only&lt;/td&gt;
      &lt;td&gt;Algorithms are dependent on applications, usually achieve good performance, only support train from scratch&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Knowledge distillation&lt;/td&gt;
      &lt;td&gt;Training a compact neural network with distilled knowledge of a large model&lt;/td&gt;
      &lt;td&gt;CONV and FC layer&lt;/td&gt;
      &lt;td&gt;Model performances are sensitive to applications and network structure only support train from scratch&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Another paper 提出的 model compression 分類 [@kuzminTaxonomyEvaluation2019].&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SVD-based methods (low rank)&lt;/li&gt;
  &lt;li&gt;Tensor decomposition-based methods (low rank)&lt;/li&gt;
  &lt;li&gt;Pruning methods&lt;/li&gt;
  &lt;li&gt;Compression ratio selection method&lt;/li&gt;
  &lt;li&gt;Loss-aware compression&lt;/li&gt;
  &lt;li&gt;Probabilistic compression&lt;/li&gt;
  &lt;li&gt;Efficient architecture design&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another good review paper from Purdue. [@goelSurveyMethods2020]&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Technique&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Advantages&lt;/th&gt;
      &lt;th&gt;Disadvantages&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Quantization and Pruning&lt;/td&gt;
      &lt;td&gt;Reduces precision/completely removes the redundant parameters and connections from a DNN.&lt;/td&gt;
      &lt;td&gt;Negligible accuracy loss with small model size. Highly efficient arithmetic operations.&lt;/td&gt;
      &lt;td&gt;Difficult to implement on CPUs and GPUs because of matrix sparsity. High training costs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Filter Compression and Matrix Factorization&lt;/td&gt;
      &lt;td&gt;Decreases the size of DNN filters and layers to improve efficiency.&lt;/td&gt;
      &lt;td&gt;High accuracy. Compatible with other optimization techniques.&lt;/td&gt;
      &lt;td&gt;Compact convolutions can be memory inefficient. Matrix factorization is computationally expensive.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Network Architecture Search&lt;/td&gt;
      &lt;td&gt;Automatically finds a DNN architecture that meets performance and accuracy requirements on a target device.&lt;/td&gt;
      &lt;td&gt;State-of-the-art accuracy with low energy consumption.&lt;/td&gt;
      &lt;td&gt;Prohibitively high training costs.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Knowledge Distillation&lt;/td&gt;
      &lt;td&gt;Trains a small DNN with the knowledge of a larger DNN to reduce model size.&lt;/td&gt;
      &lt;td&gt;Low computation cost with few DNN parameters.&lt;/td&gt;
      &lt;td&gt;Strict assumptions on DNN structure. Only compatible with softmax outputs.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Model =&amp;gt; Data =&amp;gt; Memory?? (from Huawei’s talk)&lt;/p&gt;

&lt;h2 id=&quot;my-classification&quot;&gt;My classification:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Level 1&lt;/strong&gt;:  Compression Without changing the network layer and architecture, i.e. weight compression including pruning (weight = 0), quantization (reduce weight bitwidth), weight sharing, etc.  可以到達 10x-50x compression for large network (e.g. resnet, alexnet, etc.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 2&lt;/strong&gt;:  Modify network architecture based on some basic rules (matrix/tensor decomposition), network fusion, etc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 3&lt;/strong&gt;: Change the network architecture completely.  Knowledge transfer (KT) or knowledge distillation (KD) belongs to Level 3 or Level 4?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Level 4&lt;/strong&gt;: Network architecture search (NAS) to explore a big search space and based on the constraints of edge device capability.  嚴格來說，已經不是 model compression, 而是 model search or exploration.&lt;/p&gt;

&lt;h3 id=&quot;level-1-quantization-and-pruning-and-huffman-encode&quot;&gt;Level 1: Quantization and Pruning and Huffman Encode&lt;/h3&gt;
&lt;p&gt;Details 可以參考之前兩篇文章。&lt;/p&gt;

&lt;p&gt;In summary, quantization from FP32 to INT8 可以 save up to 75% (4x) storage/bandwidth/computation, 而不損失 accuracy or increase error. 這也代表更低的功耗。如果使用更少 bitwidth (6/4/2/1), 可以省更多，但是可能 trade-off accuracy/error 或是限制應用的範圍。下圖是不同 quantized bitwidth 對應的 energy vs. test error.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15857558344760.jpg&quot; alt=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Pruning 是另一個更深奧更有空間的方式。可以視為 quantization 的 special case (weight and activation = 0), 但更進一步是一個 subset network 可以完全 represent the original network (lottery conjecture).  pruning 對於一些 “fat network” 可以達到 10x 的 saving.  對於一些 “lean network”, e.g. MobileNet 就比較少 saving.&lt;/p&gt;

&lt;p&gt;Parameter compression 也是常用的技巧。包含 weight compression and activation compression.&lt;br /&gt;
Parameter compression 省最多是 data 包含很多的冗余或是 regular structure，例如大量的 0, 從 information theory 就是 low entropy facilitate compression.  Huffman encoding 是一個有效的方法 for parameter compression.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15857617199358.jpg&quot; alt=&quot;&quot; /&gt;
pruning, quantization, compression 可以合在一起得到最佳的效果 at a cost of higher training time.&lt;/p&gt;

&lt;h3 id=&quot;level-2-matrix-and-tensor-decomposition&quot;&gt;Level 2: Matrix and Tensor Decomposition&lt;/h3&gt;
&lt;p&gt;分為兩個部分: CONV layer 和 FC layer.  當然廣義來說，FC layer 也是一種 CONV layer with kernel size WxHxC.  此處 CONV layer 的 kernel size 一般指 1x1, 3x3, …, 11x11, etc.&lt;/p&gt;

&lt;p&gt;對於 CONV layer, 越大 kernel filter 的 parameters and MACs 越大，較小的 kernel filter 的 parameters and MACs 越小。但如果把所有大的 kernel filter 都替換成小的 kernel filter, 會影響 DNN 的平移不變性，這會降低 DNN model 的精度。因此一些策略是識別冗余的 kernel filter, 並用較小 kernel filter 取代。例如 VGG 把所有大於 3x3 (e.g. 5x5, 7x7, etc.) 都用 3x3 filter 取代。SqueezeNet and MobileNet 甚至用 1x1 取代部分的 3x3 filter.&lt;/p&gt;

&lt;h4 id=&quot;convolutional-filter-compression-conv-layer-only&quot;&gt;Convolutional Filter Compression (CONV layer only)&lt;/h4&gt;
&lt;p&gt;SqueezeNet use 1x1 kernel to replace 3x3 kernel filter. 
MobileNet use depth-wise + point-wise (1x1) network to replace original kernel to reduce computation by 1/8-1/9 for 3x3 kernel.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15858142132307.jpg&quot; alt=&quot;&quot; /&gt;
MobileNet v3 可以達到不錯的精度 (75%)，但是 parameter and MAC 比起 AlexNet 少非常多。比起 ResNet50 (parameter 25M, MAC 4G) 也好不少。&lt;/p&gt;

&lt;h4 id=&quot;matrix-factorizationdecomposition-conv-or-fc-layer&quot;&gt;Matrix Factorization/Decomposition (CONV or FC layer)&lt;/h4&gt;
&lt;p&gt;通過將張量或矩陣分解為合積形式（sum-product form），將多維張量分解為更小的矩陣，從而可以消除冗余計算。一些因子分解方法可以將DNN模型加速4 倍以上，因為它們能夠將矩陣分解為更密集的參數矩陣，且能夠避免非結構化稀疏乘法的局部性問題。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15858148583700.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;目前 Matrix decomposition/factorization 並非主流。原因：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;關於矩陣分解，有多種技術。Kolda等人證明，大多數因子分解技術都可以用來做DNN模型的加速，但這些技術在精度和計算複雜度之間不一定能夠取得最佳的平衡。&lt;/li&gt;
  &lt;li&gt;由於缺乏理論解釋，因此很難解釋為什麼一些分解（例如CPD、BMD）能夠獲得較高的精度，而其他分解卻不能。&lt;/li&gt;
  &lt;li&gt;與矩陣分解相關的計算常常與模型獲得的性能增益相當，造成收益與損耗抵消。&lt;/li&gt;
  &lt;li&gt;矩陣分解很難在大型DNN模型中實現，因為隨著深度增加分解超參會呈指數增長，訓練時間主要耗費在尋找正確的分解超參。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;更多更 detailed description 可以參考 [@kuzminTaxonomyEvaluation2019].&lt;/p&gt;

&lt;h3 id=&quot;level-3-knowledge-transfer-or-distillation&quot;&gt;Level 3: Knowledge Transfer or Distillation&lt;/h3&gt;
&lt;p&gt;https://www.leiphone.com/news/202003/cggvDDPFIVTjydxS.html
大模型比小模型更準確，因為參數越多，允許學習的函數就可以越複雜。那麼能否用小的模型也學習到這樣複雜的函數呢？&lt;/p&gt;

&lt;p&gt;一種方式便是知識遷移（KT, Knowledge Transfer），通過將大的DNN模型獲得的知識遷移到小的DNN模型上。為了學習複雜函數，小的 DNN 模型會在大的 DNN 模型標記處的數據上進行訓練。其背後的思想是，大的 DNN 標記的數據會包含大量對小的DNN有用的信息。例如大的 DNN 模型對一個輸入圖像在一些類標籤上輸出中高機率，那麼這可能意味著這些類共享一些共同的視覺特徵；對於小的 DNN模型，如果去模擬這些機率，相比於直接從數據中學習，要能夠學到更多。&lt;/p&gt;

&lt;p&gt;具體的作法之一是 Hinton 在 2014年 提出的知識蒸餾 (KD, Knowledge Distillation)，這種方法的訓練過程相比於知識遷移 (KT) 要簡單得多。在知識蒸餾中，小的 DNN 模型使用學生-教師模式進行訓練，其中小的 DNN 模型是學生，一組專門的 DNN 模型是教師；通過訓練學生，讓它模仿教師的 &lt;strong&gt;softmax&lt;/strong&gt; 輸出，小的DNN 模型可以完成整體的任務。但在 Hinton 的工作中，小的 DNN 模型的準確度卻相應有些下降。 Li 等人利用最小化教師與學生之間特徵向量的歐氏距離，進一步提高的小的 DNN 模型的精度。類似的，FitNet 讓學生模型中的每一層都來模仿教師的特徵圖。但以上兩種方法都要求對學生模型的結構做出嚴格的假設，其泛化性較差。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15858302664067.jpg&quot; alt=&quot;-w600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Knowledge transfer/distillation is very interesting and similar to proxy AI I thought before!&lt;/p&gt;

&lt;p&gt;Knowledge transfer or distillation 是個非常有趣而且實用的技術。例如 teacher model 可以是雲端的大 DNN 模型，有比較好的精度以及泛化性。但在 edge or device 可以 deploy student model, i.e. 小 DNN 模型。雖然精度和泛化性比較差，但是 quick response, 以及 edge and device 不一定需要非常強的泛化性 (e.g. &lt;em&gt;local&lt;/em&gt; voice recognition, or &lt;em&gt;local&lt;/em&gt; face detection).&lt;/p&gt;

&lt;p&gt;優點：基於知識遷移和知識蒸餾的技術可以顯著降低大型預訓練模型的計算成本。有研究表明，知識蒸餾的方法不僅可以在計算機視覺中應用，還能用到許多例如半監督學習、域自適應等任務中。&lt;/p&gt;

&lt;p&gt;缺點及改進方向：知識蒸餾通常對學生和教師的結構和規模有嚴格的假設，因此很難推廣到所有的應用中。此外目前的知識蒸餾技術嚴重依賴於 softmax 輸出，不能與不同的輸出層協同工作。作為改進方向，學生可以學習教師模型的神經元激活序列，而不是僅僅模仿教師的神經元/層輸出，這能夠消除對學生和教師結構的限制（提高泛化能力），並減少對softmax輸出層的依賴。&lt;/p&gt;

&lt;h4 id=&quot;transfer-learning-is-different-from-knowledge-transferdistillation&quot;&gt;Transfer learning is different from knowledge transfer/distillation&lt;/h4&gt;
&lt;p&gt;The objective of transfer learning and knowledge distillation are quite different. &lt;strong&gt;In transfer learning, the weights are transferred&lt;/strong&gt; from a pre-trained network to a new network and the pre-trained network should exactly match the new network architecture.  What this means is that &lt;em&gt;the new network is essentially as deep and complex as the pre-trained network.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;the objective of knowledge distillation is different. The aim is not to transfer weights but to &lt;em&gt;transfer the generalizations of a complex model to a much lighter model.&lt;/em&gt;  如何 transfer generalizations?  使用 student-teach model 是一種方式。還有其他的方式可以參考 [@kompellaTapDark2018].&lt;/p&gt;

&lt;h3 id=&quot;level-4-network-architecture-search-nas&quot;&gt;Level 4: Network Architecture Search (NAS)&lt;/h3&gt;
&lt;p&gt;在設計低功耗計算機視覺程序時，針對不同的任務可能需要不同的DNN模型架構。但由於存在許多這種結構上的可能性，通過手工去設計一個最佳DNN模型往往是困難的。最好的辦法就是將這個過程自動化，即網絡架構搜索技術（Network Architecture Search）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15858392710045.jpg&quot; alt=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;NAS使用一個遞歸神經網絡(RNN)作為控制器，並使用增強學習來構建候選的DNN架構。對這些候選DNN架構進行訓練，然後使用驗證集進行測試，測試結果作為獎勵函數，用於優化控制器的下一個候選架構。&lt;/p&gt;

&lt;p&gt;NASNet 和AmoebaNet 證明瞭NAS的有效性，它們通過架構搜索獲得DNN模型能夠獲得SOTA性能。&lt;/p&gt;

&lt;p&gt;為了獲得針對移動設備有效的DNN模型，Tan等人提出了MNasNet，這個模型在控制器中使用了一個多目標獎勵函數。在實驗中，MNasNet 要比NASNet快2.3倍，參數減少4.8倍，操作減少10倍。此外，MNasNet也比NASNet更準確。&lt;/p&gt;

&lt;p&gt;不過，儘管NAS方法的效果顯著，但大多數NAS算法的計算量都非常大。例如，MNasNet需要50,000個GPU 時才能在ImageNet數據集上找到一個高效的DNN架構。&lt;/p&gt;

&lt;p&gt;為了減少與NAS相關的計算成本，一些研究人員建議基於代理任務和獎勵來搜索候選架構。例如在上面的例子中，我們不選用ImageNet，而用更小的數據集CIFAR-10。FBNet正是這樣來處理的，其速度是MNasNet的420倍。但Cai等人表明，在代理任務上優化的DNN架構並不能保證在目標任務上是最優的，為了克服基於代理的NAS解決方案所帶來的局限性，他們提出了Proxyless-NAS，這種方法會使用路徑級剪枝來減少候選架構的數量，並使用基於梯度的方法來處理延遲等目標。他們在300個GPU時內便找到了一個有效的架構。此外，一種稱為單路徑NAS（Single-Path NAS）的方法可以將架構搜索時間壓縮到 4 個GPU時內，不過這種加速是以降低精度為代價的。&lt;/p&gt;

&lt;p&gt;優點：NAS通過在所有可能的架構空間中進行搜索，而不需要任何人工干預，自動平衡準確性、內存和延遲之間的權衡。NAS能夠在許多移動設備上實現準確性、能耗的最佳性能。&lt;/p&gt;

&lt;p&gt;缺點及改進方向：計算量太大，導致很難去搜索大型數據集上任務的架構。另外，要想找到滿足性能需求的架構，必須對每個候選架構進行訓練，並在目標設備上運行來生成獎勵函數，這會導致較高的計算成本。其實，可以將候選DNN在數據的不同子集上進行並行訓練，從而減少訓練時間；從不同數據子集得到的梯度可以合併成一個經過訓練的DNN。不過這種並行訓練方法可能會導致較低的準確性。另一方面，在保持高收斂率的同時，利用自適應學習率可以提高準確性。&lt;/p&gt;

&lt;h3 id=&quot;model-compression-examples&quot;&gt;Model Compression Examples&lt;/h3&gt;

&lt;h4 id=&quot;ex1-deep-compression-by-han-level-1&quot;&gt;Ex1: Deep Compression by Han (Level 1)&lt;/h4&gt;
&lt;p&gt;參考 fig.1 使用 pruning, quantization, and parameter compression.  整體的效益如下。精度和 AlexNet 差不多 (TBC)。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Step 1: Pruning (9x-13x)&lt;/li&gt;
  &lt;li&gt;Step 2: Quantizing clustered weights for weight sharing (32bit -&amp;gt; 5bit) (~4x)&lt;/li&gt;
  &lt;li&gt;Step 3: Compression: encode weights/index for &lt;strong&gt;weight compression&lt;/strong&gt;; Huffman encoding &lt;strong&gt;sparsity/zero and weight sharing compression&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Total: 35x-49x&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Accuracy result (TBA)&lt;/p&gt;

&lt;h4 id=&quot;ex2-model-compression-via-distillation-and-quantization-level-13&quot;&gt;Ex2: Model compression via &lt;em&gt;distillation&lt;/em&gt; and &lt;em&gt;quantization&lt;/em&gt; (Level 1+3)&lt;/h4&gt;
&lt;p&gt;This &lt;strong&gt;excellent&lt;/strong&gt; paper [@polinoModelCompression2018] &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; proposes two new compression methods, which jointly leverage weight quantization and distillation of larger networks, called “teachers,” into compressed “student” networks.  簡單說 FP32 model 是 teacher model; quantized model 是 student model. Github code &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;The first method is called quantized distillation and leverages distillation during the training process, by incorporating distillation loss, expressed with respect to the teacher network, into the training of a smaller student network whose weights are quantized to a limited set of levels. &lt;strong&gt;teacher model 使用 FP32 deep model; student model 則是 uniformly quantized and shallow model.  藉著 distillation loss that teacher model can train student model.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The second method, differentiable quantization, optimizes the location of quantization points through &lt;em&gt;stochastic gradient descent&lt;/em&gt;, to better fit the behavior of the teacher model. &lt;strong&gt;使用和 student model 同樣的小模型。重點是 linear but non-uniform quantization. 但沒有 distillation loss; 而是用一般的 cross-entropy loss to train this model and optimize the &lt;em&gt;non-uniform&lt;/em&gt; quantization.&lt;/strong&gt;  當然也可以使用 non-uniform quantization for student model.  可能 computation 會太複雜。&lt;/p&gt;

&lt;p&gt;其他細節請參考[@polinoModelCompression2018].  這裏直接討論結果。&lt;/p&gt;

&lt;h4 id=&quot;cifar10-accuracy--teacher-model-53m-param-of-fp32-21mb-accuracy-8971&quot;&gt;CIFAR10 accuracy.  Teacher model: 5.3M param of FP32, 21MB, accuracy 89.71%.&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;有三種 student models, 分別為 1M/0.3M/0.1M param 如下表左第一欄。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第一欄 (A) 都是 FP32 full precision training. 例如 A1 代表 student model 1, 1M param, FP32：4MB.  兩個 accuracy 對應 cross-entropy loss and distillation loss.  Accuracy 84.5% 對應 normal training (cross-entropy loss).  Accuracy 88.8% 對應 teacher-student training (distillation loss).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;第二欄 (B) 都是 quantized training.  PM (post-mortem) Quant. 只是把 FP32 teacher-student training 的 weight 直接 post training &lt;strong&gt;uniform&lt;/strong&gt; quantization without any additional operation. 有兩種 PM Quant., 一是 global scaling (no bucket), 另一個是 local scaling (with bucket size = 256).  所以 (1) PM Quant. accuracy 一定差於 FP32 accuracy (88.8%).  Quantized Distill. 使用 distillation loss back propagation, 因此 accuracy is better than PM Quant.  In summary, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FP Distill. &amp;gt; Quantized Distill. &amp;gt; PM (with bucket) &amp;gt; PM (no bucket)&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Differentiable Quant. 使用 cross-entropy loss training.  從另一個角度, &lt;strong&gt;non-uniform&lt;/strong&gt; quantization, approach this problem.  在 4-bits quantization 的表現不輸於 uniform distillation loss training.  但在 2-bits quantization distillation loss training 還是比較好。合理推論，differentiable non-uniform quantization with distillation loss 應該會有最佳的 accuracy.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Differentiable quantization 在 computation 不容易在 edge AI 實現，因為 quantized values 不會落在 linear grid 上，很難用 finite bitwidth 表示，也很難做 MAC 計算。比較接近的解法是用 k-mean clustering algorithm to cluster weights and adopt the centroids as quantization points. Han 稱為 weight sharing.&lt;/li&gt;
  &lt;li&gt;最佳的結果 assuming &lt;strong&gt;accuracy loss &amp;lt; 2%&lt;/strong&gt; compared with baseline (89.71%) is student model 1 (1M param) of 4-bit with accuracy &lt;strong&gt;88%&lt;/strong&gt;. The total size of best student model 1 is: 1M param x 0.5 = 0.5MB.  &lt;strong&gt;A factor of 21MB/0.5MB = 42x saving in memory/bandwidth/computation etc.!!!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15859946738058.jpg&quot; alt=&quot;-w600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更好的結果是用比較 deeper student model, 但是用 4-bit (5.8M x 0.5 = 2.9MB), 而且 accuracy 還比較好 (&lt;strong&gt;92.3% vs. 89.71%&lt;/strong&gt;).  &lt;strong&gt;A factor of 21MB/2.9MB = 7.2x saving in memory/bandwidth/computation etc.!!!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15860150600942.jpg&quot; alt=&quot;-w527&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;cifar100-accuracy--teacher-model-365m-param-of-fp32-146mb-accuracy-7721&quot;&gt;CIFAR100 accuracy.  Teacher model: 36.5M param of FP32, 146MB, accuracy 77.21%.&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Student model is 17.2M param, about 1/2 of teacher model.  4-bit model is 8.2MB with accuracy 76.31%.  A factor of 146MB/8.2MB = 17.8x saving.&lt;/li&gt;
  &lt;li&gt;Differential quantization seems to perform better, but with more params and more complicated computation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15860167658569.jpg&quot; alt=&quot;-w600&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;imagenet-accuracy--teacher-model-resnet34-or-resnet50&quot;&gt;Imagenet accuracy.  Teacher model: ResNet34 or ResNet50&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Student model: 2xResNet18 QD 4 bit and 2xResNet34 QD 4 bit&lt;/li&gt;
  &lt;li&gt;Student model of 4-bit 可以得到和 teacher model 類似 accuracy.  但 size 比起 teacher FP32 model 少了 2x-4x.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/15842337834603/15860186870025.jpg&quot; alt=&quot;-w600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Distillation + Quantization 結論：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;FP32 to INT8 已經有很多 post-training quantization or quantization aware training 可以達到同樣的 accuracy.  因此 4x saving 已經很普通。&lt;/li&gt;
  &lt;li&gt;Teacher-student models 在小 dataset (CIFAR10), model compression 效果比較突出: (1) 8x from FP32 to 4-bit;  (2) student model 可以比 teacher model gain 4x-5x.  但對於大 dataset, CIFAR100 or ImageNet, student model param 已經接近甚至超過 teacher model param.  此時只有 FP32 to 4-bit gain.&lt;/li&gt;
  &lt;li&gt;對於大 dataset, knowledge distillation 的結果並不突出。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Level 1 + Level 2 compression 可以同時使用。增加壓縮的倍率。&lt;/li&gt;
  &lt;li&gt;Level 1 + Level 3 compression 可以同時使用。對於大 dataset 效果有限。但是小 dataset 似乎不錯。&lt;/li&gt;
  &lt;li&gt;Level 4 NAS 雖然看起來很好，但是需要太多的 computation resource/time to search.  需要更好的方式用於 edge AI.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Cheng, Yu, Duo Wang, Pan Zhou, and Tao Zhang. 2019. “A Survey of Model
Compression and Acceleration for Deep Neural Networks,” September.
&lt;a href=&quot;https://arxiv.org/abs/1710.09282v8&quot;&gt;https://arxiv.org/abs/1710.09282v8&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Goel, Abhinav, Caleb Tung, Yung-Hsiang Lu, and George K. Thiruvathukal. 2020. “A Survey of Methods for Low-Power Deep Learning and Computer Vision,” March. &lt;a href=&quot;http://arxiv.org/abs/2003.11066&quot;&gt;http://arxiv.org/abs/2003.11066&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Han, Song, Huizi Mao, and William J. Dally. 2016. “Deep Compression:
Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding,” February. &lt;a href=&quot;http://arxiv.org/abs/1510.00149&quot;&gt;http://arxiv.org/abs/1510.00149&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Han, Song, Jeff Pool, John Tran, and William J. Dally. 2015. “Learning Both Weights and Connections for Efficient Neural Networks,” October. &lt;a href=&quot;http://arxiv.org/abs/1506.02626&quot;&gt;http://arxiv.org/abs/1506.02626&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Kompella, Ravindra. n.d. “Tap into the Dark Knowledge Using Neural Nets Distillation.” Medium. Accessed April 2, 2020.
&lt;a href=&quot;https://towardsdatascience.com/knowledge-distillation-and-the-concept-of-dark-knowledge-8b7aed8014ac&quot;&gt;https://towardsdatascience.com/knowledge-distillation-and-the-concept-of-dark-knowledge-8b7aed8014ac&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Kuzmin, Andrey, Markus Nagel, Saurabh Pitre, Sandeep Pendyam, Tijmen
Blankevoort, and Max Welling. 2019. “Taxonomy and Evaluation of
Structured Compression of Convolutional Neural Networks,” December.
&lt;a href=&quot;http://arxiv.org/abs/1912.09802&quot;&gt;http://arxiv.org/abs/1912.09802&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Polino, Antonio, Razvan Pascanu, and Dan Alistarh. 2018. “Model
Compression via Distillation and Quantization,” February.
&lt;a href=&quot;http://arxiv.org/abs/1802.05668&quot;&gt;http://arxiv.org/abs/1802.05668&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Published in ICLR 2018 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;https://github.com/antspy/quantized_distillation &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="python" /><category term="quantization" /><category term="model compression" /><category term="pruning" /><category term="distillation" /><summary type="html">Edge AI Trilogy III - Model Compression</summary></entry><entry><title type="html">Poincare Conjecture/Theorem and Ricci Flow</title><link href="http://localhost:4000/foo/2018/12/22/test/" rel="alternate" type="text/html" title="Poincare Conjecture/Theorem and Ricci Flow" /><published>2018-12-22T07:29:08+08:00</published><updated>2018-12-22T07:29:08+08:00</updated><id>http://localhost:4000/foo/2018/12/22/test</id><content type="html" xml:base="http://localhost:4000/foo/2018/12/22/test/">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;之前學 group theory 和 tensor calculus, 總結到平直空間的量子場論。最簡單的是 QED 的 Lagrangian 如下為純量，具有 U(1) 對稱性，對應各種守恆律。以及不同路徑對時間積分滿足最小作用原理。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathscr{L}_{\mathrm{QED}}=\bar{\psi}\left(i \hbar c \gamma^{\mu} D_{\mu}-m c^{2}\right) \psi-\frac{1}{4 \mu_{0}} F_{\mu \nu} F^{\mu \nu}&lt;/script&gt;

&lt;p&gt;可以由 QED Lagrangian 推導&lt;strong&gt;非量子場論&lt;/strong&gt;近似解 Maxwell equations. Maxwell equations 可以解釋所有的電磁現象，但無法解釋光量子效應例如光電效應，黑體輻射，雷射等等。就像可以從愛因斯坦場方程式推導近似解牛頓萬有引力定律。&lt;/p&gt;

&lt;p&gt;把 tensor calculus 從 Euclidean (differential) geometry 推廣到 Riemannian (differential) geometry, 可以連結到廣義相對論。以下是愛因斯坦場方程式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G_{\mu \nu} \equiv R_{\mu \nu}-\frac{1}{2} R g_{\mu \nu}=\frac{8 \pi G}{c^{4}} T_{\mu \nu}&lt;/script&gt;

&lt;p&gt;右手 $T_{\mu\nu}$ 是 energy-momentum tensor, 二階張量，代表 mass-energy distribution. 左手 $G_{\mu\nu}$ 是 Einstein tensor, 也是二階張量，代表 space-time curvature, 基本是 $R_{\mu\nu}$ (Ricci curvature tensor) 減去一個修正項。&lt;/p&gt;

&lt;p&gt;多出的修正項 $ 1/2 R g_{\mu\nu}$ 項：$R$ 是 scalar curvature (trace of Ricci curvature tensor), $g_{\mu\nu}$ is metric tensor.  當初愛因斯坦寫下的場方程式並沒有這一項: (1)違反 local conservation of energy-momentum. 也就是 energy flow is not preserved [@wikiHistoryGeneral2019];（2）無法得到座標系無關形式，違反(馬赫)廣義相對性原理。愛因斯坦求助於 Hilbert.  在 Hilbert 的協助下，找到這個修正項。&lt;/p&gt;

&lt;p&gt;如果 $T_{\mu\nu}$ 隨時間變化，例如兩個黑洞旋轉合併，會改變時空曲率。時空曲率又會反過來影響質能分佈 and vice versa, 因而產生時空漣漪，一般稱為引力波。如同 Maxwell equation 的電場變化產生磁場 and vice versa, 因而產生電磁波。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tensor Calculus&lt;/strong&gt; 和 &lt;strong&gt;Differential Geometry&lt;/strong&gt; 能夠用於 Quantum Field Theory and General Relativity 兩大物理學，已經是非常幸福。 更幸福的是可以用於 Topology 的 Poincare conjecture (now theorem proved by Perelman).  這部分我們 follow Hamilton’s direction using Ricci flow. [@hamiltonRichardHamilton]&lt;/p&gt;

&lt;h2 id=&quot;laplacian-operator-and-heat-equation&quot;&gt;Laplacian Operator and Heat Equation&lt;/h2&gt;
&lt;p&gt;這部分可以參考前文【】。&lt;/p&gt;

&lt;p&gt;我們從&lt;strong&gt;座標無關&lt;/strong&gt;的張量定義拉普拉斯算子：$\Delta = \nabla\cdot\nabla$, 或是 diverge of gradient of a scalar or vector field. 以上的定義不只用於歐氏幾何，也適用黎曼幾何。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;熱傳導 (heat diffusion)&lt;/strong&gt; 
&lt;script type=&quot;math/tex&quot;&gt;\Delta \varphi(\vec{r},t) = -\frac{1}{c}\frac{\partial}{\partial t}\varphi(\vec{r},t)\quad c\text{ is conductivity}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;上式是 manifold 固定，只是定義在 manifold 上的純量場 (e.g. 勢能場，溫度場) 隨時間和空間變化，但是整體 volume 不變（守恆量），對應一個 flow。&lt;/p&gt;

&lt;h2 id=&quot;ricci-flow--愛因斯坦場方程式--拉普拉斯熱傳導&quot;&gt;Ricci Flow = 愛因斯坦場方程式 + 拉普拉斯熱傳導&lt;/h2&gt;

&lt;p&gt;Hamilton 則是考慮 manifold 本身隨時間變化。1981 引入 Ricci flow. 觀念上非常類似上述的熱傳導。但直接用於 manifold (intrinsic) 而非其上的 (extrinsic) field.  非常開創性而且具物理性直觀性！&lt;/p&gt;

&lt;p&gt;看了 Hamilton 2006 Youtube 的演講 [@hamiltonRichardHamilton2006], 他也許不是第一個把 PDE (Partial Differential Equation) 用於 topology. 但是第一個引入 Ricci flow, 結合分析和拓墣，對於 topology 非常&lt;strong&gt;具體實用&lt;/strong&gt; (N-manifold, not only 2 or 3).  拓墣可以大量借用 PDE 的理論，甚至可以用計算機協助。就像笛卡爾引入直角座標系結合代數和幾何。&lt;/p&gt;

&lt;p&gt;Hamilton 高度評價 Perelman 在 Ricci flow 的貢獻，不像某一些文章暗示 Hamilton 對 Perelman 有心結。Perelman 在拒絕 Fields medal 也高度評價 Hamilton 在 Ricci flow 的創見。兩人在專業領域應該是互相佩服。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hamilton 提出的 Ricci Flow 如下。果然是數學家的公式，非常簡潔。其實就是張量版的熱傳導方程式！&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2 R_{i j} = -\partial_{t} g_{i j}&lt;/script&gt;

&lt;p&gt;$R_{ij}$ 代表 manifold 的 intrinsic curvature, 基本是 Christoffel symbol 的空間一階導數 [@ListFormulas2019]。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_{ij} = \frac{\partial \Gamma_{i j}^{\ell}}{\partial x^{\ell}}-\frac{\partial \Gamma_{i \ell}^{\ell}}{\partial x^{j}}+\Gamma_{i j}^{m} \Gamma_{\ell m}^{\ell}-\Gamma_{i \ell}^{m} \Gamma_{j m}^{\ell}&lt;/script&gt;

&lt;p&gt;and Christoffel symbol 是 metric tensor 的空間一階導數&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Gamma_{k i}^{i}=\frac{1}{2} g^{i m} \frac{\partial g_{i m}}{\partial x^{k}}=\frac{1}{2 g} \frac{\partial g}{\partial x^{k}}=\frac{\partial \log \sqrt{|g|}}{\partial x^{k}}&lt;/script&gt;

&lt;p&gt;因此 $R_{ij}$ 基本是 metric tensor $g_{ij}$ 的&lt;strong&gt;空間二階導數&lt;/strong&gt;。這和拉普拉斯算子的功能一致。等式的右手則是 metric tensor 對&lt;strong&gt;時間一階導數&lt;/strong&gt;。因此 Ricci flow equation 類似拉普拉斯熱傳導公式。隨時間改變 manifold 的 metric tensor, Christoffel tesnor, curvature tensor.&lt;/p&gt;

&lt;p&gt;熟悉愛因斯坦場方程式者會想到修正項。Yes! 這稱為 normalized Ricci flow.
&lt;strong&gt;Normalized&lt;/strong&gt; Ricci flow 的定義如下 [@wikiRicciFlow2019]：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2 R_{i j} - \frac{2}{n} R_{\mathrm{avg}} g_{i j} = -\partial_{t} g_{i j}&lt;/script&gt;

&lt;p&gt;where $R_{avg}$ is the average (mean) of the scalar curvature (which is the trace of Ricci tensor), n is the dimension of the manifold.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The normalized equation preserves the volume of the metric space&lt;/strong&gt;.  這一句話就是加上中間這一項才能保持 volume 不變。這是 “(incompressible) flow” 的基本條件。這修正項和愛因斯坦廣義場方程式基本一致 (n=4)，滿足場方程式座標系無關，也就是廣義相對性原理。&lt;/p&gt;

&lt;p&gt;基本原則是 metric tensor, Christoffel tensor, curvature tensor exponentially decay.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ricci flow 的負號會讓不穩定的負曲率 (3-manifold 雙曲面) 只會短暫出現。&lt;/li&gt;
  &lt;li&gt;大的正曲率（非常彎 3-manifold 橢圓曲面）也會很快 decay。&lt;/li&gt;
  &lt;li&gt;最後由小的正曲率（平緩 3-manifold 橢圓曲面）dominate manifold 的變化。&lt;/li&gt;
  &lt;li&gt;Ricci flow 變化 manifold 過程中，拓墣特性不變 (invariant)，就是同胚！可以用於證明 Poincare theorem.&lt;/li&gt;
  &lt;li&gt;Volume (area for 2-manifold) is preserved? Yes for normalized Ricci flow; No for Ricci flow.  A good way to think of the normalized Ricci flow is that it’s the same as Ricci flow but you rescale every time-slice to make the volume constant. Maybe also reparametrize time to make the equation nicer if you feel like it. Of course, isometries are still isometries after a metric gets rescaled.&lt;/li&gt;
  &lt;li&gt;下圖是一個 2D surface/manifold 的 Ricci flow 變化 surface/manifold 的過程。因為是 Ricci flow, surface area is not preserved.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;media/15774610801799/15775517204932.jpg&quot; alt=&quot;-w295&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;poincare-conjecturetheorem&quot;&gt;Poincare Conjecture/Theorem&lt;/h2&gt;
&lt;p&gt;回到 Poincare conjecture [@PoincareConjecture2019]. 先從最基本的 2D surface 開始，比較直觀。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A compact 2-dimensional surface (2D manifold) without boundary is topologically homeomorphic to a 2-sphere if every loop can be continuously tightened to a point.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;更簡潔的說法&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Every simply connected, closed (i.e. no boundary and compact) 2-manifold is homeomorphic to the 2-sphere.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15774610801799/15775809209618.jpg&quot; alt=&quot;-w450&quot; /&gt;&lt;/p&gt;

&lt;p&gt;基本上如果一個 2D surface 任何一個 loop 可以連續收斂到一個點，2D surface 必定和球面同胚，如上圖。&lt;/p&gt;

&lt;p&gt;再看 2D torus (環面) 如下圖。沒有 boundary, 存在兩種 loops (red and pink) 都無法收斂到一個點。因此 2D torus 和球面不同胚。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15774610801799/15775814960654.jpg&quot; alt=&quot;-w246&quot; /&gt;&lt;/p&gt;

&lt;p&gt;任何一個 loop 可以連續收斂到一個點 = 沒有破洞 = 單連通
翻譯成中文：
&lt;strong&gt;任一單連通的、封閉的二維流形與二維球面同胚。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The Poincaré conjecture asserts that the same is true for 3-dimensional as follows!
&lt;strong&gt;Every simply connected, closed (i.e. no boundary and compact) 3-manifold is homeomorphic to the 3-sphere.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;翻譯成中文：
&lt;strong&gt;任一單連通、封閉的三維流形與三維球面同胚。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;###如何想像單連通、封閉的三維流形？
對於處於三維歐氏空間的我們，可以看到封閉的二維流形（如各種球面，環面，Klein bottle, etc.）我們可以想像有邊界的三維流形，但是很難想像封閉的三維流形。這需要四維空間的視角才能想像。但對於簡單封閉三維流形，我們可以展開降維到三維歐氏空間。&lt;/p&gt;

&lt;p&gt;以下用 2D 骰子面（和 2D 球面同胚）來類比。參考數學女孩龐加萊猜想。
2D 骰子面是單連通、封閉的二維曲面，和二維球面同胚。
為什麼用 2D 骰子面？因為 3D cube (embed 2D 骰子面)可以展開成 6 個 2D 正方形在 2D 歐氏平面。每一個正方形的 4 邊，都和 4 個正方形相鄰。因此一個 2D 曲面的生物 (毛毛蟲)，只要遵循相鄰的規則，可以一直移動不會離開 2D 骰子面。也就是具有封閉性。
&lt;img src=&quot;/media/15827309953153.jpg&quot; alt=&quot;-w482&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/15827309309973.jpg&quot; alt=&quot;-w671&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15774610801799/15776132514499.jpg&quot; alt=&quot;-w253&quot; /&gt;&lt;/p&gt;

&lt;p&gt;把 2D 骰子面推廣到 3D 骰子體（和 3D 超球面同胚）。原則上要在 4D 歐氏空間才能想像。可以用下圖左近似 4D hypercube。可以展開成 8 個 3D 立方體 (cube), 每一個 3D cube 的 6 面，都和 6 個（上下左右前後）3D cube 相鄰。因此一個 3D 生物（人），只要遵循相鄰的規則，可以一直移動不會離開 3D 骰子體。也就是具有封閉性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;media/15774610801799/15776143479478.jpg&quot; alt=&quot;-w358&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-poincare-conjecture-is-important&quot;&gt;Why Poincare Conjecture is Important？&lt;/h2&gt;
&lt;p&gt;首先聽起來很基本且重要。的確這是拓墣學一個基本問題。事實上，在 2 維和大於等於 4 維流形，本命題都已證明維真。只有在 3 維流形，也就是 Poincare conjecture, 一直到 Perelman 在 2006 才證明 Poincare conjecture.&lt;/p&gt;

&lt;p&gt;更重要的是 1982 Thurston 提出 geometrization conjecture (now theorem) 猜測所有封閉的三維流形 (3-manifold) 可以分解為 8 種基本幾何結構，3-sphere 是其中之一。[@wikiGeometrizationConjecture2019]&lt;/p&gt;

&lt;p&gt;類似有 uniformization theorem 適用於二維流形 (2-manifold): 所有單連通的二維流形（球面）一定是 3 種曲面之一（Euclidean, spherical, or hyperbolic).&lt;/p&gt;

&lt;h2 id=&quot;strategy-to-prove-poincare-conjecture&quot;&gt;Strategy to Prove Poincare Conjecture&lt;/h2&gt;
&lt;p&gt;Hamilton 1981 提出 Ricci flow 的思路：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;對於單連通、封閉 3-manifold 作為初始條件, $g_{ij}(0)$, 施加 Ricci flow deforms 3-manifold.&lt;/li&gt;
  &lt;li&gt;Ricci flow 變化 manifold 過程中，manifold 拓墣特性不變 (invariant)，就是同胚！&lt;/li&gt;
  &lt;li&gt;Ricci flow 的負號會讓不穩定的負曲率只會短暫出現。大的正曲率也會很快 decay.  最後由小的正曲率 dominate manifold 的變化。最後趨近 3-sphere.&lt;/li&gt;
  &lt;li&gt;因此證明單連通、封閉 3-manifold 和 3-sphere 同胚，也就是 Poincare conjecture.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Hamilton 在 Ricci flow 的貢獻：[@hamiltonRichardHamilton2006]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;正曲率的 2/3-manifold 在 finite time 收斂到一點 (singularity with curvature $\to\infty$)。但 normalize (area/volume) 之後收斂到 2/3-sphere，就是 2/3-sphere 同胚。等效於使用 normalized Ricci flow to preserve volume (?).&lt;/li&gt;
  &lt;li&gt;2-manifold 啞鈴 (1 “neck” with positive and negative curvature) 或是多個 “neck” 如圖一在 finite time 收斂到一點。&lt;/li&gt;
  &lt;li&gt;因此 2-manifold 可以很容易用 Ricci flow 證明和 2-sphere 同胚。這是簡單的牛刀小試。&lt;/li&gt;
  &lt;li&gt;3-manifold with neck 就跟複雜，會產生 “neck pinch” singularity.  Hamilton 提出 Ricci flow with surgery to cut off large curvature portion and solve the singularity to converge to 3-sphere.  Hamilton 的父親是真的外科醫生。&lt;/li&gt;
  &lt;li&gt;但存在 cigar (2-manifold) or other 3-manifold &lt;strong&gt;soliton&lt;/strong&gt; 過程永遠保持形狀不變，無法收斂到 3-sphere.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Perelman 解決 Hamilton Ricci-flow 的漏洞。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Improve the surgery to completely solve singularity.&lt;/li&gt;
  &lt;li&gt;From transport equation to make soliton 無法產生。&lt;/li&gt;
  &lt;li&gt;Prove geometrization conjecture, Poincare conjecture 基本是一個子定理。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;Hamilton, Richard, dir. 2006. &lt;em&gt;Richard Hamilton | the Poincare
Conjecture | 2006&lt;/em&gt;. &lt;a href=&quot;https://www.youtube.com/watch?v=fymCXcIt20g&quot;&gt;https://www.youtube.com/watch?v=fymCXcIt20g&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Wiki. 2019a. “Ricci Flow.” &lt;em&gt;Wikipedia&lt;/em&gt;.
&lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Ricci_flow&amp;amp;oldid=920777616&quot;&gt;https://en.wikipedia.org/w/index.php?title=Ricci_flow&amp;amp;oldid=920777616&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;———. 2019b. “History of General Relativity.” &lt;em&gt;Wikipedia&lt;/em&gt;.
&lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=History_of_general_relativity&amp;amp;oldid=931327622&quot;&gt;https://en.wikipedia.org/w/index.php?title=History_of_general_relativity&amp;amp;oldid=931327622&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;———. 2019c. “Geometrization Conjecture.” &lt;em&gt;Wikipedia&lt;/em&gt;.
&lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Geometrization_conjecture&amp;amp;oldid=932572904&quot;&gt;https://en.wikipedia.org/w/index.php?title=Geometrization_conjecture&amp;amp;oldid=932572904&lt;/a&gt;.&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><summary type="html">Introduction 之前學 group theory 和 tensor calculus, 總結到平直空間的量子場論。最簡單的是 QED 的 Lagrangian 如下為純量，具有 U(1) 對稱性，對應各種守恆律。以及不同路徑對時間積分滿足最小作用原理。</summary></entry></feed>