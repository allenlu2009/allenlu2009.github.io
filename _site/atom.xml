<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/atom.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-09-19T14:28:53+08:00</updated><id>http://localhost:4000/atom.xml</id><title type="html">NexT</title><author><name>Allen Lu (from John Doe)</name></author><entry><title type="html"></title><link href="http://localhost:4000/2021/09/19/2021-09-19-Deterministic_Probabilistic/" rel="alternate" type="text/html" title="" /><published>2021-09-19T14:28:53+08:00</published><updated>2021-09-19T14:28:53+08:00</updated><id>http://localhost:4000/2021/09/19/2021-09-19-Deterministic_Probabilistic</id><content type="html" xml:base="http://localhost:4000/2021/09/19/2021-09-19-Deterministic_Probabilistic/">&lt;p&gt;Machine learning 就是一個 determinstic 和 probabilistic 擺盪和交織的過程。&lt;/p&gt;

&lt;p&gt;(Input) dataset 一般是 deterministic.&lt;/p&gt;

&lt;p&gt;傳統的 machine learning technique, e.g. linear regression, SVM, decision tree, etc. 也很多是 deterministic math.&lt;/p&gt;

&lt;p&gt;但是 ML 背後的 modeling, 邏輯，和解釋卻可以用 probabilistic 統一解釋。例如 logistic regression, 甚至 neural network 的分類網路卻可以有 probability 的詮釋。&lt;/p&gt;

&lt;p&gt;最後一類從頭到尾都是 probabilistic.  例如 bayesian inference, variational autoencoder.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Input&lt;/th&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Output&lt;/th&gt;
      &lt;th&gt;Comment&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Linear regression&lt;/td&gt;
      &lt;td&gt;(D) dataset&lt;/td&gt;
      &lt;td&gt;(D) linear function&lt;/td&gt;
      &lt;td&gt;(D) error&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Logistic regression&lt;/td&gt;
      &lt;td&gt;(D) dataset&lt;/td&gt;
      &lt;td&gt;(D) logistic function&lt;/td&gt;
      &lt;td&gt;(P) probability distribution&lt;/td&gt;
      &lt;td&gt;distribution is a (D) function&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Classification NN&lt;/td&gt;
      &lt;td&gt;(D) dataset&lt;/td&gt;
      &lt;td&gt;(D) NN&lt;/td&gt;
      &lt;td&gt;(P) probability distribution&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;VAE encoder, training&lt;/td&gt;
      &lt;td&gt;(D) 1-data&lt;/td&gt;
      &lt;td&gt;(D) NN&lt;/td&gt;
      &lt;td&gt;(P) random variable&lt;/td&gt;
      &lt;td&gt;parameter to RV&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;VAE decoder, generation&lt;/td&gt;
      &lt;td&gt;(P) RV 1-sample&lt;/td&gt;
      &lt;td&gt;(D) NN&lt;/td&gt;
      &lt;td&gt;(P) random variable&lt;/td&gt;
      &lt;td&gt;output sample&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SVM&lt;/td&gt;
      &lt;td&gt;(D) dataset&lt;/td&gt;
      &lt;td&gt;(D) kernel function&lt;/td&gt;
      &lt;td&gt;(D) binary&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;absolute deterministic:  function, NN? (input/output), not parameter
deterministic/probabilistic:  random variable, distribution; ideal is random, but representation (function) is determinstic!
probabilistic:  sampling, MC&lt;/p&gt;

&lt;p&gt;single data-point and collective data&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author></entry><entry><title type="html">Machine Learning Database</title><link href="http://localhost:4000/ai/2021/09/19/Machine_Learning_Database/" rel="alternate" type="text/html" title="Machine Learning Database" /><published>2021-09-19T00:00:00+08:00</published><updated>2021-09-19T00:00:00+08:00</updated><id>http://localhost:4000/ai/2021/09/19/Machine_Learning_Database</id><content type="html" xml:base="http://localhost:4000/ai/2021/09/19/Machine_Learning_Database/">&lt;p&gt;AI, 特別是深度學習的 ABC 是 Algorithm, Big data, and Computation.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Algorithm: CNN (image, vision), LSTM (voice), Transformer (NLP), etc.&lt;/li&gt;
  &lt;li&gt;Big data: ImageNet, and other big datasets.&lt;/li&gt;
  &lt;li&gt;Computation: GPU, TPU/NPU/APU, etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其中 (2) 顯然和 database 高度相關。不過早期的 big data 都是非常結構化的資料，簡單的 table or dataframe 類似 csv 就可以用來 training. 似乎沒有強烈的 database 需求。&lt;/p&gt;

&lt;h2 id=&quot;ai-幾個趨勢&quot;&gt;AI 幾個趨勢&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;從雲 (cloud) 擴散到端/終端裝置 (edge/device)。對於 cloud 而言，有無限的 computation and storage resources, 1-3 都不是問題。目前端主要是 inference 為主，2 並不重要。不過 on-device learning 越來越重要，edge AI 需要 on-device database 處理 real-time update data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;結構化資料變成非結構化資料。甚至 fused structured/unstructured data, e.g. image+voice, video+radar, etc.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Centralized learning (and database) 變成 distributed learning (and database).  由於隱私考量，還有 federated learning, etc.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;our-goal&quot;&gt;Our Goal&lt;/h2&gt;
&lt;p&gt;Edge or on-device learning.  可以 real-time training (~1sec)! base on dynamically updated data.  不是等到 idle time or sleep time 才 training.  此時要同時解決 database + learning 的問題。另外也需要支持 distributed learning or federated learning 和 cloud or 其他的 edge device exchange information.&lt;/p&gt;

&lt;h2 id=&quot;方法&quot;&gt;方法&lt;/h2&gt;
&lt;p&gt;Method 1: Database is database;  Learning is learning.&lt;/p&gt;

&lt;p&gt;Method 2: Keep your friends close, and your enemies closer -&amp;gt; Keep your ML close, and your data closer. 直接在 database 支持 ML!
WHY?
    * Real-time, low latency
    * AutoML for database!  Extract feature automatically&lt;/p&gt;

&lt;h2 id=&quot;database-candidate-choudhurytopdatabases2020&quot;&gt;Database candidate [@choudhuryTopDatabases2020]&lt;/h2&gt;
&lt;p&gt;Method 1:&lt;/p&gt;

&lt;p&gt;MySQL
    Most popular open-source relational database manageemnet systems (RDBMS).
    Acquired by Oracle, paid for commerical application.
MariaDB
    Open source, similar to MySQL (by MySQL inventor)
MongoDB
    Document database. Store data in JSON-like documents.  It seems useful for non-stuctured data.&lt;/p&gt;

&lt;p&gt;PostgreSQL
    Extensibility.  Tensorflow support PostgreSQL.&lt;/p&gt;

&lt;p&gt;Method 2:
MLDB
    Open source real time prediction endpoints.  Integrate ML functions.&lt;/p&gt;

&lt;p&gt;Redis
    built-in Lua scripting, Redis-ML.&lt;/p&gt;

&lt;p&gt;MindsDB&lt;/p&gt;

&lt;p&gt;隨著網際網路的發展，我們把一台一台伺服器變成多台伺服器。當開始建立資料備份時，需要加一個緩衝層來調整所有的查詢，投入更多硬體。最後，需要將資料切分多個集群上，並重構大量的應用邏輯以適應這種切分。不久之後，你就會發現被自己數月前的設計資料結構限制住了。&lt;/p&gt;

&lt;p&gt;隨著web2.0的興起，關聯式資料庫本身無法克服的缺陷越來越明顯，主要表現為如下幾點：
1.對資料高併發讀寫的需求
2.對海量資料的高效率存儲和訪問的需求。
3.對資料庫的高可擴展性和高可用性的需求。
4.資料庫事務一致性需求。
5.資料庫寫實性和讀寫時性需求。
6.對複雜SQL的查詢，特別是對關聯查詢的需求。&lt;/p&gt;

&lt;p&gt;NoSQL是Notonly SQL的縮寫，NoSQL不使用SQL作為查詢語言。其資料存儲可以不需要固定的表格模式，也經常避免使用SQL的join操作，一般有水準可擴展性的特徵。&lt;/p&gt;

&lt;p&gt;NoSQL又分成四大類：
1.Key-Value，如Redis。
2.Document-Oriented，如MongoDB。
3.Wide Column Store，如Cassandra。
4.Graph-Oriented，如Neo4J。
而本篇要介紹的主角則是Key-Value的Redis。&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="database" /><category term="machine learning" /><category term="ML" /><summary type="html">AI, 特別是深度學習的 ABC 是 Algorithm, Big data, and Computation. Algorithm: CNN (image, vision), LSTM (voice), Transformer (NLP), etc. Big data: ImageNet, and other big datasets. Computation: GPU, TPU/NPU/APU, etc.</summary></entry><entry><title type="html">跨平臺 Markdown Plus MathJax Blog Editing 分享</title><link href="http://localhost:4000/ai/2021/09/12/Cross_Platform_Markdown_Math_Blog/" rel="alternate" type="text/html" title="跨平臺 Markdown Plus MathJax Blog Editing 分享" /><published>2021-09-12T00:00:00+08:00</published><updated>2021-09-12T00:00:00+08:00</updated><id>http://localhost:4000/ai/2021/09/12/Cross_Platform_Markdown_Math_Blog</id><content type="html" xml:base="http://localhost:4000/ai/2021/09/12/Cross_Platform_Markdown_Math_Blog/">&lt;p&gt;我常用的計算平臺包含：MacBook air/pro (Mac OS),  PC (Windows 10), and iPad air (iPad OS).&lt;/p&gt;

&lt;p&gt;常常使用的 computing platform and offline blog editors 如下：&lt;/p&gt;

&lt;h2 id=&quot;computing-platform-and-editor&quot;&gt;Computing Platform and Editor&lt;/h2&gt;

&lt;p&gt;MacBook air/pro (mobile at work)  - &lt;strong&gt;Marsedit (paid), mweb (paid, Markdown)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Windows (fixed at home) - WLW (Window Live Writer, free), &lt;strong&gt;VScode (free, Markdown), Typora (free, Markdown)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;iPad air (for portability and photo) - &lt;strong&gt;mweb (free for editing, not for creating, publishing, Markdown)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;推薦的-markdownmathjax-editor&quot;&gt;推薦的 Markdown+MathJax Editor&lt;/h2&gt;

&lt;h3 id=&quot;爲什麽使用-markdown-editor-for-blog&quot;&gt;爲什麽使用 Markdown editor for Blog&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Math equation input: Markdown editor 大多可以插入 latex-based 數學公式 (e.g. MathJax or KaTex).  搭配 &lt;a href=&quot;https://mathpix.com/&quot;&gt;Mathpix Snip&lt;/a&gt; (大推！) 是我用過最好的 math equation generator!  Example: $i \hbar \frac{d}{d t}\mid \Psi(t)\rangle=\hat{H}\mid \Psi(t)\rangle$&lt;/li&gt;
  &lt;li&gt;主要的 blog platforms (e.g. Wordpress, 特別是 Github) 都支持 Markdown.&lt;/li&gt;
  &lt;li&gt;可携性大爲提高。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此我從 WYSIWYG editor 像是 Marsedit (Mac), WLW (PC) 改用 Markdown editors.&lt;/p&gt;

&lt;h3 id=&quot;數學公式-rendering-for-blog&quot;&gt;數學公式 rendering for Blog&lt;/h3&gt;

&lt;p&gt;最早的數學公式 rendering 來自 Latex，主打 professional and static publising 例如 thesis, paper, etc. pdf files.&lt;/p&gt;

&lt;p&gt;Latex 的龐大和 static 特性並不適合用於 dynamic rendering 的 blog.  因此有兩種變形：MathJax and KaTex.   MathJax 比較接近 Latex.  KaTex 主打快速 dynamic rendering, 有一些 equation numbering and reference 並不支持，&lt;strong&gt;因此我主要使用 MathJax.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210911234257339.png&quot; alt=&quot;image-20210911234257339&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Latex/MathJax 的輸入可以使用 Mathpix Snip capture, 非常有用！&lt;/p&gt;

&lt;h3 id=&quot;分享我用過的-markdownmath-editors&quot;&gt;分享我用過的 Markdown+Math editors&lt;/h3&gt;

&lt;h4 id=&quot;mweb-built-in-mathjax-support&quot;&gt;mweb (built-in MathJax support)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;優點:&lt;/strong&gt; (1) 支持 markdown editing, content management, figure management, and blog publishing; (2) 跨 Mac OS and iPad OS or iOS;  (3) 支持 iCloud sync between MacBook pro and iPad air.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;缺點:&lt;/strong&gt; &lt;strong&gt;(1) 沒有 Windows version.&lt;/strong&gt;  (2) mweb3.0 對於 math equation 支持比較差，有一些常用的 math symbol (e.g. Lagrangian) 不支持。不過 mweb4.0 似乎有改善。&lt;strong&gt;(3) 另外對於 Apple M1 晶片的穩定性很差！&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;typora-built-in-mathjax-support&quot;&gt;Typora (built-in MathJax support)&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;優點:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;設定簡單，基本打開  (Jekyll _post) directory 就可以編輯。下圖左是 directory file list.  下圖右是 editing&amp;amp;preview together window.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;UI 非常簡潔，不支持 side-by-side markdown and rendering display. 但是使用一陣子發覺 Typora 直接 rendering output to display 很棒。&lt;/strong&gt;不會像 mweb editing 時，另一個 display 動來動去。特別在小銀幕非常適合，mweb 的 iOS 版採用一樣的做法。可惜沒有 iOS/iPad OS version&lt;/li&gt;
      &lt;li&gt;跨 Windows/Mac OS/Linux, 但沒有 iOS version.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;缺點:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;只有 Markdown editing, preview, file list, 但是沒有 blog publishing.&lt;/li&gt;
      &lt;li&gt;Another big disadvantage: math equation number 支持不好 \label{} 常常有問題。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210912100220717.png&quot; alt=&quot;image-20210912100220717&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;設定 root-path for image directory (下面兩步都要做！)
    &lt;ul&gt;
      &lt;li&gt;在本文加上： typora-root-url: ../../allenlu2009.github.io&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;/media/image-20210814233107185.png&quot; alt=&quot;image-20210814233107185&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Typora: Format: Image: Use Image Root Path: set to the above directory&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;設定 copy and paste image path:  Typora: File : Preference: Image :  設定 copy and paste image directory.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210912100913945.png&quot; alt=&quot;image-20210912100913945&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;vscode--math-preview-extension&quot;&gt;VSCode + Math Preview Extension&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;優點:&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;VSCode 整合 (via extension) git version control and Github pull/push, 可能對 Github posting 比較容易&lt;/li&gt;
      &lt;li&gt;VSCode 有很多的 extensions, 例如 jekyll 可以直接 preview post to github blog.  或是 mathjax 以及其他 preview 的功能。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;缺點:&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;VSCode 有 built-in markdown preview!  但完全不支持 Math rendering!!&lt;/strong&gt; 需要 install plug-in.  另外 preview image 非常多坑！&lt;/li&gt;
      &lt;li&gt;除非是 coding 達人，不然不推用 VSCode 做 math blog!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;VSCode extension 有兩個 extensions  &lt;strong&gt;(1) Markdown+Math:  only support KaTex;  (2) Markdown Preview Enhaced: Default KaTex, Optional MathJax&lt;/strong&gt;, changed in setting.
&lt;img src=&quot;/media/image-20210912001358757.png&quot; alt=&quot;image-20210912001358757&quot; style=&quot;zoom:40%;&quot; /&gt; and &lt;img src=&quot;/media/image-20210912001314540.png&quot; alt=&quot;image-20210912001314540&quot; style=&quot;zoom:40%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;兩者各有缺點，所以兩個都用。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Markdown+Math (KaTex only): 下圖左是 Markdown, 下圖右是 Markdown+Math preview.  首先這個 markdown 支持 dark mode; 再來 math 只支持 KaTex, 所以 \label{} 以及 cross reference equation 不支持。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210912085129732.png&quot; alt=&quot;image-20210912085129732&quot; style=&quot;zoom:90%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Markdown Preview Enhanced (Default KaTex, change to MathJax in setting): 下圖左是 Markdown, 下圖右是 Markdown Preview Enhanced (Setting: KaTex -&amp;gt; MathJax).   看起來還不錯。但只要左邊編輯 markdown, 右邊數學公式就出現亂碼！所以只能用於最後確認效果。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210912081052675.png&quot; alt=&quot;image-20210912081052675&quot; style=&quot;zoom:100%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Image preview 一堆問題！同樣分成 built-in preview 和 Markdown Preview Enhaced.  總結來説都很爛，但是 Markdown Preview Enhanced (差) 比 built-in preview (爛) 好。
    &lt;ul&gt;
      &lt;li&gt;image reference 格式:  built-in preview 只接受標準 markdown 格式： &lt;img src=&quot;...jpg&quot; alt=&quot;text&quot; /&gt; ；preview enhanced 支持標準格式以及 html 格式 : &amp;lt;img src =“…”&amp;gt;”&lt;/li&gt;
      &lt;li&gt;remote image:  由於 secuity concern, built-in preview 只接受 https;  preview enhanced 支持 http or https.  e.g.
&lt;img src=&quot;https://ww1.sinaimg.cn/mw690/81b78497jw1emfgwkasznj21hc0u0qb7.jpg&quot; alt=&quot;https&quot; /&gt;
&lt;img src=&quot;http://ww1.sinaimg.cn/mw690/81b78497jw1emfgwkasznj21hc0u0qb7.jpg&quot; alt=&quot;http&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;&lt;del&gt;local file system image:  這是最糟糕的部分！只支持 local directory 為 root 的絕對 path!!!  也就是説，無法另外設定 root path, 也不能用 ../media/ 往上 path (因爲 root 沒有更上面的 directory).  我最後只能在 _post directory 之下做一個 symbolic link : PS&amp;gt;  new-item -itemtype symboliclink -path ./  -name media -value ../media&lt;/del&gt;&lt;/li&gt;
      &lt;li&gt;找到正確做法。 File: Add folder to workspace: pick allenlu.github.io as workspace.  此時就成爲 root path.  不用再設定 symbolic link. 不過以下的結論相同。&lt;/li&gt;
      &lt;li&gt;完全不建議一般人用 VSCode 作 markdown blog!&lt;/li&gt;
      &lt;li&gt;Solve another issue of image copy and paste.   Image copy:  “shift+windows(cmd)+s”
image paste -&amp;gt; install paste image extension!!!&lt;br /&gt;
 then set image path and prefix =&amp;gt; ctl+windows(cmd)+v   Ctrl+Alt+V (Cmd+Alt+V on Mac).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cloud-platform&quot;&gt;Cloud Platform&lt;/h2&gt;

&lt;p&gt;跨平臺不只是 computing platforms, Windows/Mac OS/iOS, 更重要是要有 cloud platform 同步到一個 database!  從不同的 computing platforms 要很容易讀寫這個 cloud platform.  基本上只有幾個常見 cloud platforms 能達到這個要求：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Google Drive&lt;/li&gt;
  &lt;li&gt;Microsoft Onedrive&lt;/li&gt;
  &lt;li&gt;Apple iCloud&lt;/li&gt;
  &lt;li&gt;Dropbox&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我選擇使用 iCloud, 原因很簡單。因爲 mweb 只支持 iCloud and Dropbox.   Dropbox 的 free quota 只有 2GB.  iCloud 的 free quota 5GB.   本文是先用 MacBook Pro 的 mweb create and start the article.  再使用 PC Typora 纂寫大部分内容。&lt;/p&gt;

&lt;p&gt;最後再切回 iPad Air 使用 MWeb 繼續，並且拍一張照片結束。這是目前我比較滿意的寫作方式。
最後再再切回 MacBook Pro to publish, have fun!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16101804667280/16102111356622.jpg&quot; alt=&quot;text&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210911234257339.png&quot; alt=&quot;test&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210911234257339.png&quot; alt=&quot;image-20210911234257339&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="markdown" /><category term="mathjax" /><summary type="html">我常用的計算平臺包含：MacBook air/pro (Mac OS), PC (Windows 10), and iPad air (iPad OS).</summary></entry><entry><title type="html">Math AI - Variational Autoencoder Vs. Variational EM Algorithm</title><link href="http://localhost:4000/ai/2021/08/19/Variational-Autoencoder/" rel="alternate" type="text/html" title="Math AI - Variational Autoencoder Vs. Variational EM Algorithm" /><published>2021-08-19T07:10:08+08:00</published><updated>2021-08-19T07:10:08+08:00</updated><id>http://localhost:4000/ai/2021/08/19/Variational%20Autoencoder</id><content type="html" xml:base="http://localhost:4000/ai/2021/08/19/Variational-Autoencoder/">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&lt;/script&gt;

&lt;h2 id=&quot;main-reference&quot;&gt;Main Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[@kingmaIntroductionVariational2019] : excellent reference&lt;/li&gt;
  &lt;li&gt;[@escuderoVariationalAutoEncoders2020]&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;重點-outline&quot;&gt;重點 outline&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;VAE 第一個 innovation (encoder+decoder): 使用 encoder neural network ($\phi$) 和 decoder neural network ($\theta$) 架構。&lt;strong&gt;從 autoencoder 的延伸&lt;/strong&gt;似乎很直觀。但從 deterministic 延伸到 probabilistic 有點魔幻寫實，需要更嚴謹的數學框架。&lt;/li&gt;
  &lt;li&gt;VAE 第二個 innovation (DLVM):  引入 hidden (random) variable $\mathbf{z}$, 從 $\mathbf{z} \to \text{neural network}\,(\theta) \to \mathbf{x}.$  &lt;strong&gt;Hidden variable $\mathbf{z}$ 源自 (variational) EM + DAG;  再用 (deterministic) neural network of $\theta$ for parameter optimization.  這就是 DLVM (Deep Learning Variable Model) 的精神。&lt;/strong&gt;  根據 (variational) EM:
    &lt;ul&gt;
      &lt;li&gt;E-step: 找到 $q(\mathbf{z}) \approx p_{\theta}(\mathbf{z} \mid \mathbf{x})$, &lt;strong&gt;也就是 posterior&lt;/strong&gt;, &lt;strong&gt;但我們知道在 DLVM posterior 是 intractable，必須用近似&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;M-step: optimize $\theta$ based on posterior:  $\underset{\boldsymbol{\theta}}{\operatorname{argmax}} E_{q(\mathbf{z})} \ln p_{\theta}(\mathbf{x}, \mathbf{z})$,  &lt;strong&gt;其中的 joint distribution 是 tractable, 但是 $q(\mathbf{z})$ intractable&lt;/strong&gt;, 所以是卡在 posterior intractable 這個問題！&lt;/li&gt;
      &lt;li&gt;Iterate E-step and M-step in (variational EM); 在 DLVM 就變成 SGD optimization!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;VAE 第三個 innovation 就是為了解決2.的 posterior 問題  $q(\mathbf{z}) \to q_{\phi}(\mathbf{z}\mid x)$:  用另一個 (tractable) decoder neural network $\phi$, 來近似 (intractable) posterior $q_{\phi}(\mathbf{z}\mid x) \approx p(\mathbf{z}\mid x)$&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;因此 VAE 和 DLVM (or variational EM) 的差別在於 VAE 多了 decoder neural network $\phi$ ，所以三者的數學框架非常相似！&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;VAE 的 training loss 包含 reconstruction loss (源自 encoder+decoder) + 上面的 M-step loss (源自 variational EM)&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Maximum likelihood optimization ~ minimum cross-entropy loss (not in this case)  ~ M-step loss (in this case)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;同樣的方法應該可以用在很多 DLVM 應用中。如果有 intractable posterior, 就用 (encoder) neural network 近似。但問題是要有方法 train 這個 encoder.  VAE 很巧妙的同時 train encoder + decoder 是用原始的 image and generative image.   需要再檢驗。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;下圖顯示 ML, EM, DLVM, VAE 的演進關係；DLVM 和 VAE echo 1-4.  雙圓框代表 observed random variable, 單圓框代表 hidden random variable.  單方框代表 (fixed and to be estimated) parameter.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210830230538496.png&quot; width=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其他的重點：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;如何用 deterministic neural network 表示 probabilistic bayesian inference?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如何用 deterministic neural network 表示 probabilistic VAE encoder and decoder?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如何把 intractable posterior 用 tractable neural network encoder 近似?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;variational-autoencoder-again&quot;&gt;Variational Autoencoder, Again&lt;/h2&gt;

&lt;p&gt;第 N 次討論 VAE (variational autoencoder).  之前從 AE (autoencoder) 出發，有一些手感。但用 deterministic autoencoder 延伸想像力到 probabilistic VAE 還是隔了一層~~紗~~山。有點像二十世紀初把古典力學加上一點量子想像 ($E = h\nu$) 得到氫原子的量子光譜。雖然結果對了，但只能用在特定的情況。&lt;/p&gt;

&lt;p&gt;或是從 “variational inference” 的出發, 掉入一堆數學中沒有抓到重點。&lt;/p&gt;

&lt;p&gt;我們這次從 gaph+variational inference 出發。引入 neural network 變成 deep learning variable model (DLVM)。再引入 encoder neural network for posterior.  另外我們會比較 variational EM 和 VAE 增加理解。&lt;/p&gt;

&lt;h2 id=&quot;ml-estimation-和-bayesian-inference-到底有什麼差別&quot;&gt;ML estimation 和 Bayesian inference 到底有什麼差別？&lt;/h2&gt;

&lt;p&gt;簡單說 ML estimation 把 unknown/hidden 視為 a &lt;strong&gt;“fixed parameter”&lt;/strong&gt; (上圖左上).  Bayesian inference 把 unknown/hidden 視為 &lt;strong&gt;“distribution”&lt;/strong&gt; described by a random variable (上圖左下).&lt;/p&gt;

&lt;p&gt;有時候我們也把 $p(x;\theta)$ 寫成 conditional distribution 形式 $p(x\mid\theta).$​  嚴格來說並不對。不過可以視為 Bayesian 詮釋的擴展。&lt;/p&gt;

&lt;p&gt;ML estimation 做法是微分上式，解 $\theta$ parameter.&lt;/p&gt;

&lt;p&gt;Bayesian 的觀念是: (1) $\theta$ 視為 hidden random variable; (2) 引入 hidden random variable $\mathbf{z}$ with $\theta$ as a parameter.&lt;/p&gt;

&lt;p&gt;我們假設 (1), 利用 Bayes formula&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta | x) = \frac{p(x | \theta) p(\theta)}{p(x)}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z | x; \theta ) = \frac{p(x | z; \theta) p(z; \theta)}{p(x)}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\theta}(z | x) = \frac{p_{\theta}(x | z) p_{\theta}(z)}{p(x)}&lt;/script&gt;

&lt;p&gt;&lt;u&gt;上式的術語和解讀&lt;/u&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Random variable $x$ :  post (事後) observations, (post) evidence. $p(x)$ 稱為 evidence distribution or marginal likelihood.&lt;/li&gt;
  &lt;li&gt;Random variable $\mathbf{z}$ : 相對於 $x$, $\mathbf{z}$ 是 prior (事前, 先驗) 並且是 hidden variable (i.e. not evidence).  擴展我們在 maximum likelihood 的定義，從 parameter 變成 random variable.  $p(z)$​​ &lt;strong&gt;稱為 prior distribution.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;注意 prior 是 distribution&lt;/strong&gt;,  不會出現在 ML, 因為 $z$​ 在 ML 是 parameter.  只有在 Bayesian 才有 prior (distribution)!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conditional distribution $p(x\mid z)$ :  likelihood (或然率)。擴展我們在 maximum likelihood 的定義，從 parameter dependent distribution or function 變成 conditional distribution.&lt;/li&gt;
  &lt;li&gt;Conditional distribution $p(z\mid x)$ ： &lt;strong&gt;posterior, 事後機率。就是我們想要求解的東西。&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;注意 posterior 是 conditional distribution&lt;/strong&gt;.  有人會以為 $p(z)$ 是 prior distribution, $p(x)$​ 是 posterior distribution. Wrong!&lt;/li&gt;
      &lt;li&gt;Posterior 不會出現在 ML, 只有在 Bayesian 才會討論 posterior (distribution)!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;簡言之：Posterior&lt;/strong&gt; $\propto$ &lt;strong&gt;Likelihood x Prior&lt;/strong&gt; $\to p(z \mid x) \propto {p(x \mid z) \times p(z)}$
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;一般我們忽略 $p(x)$ ，因為它和要 estimate 的 $z$​​ distribution (or parameter) 無關，視為常數忽略。&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;很好記: 事後 = 事前 x 喜歡 (likelihood).  如果很喜歡，才會有事後。如果不喜歡，事後不理 (0分)&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Prior 和 posterior (事前/先驗，事後) 都是 Bayesian 才有的說法。 ML (or Frequentist) 不會有 prior and posterior 說法。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;以通信為例，$z$ 是 transmitted signal (unknown),  $x$ 是 received signal,  $x = z + n$,  是 transmitted signal 加 noise.  如果只根據 $p(\text{received signal}\mid\text{transmitted signal}) = p(x\mid z)$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bayesian-inference-for-vae-思路&quot;&gt;Bayesian Inference for VAE 思路&lt;/h2&gt;

&lt;p&gt;我們的問題比較類似 (2), 引入一個 hidden variable, z, with parameter $\theta$.  這和 EM algorithm 的想法完全一樣。藉著引入 hidden variable to account for some incomplete information (參考 EM article of incomplete data).&lt;/p&gt;

&lt;p&gt;一般 Bayesian inference 是求 posterior $p(z\mid x; \theta)$, or maximize the likelihood $p(x \mid z; \theta)$.   我們待會談到 VAE，卻是要找 $p(x)$, i.e. marginal likelihood.  數學上是 $p(x) = \int_{z} p(x, z; \theta) dz = \int_{z} p(x \mid z; \theta)p(z) dz $; where $\theta$ 是 parameter, not a random variable.&lt;/p&gt;

&lt;p&gt;另一個表示式 $p(x)= \int_{z} p(z \mid x)p(x) dx$  顯然不行，因為 $p(x)$ 就是我們要找的 unknown.&lt;/p&gt;

&lt;p&gt;所以我們現在缺 likelihood $p(x\mid z)$ and prior $p(z)$.  $p(z)$ 不是問題，基本就是假設。會隨著 more evidence x 而被取代。我們在 VAE 一般用 N(0, 1).  理論上可以用其他的 distribution, but why bother.  現在問題就是如何求 posterior $p(x\mid z)$.  結論就是用 VAE 來 train 一個 $p(x\mid z)$.&lt;/p&gt;

&lt;h2 id=&quot;deterministic-neural-network-vs-probabilistic-bayesian-inference-how&quot;&gt;Deterministic Neural Network Vs. Probabilistic Bayesian Inference, How?&lt;/h2&gt;

&lt;p&gt;對於 random variable 如 $x$ or $z$,  總有兩個截然不同的面向：(1) (deterministic) distribution function, $p(x), p(z)$; 以及 (2) random sample $\mathbf{x} = {x_1, x_2, \cdots, x_k}$, $\mathbf{z} = {z_1, z_2, \cdots, z_k}.$    一般常用 deterministic function maps random samples $z_i = f(x_i)$ from $x$ space to $z$ space.   因此  $p(x)$ distribution 可以轉換成 $p(z)$ distribution.  實務上我們常常用 function 把一個 distribution 轉成另一個 distribution, 例如 uniform distribution to normal distribution.   Neural network 其實就是一個比較複雜的 (deterministic) function.  這部分沒有問題。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;問題是 Bayesian 需要 conditional distribution.&lt;/strong&gt;   如果 $z = f(x)$ 是一個 deterministic neural network (or any deterministic function).  在這種情況下，conditional probability $p(z\mid x)$ 在 given $x$ 時,  $z$ 卻是一個定值 ，無法變成 distribution (or a delta distribution)?  因為每一個 $x$ 只對應一個 $z$, 沒有所謂 distribution.&lt;/p&gt;

&lt;p&gt;因此如何讓 deterministic neural network 用於 Bayesian inference?  有以下幾種可能性：&lt;/p&gt;

&lt;h3 id=&quot;example-1two-neural-networks-from-a-hidden-random-variable-to-create-conditional-distribution--only-for-demonstration-not-use-here&quot;&gt;Example 1：Two neural networks from a hidden random variable to create conditional distribution.  Only for demonstration, not use here&lt;/h3&gt;

&lt;p&gt;Deterministic functions 可以產生 conditional probability.  如下例&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Conditional_probability_distribution&quot;&gt;https://en.wikipedia.org/wiki/Conditional_probability_distribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Consider the roll of a fair die and let $X=1$ if the number is even (i.e. 2, 4, or 6) and $X=0$ otherwise. Furthermore, let $Y=1$ if the number is prime (i.e. 2, 3, or 5) and $Y=0$ otherwise.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210821221517777.png&quot; alt=&quot;image-20210821221517777&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then the unconditional probability that $X=1$ is 3/6 = 1/2 (since there are six possible rolls of the die, of which three are even), whereas the probability that $X=1$ conditional on $Y=1$ is 1/3 (since there are three possible prime number rolls—2, 3, and 5—of which one is even).&lt;/p&gt;

&lt;p&gt;$X = f_1(Z)$ and $Y=f_2(Z)$   $Z$ 是 die 的 output random variable $1,2,\cdots,6$ 雖然 $f_1$ and $f_2$  都是 deterministic function, 但是 $P(Y\mid X)$ 的確是 distribution, 因為我們不知道 $X=1$ 到底對應 $Z=?$&lt;/p&gt;

&lt;p&gt;所以如果我們有一個 $Z$ random variable, 以及不同的 neural network $X = f_1(Z)$ and $Y = f_2(Z)$.   Then $p(Y\mid X)$  可以是一個 distribution 而非單一 value.&lt;/p&gt;

&lt;h4 id=&quot;example-2--given-input-經過-deterministic-nn-轉成-probabilistic-conditional-distribution&quot;&gt;Example 2:  Given Input 經過 Deterministic NN 轉成 Probabilistic Conditional Distribution&lt;/h4&gt;

&lt;p&gt;[@kingmaIntroductionVariational2019]&lt;/p&gt;

&lt;p&gt;一般的 differentiable feed-forward neural networks are a particularly flexible and computationally scalable type of &lt;strong&gt;function approximator.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A particularly interesting application is probabilistic models&lt;/strong&gt;, i.e. the use of neural networks for probability density functions (PDFs) or probability mass functions (PMFs) in probabilistic models (how?). Probabilistic models based on neural networks are computationally scalable since they allow for stochastic gradient-based optimization.&lt;/p&gt;

&lt;p&gt;We will denote a deep NN as a vector function:  NeuraNet(.).  In case of neural entwork based image classifcation, for example, nerual networks parameterize a categorical distrbution $p_{\theta}(y\mid \mathbf{x})$ over a class label $y$,  conditioned on an image $\mathbf{x}$.  ??? y is a single label or distribution?&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathbf{p} &amp;=\operatorname{NeuralNet}_{\boldsymbol{\theta}}(\mathbf{x}) \\
p_{\boldsymbol{\theta}}(y \mid \mathbf{x}) &amp;=\text { Categorical }(y ; \mathbf{p})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where the last operation of NeuralNet(.) is typical a softmax() function! such that $\Sigma_i p_i = 1$&lt;/p&gt;

&lt;p&gt;這是很有趣的觀點。 $\mathbf{x}$ and $\mathbf{p}$ 都是 deterministic, 甚至 softmax function 都是 deterministic.  但我們賦予最後的 $y$ probabilistic distribution 涵義！基本上 NN 分類網路都是如此 (e.g. VGG, ResNet, MobileNet)。&lt;/p&gt;

&lt;p&gt;例如 $\mathbf{x}$ 可能是一張狗照片， $\mathbf{p}$ 是 feature extraction of $\mathbf{x}$.  兩者都是 deterministic.   但最後 categorical function 直接把 $\mathbf{p}$  賦予多值的 (deterministic) distribution, 例如狗的機率 $p_1 = 0.8,$ 貓的機率  $p_2 = 0.15,$ 其他的機率  $p_3 = 0.05.$    這和我們一般想像的機率性 outcome,   同一個 $\mathbf{p}$ 有時 output 狗，有時 output 貓不同。&lt;/p&gt;

&lt;p&gt;數學上這只是 vector to vector conversion,   $\mathbf{p}$ 是 high dimension feature vector (e.g. 1024x1), $\mathbf{y} = [y_1, y_2, \cdots]$ 是 low dimension output vector (e.g. 3x1 or 10x1) summing to 1.  重點是這個 low dimension vector $\mathbf{y}$ 就是 conditional distribution!  &lt;strong&gt;也就是一個 sample $\mathbf{x}$ 就可以 output 一個 conditional distribution, 而不需要很多 $\mathbf{x}$ samples 產生 conditional distribution!&lt;/strong&gt;   這很像量子力學中一個電子就可以產生 wave distribution, 有點違反直覺。&lt;/p&gt;

&lt;p&gt;這似乎是把一個 random sample 轉換成一個 (deterministic) conditional distribution 的方式。不過是否是 general method, TBC.&lt;/p&gt;

&lt;p&gt;另外這裡的 $\theta$ 就是 neural network 的 weights, determinstic parameters to be optimzed.&lt;/p&gt;

&lt;h3 id=&quot;neural-network-and-dag-directed-acyclic-graph&quot;&gt;Neural Network and DAG (Directed Acyclic Graph)&lt;/h3&gt;

&lt;p&gt;我們 focus on directed probabilistic graphical models  (PGM) or Bayesian networks.
&lt;script type=&quot;math/tex&quot;&gt;p_{\boldsymbol{\theta}}\left(\mathbf{x}_{1}, \ldots, \mathbf{x}_{M}\right)=\prod_{j=1}^{M} p_{\boldsymbol{\theta}}\left(\mathbf{x}_{j} \mid P a\left(\mathbf{x}_{j}\right)\right)&lt;/script&gt;
where Pa(xj) is the set of parent variables of node j in the directed graph.&lt;/p&gt;

&lt;p&gt;Traditionally, each conditional probability distribution xx is parameterized as a lookup table or a linear model.&lt;/p&gt;

&lt;p&gt;A more flexible way to parameterize such conditional distributions is with neural networks.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\boldsymbol{\eta} &amp;=\operatorname{NeuralNet}(P a(\mathbf{x})) \\
p_{\boldsymbol{\theta}}(\mathbf{x} \mid P a(\mathbf{x})) &amp;=p_{\boldsymbol{\theta}}(\mathbf{x} \mid \boldsymbol{\eta})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;同樣這裡的 $\theta$ 就是 neural network 的 weights, determinstic parameters to be optimzed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;重要！我們用 $\theta$ 代表這個 neural network.  這個 $\theta$ neural network 的方向是從 hidden variable $Pa(\mathbf{x})$ 到 observations $\mathbf{x}$.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;deep-learning-latent-variable-model-dlvm-tractable-and-intractable&quot;&gt;Deep (Learning) Latent Variable Model (DLVM) Tractable and Intractable&lt;/h4&gt;

&lt;p&gt;以下我們用 hand-waving 方法說明幾個&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\boldsymbol{\theta}}(\mathbf{x})=\int p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}) d \mathbf{z}&lt;/script&gt;

&lt;p&gt;The above equation is the marginal likelihood or the model evidence, when taken as a function of $\theta$&lt;/p&gt;

&lt;p&gt;$\theta$ 代表這個 neural network.  這個 $\theta$ neural network 的方向是從 hidden variable $\mathbf{z}$ 到 observations $\mathbf{x}$.&lt;/p&gt;

&lt;p&gt;$p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})$ : joint distribution is tractable because it includes both evidence and latent&lt;/p&gt;

&lt;p&gt;$p_{\boldsymbol{\theta}}(\mathbf{x})$ : marginal likelihood is intractable in DLVM; 因此上式的積分也是 intractable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})=p_{\boldsymbol{\theta}}(\mathbf{z}) p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z})&lt;/script&gt;

&lt;p&gt;$p_{\boldsymbol{\theta}}(\mathbf{z})$ and $p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z})$ : prior and likelihood 一般 tractable because the joint distribution is tractable.  一般 prior 和 likelihood 是 tractable.&lt;/p&gt;

&lt;p&gt;$p_{\boldsymbol{\theta}}(\mathbf{z}\mid \mathbf{x})$: posterior is intractable in DLVM because marginal likelihood is intractable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})=\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{x})}&lt;/script&gt;

&lt;p&gt;In summary&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Joint distribution, prior, likelihood 通常是 tractable, 甚至有 analytic solution.&lt;/li&gt;
  &lt;li&gt;Marginal likelihood, posterior 通常是 intractable, 需要解但只有 approximate solution.
    &lt;ul&gt;
      &lt;li&gt;Posterior $p(z\mid x)$ =&amp;gt; discriminative problem!   given high dimension x to get a low dimension z, or $\theta$&lt;/li&gt;
      &lt;li&gt;Marginal likelihood p(x) =&amp;gt; generative problem!  generate a high dimension x; or sometimes given a low dimension z to generate dimensional x (conditional generative model)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;以下是一個例子。&lt;/p&gt;

&lt;h4 id=&quot;example-3-multivariate-bernoulli-data-3-產生-conditional-distribution-的方法和-2-一樣&quot;&gt;Example 3: Multivariate Bernoulli data (3 產生 conditional distribution 的方法和 2 一樣)&lt;/h4&gt;

&lt;p&gt;一個簡單的例子說明 hand-waving 的 assertion for the DLVM.&lt;/p&gt;

&lt;p&gt;Prior $p(z)$ 是簡單的 normal distribution.   Neural network 把 random sample $z$ 轉換成 $\mathbf{p}$, 再來 $\mathbf{p}$ 直接變成 Bernoulli distribution!  就像例三的 softmax 一樣。&lt;/p&gt;

&lt;p&gt;Likelihood $\log p(x\mid z)$ 因此也是簡單的 cross-entropy, i.e. maximum likelihood ~ minimum cross-entropy loss&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
p(\mathbf{z}) &amp;=\mathcal{N}(\mathbf{z} ; 0, \mathbf{I}) \\
\mathbf{p} &amp;=\text { DecoderNeuralNet }_{\boldsymbol{\theta}}(\mathbf{z}) \\
\log p(\mathbf{x} \mid \mathbf{z}) &amp;=\sum_{j=1}^{D} \log p\left(x_{j} \mid \mathbf{z}\right)=\sum_{j=1}^{D} \log \operatorname{Bernoulli}\left(x_{j} ; p_{j}\right) \\
&amp;=\sum_{j=1}^{D} x_{j} \log p_{j}+\left(1-x_{j}\right) \log \left(1-p_{j}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\forall p_j \in \mathbf{p}: 0 \le p_j \le 1$&lt;/p&gt;

&lt;p&gt;Joint distribution  $p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})=p_{\boldsymbol{\theta}}(\mathbf{z}) p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z})$​ 就是把兩者乘積。雖然看起來 messy, 還夾著 neural network, 但理論上 straightforward, 甚至可以寫出 analytical form.&lt;/p&gt;

&lt;p&gt;但反過來:  posterior $p(z\mid x)$,  marginal likelihood $p(x)$  即使在這麼簡單的 network, 都是難啃的骨頭！&lt;/p&gt;

&lt;h2 id=&quot;vae-and-dlvm&quot;&gt;VAE and DLVM&lt;/h2&gt;

&lt;p&gt;前面提到  基本就是把 intractable posterior inference and learning problem.&lt;/p&gt;

&lt;p&gt;Marginal likelihood, posterior 通常是 intractable, 需要解但只有 approximate solution.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Posterior $p(z\mid x)$ =&amp;gt; discriminative problem!   given high dimension x to get a low dimension z&lt;/li&gt;
  &lt;li&gt;Marginal likelihood p(x) =&amp;gt; generative problem!  generate a high dimension x; or sometimes given a low dimension z to generate dimensional x (conditional generative model)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;首先 target posterior $p_{\theta}(\mathbf{z}\mid \mathbf{x})$ :  注意，此處 $\theta$ 代表的 neural network (weights) from $\mathbf{z}$ to $\mathbf{x}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;引入 encoder neural network&lt;/strong&gt; $q_{\phi}(\mathbf{z}\mid x)$：注意，此處 $\phi$ 代表 neural network from $\mathbf{x}$ to $\mathbf{z}$.&lt;/p&gt;

&lt;p&gt;我們希望 optimize the variational parameter $\phi$ such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x}) \approx p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})&lt;/script&gt;

&lt;p&gt;就是讓 (tractable) encoder 近似 (intractable) posterior.&lt;/p&gt;

&lt;p&gt;現在問題是：這個 neural network 長得怎麼樣？以及如何把 deterministic neural network 轉換成 probabilistic distribution?&lt;/p&gt;

&lt;h3 id=&quot;example-4given-input-經過-deterministic-nn-轉成-parameters-of-a-random-variable-to-create-conditional-distribution-eg-vae-encoder&quot;&gt;Example 4：Given Input 經過 Deterministic NN 轉成 Parameters of A Random Variable to Create Conditional Distribution (e.g. VAE encoder)&lt;/h3&gt;

&lt;p&gt;Example 2 and 3 NN 產生 conditional distribution 的方式只能用在 discrete distribution.   對於 continuous distribution, NN 無法產生無限長的 distribution!  例如 VAE 使用 Normal distribution 如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
(\boldsymbol{\mu}, \log \boldsymbol{\sigma}) &amp;=\text { EncoderNeuralNet }_{\boldsymbol{\phi}}(\mathbf{x}) \\
q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x}) &amp;=\mathcal{N}(\mathbf{z} ; \boldsymbol{\mu}, \operatorname{diag}(\boldsymbol{\sigma}))
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Neural network 產生 $\mu, \log \sigma$ for normal distribution.  雖然這解決 deterministic to probabilistic 問題。但聽起來還是有點魔幻寫實方式把 deterministic to probabilistic.  這是 VAE 的實際做法。&lt;/p&gt;

&lt;p&gt;雖然的確產生 conditional distribtuion, 但似乎比直接產生 distribution 更不直觀！例如為什麼是 $\log \sigma$, 不是 $\sigma$ 或 $1/\sigma$ ? 另外只產生 $\mu, \log \sigma$ 兩個 parameters, 是否太簡化？  比起 softmax distribution 可能包含 10-100 parameters.&lt;/p&gt;

&lt;p&gt;Before we can answer this question, let me quote below and move on to algorithm.&lt;/p&gt;

&lt;p&gt;Typically, we use a single encoder neural network to perform posterior inference over all of the datapoints in our dataset. This can be contrasted to more traditional variational inference methods where the variational parameters are not shared, but instead separately and iteratively optimized per datapoint. The strategy used in VAEs of sharing variational parameters across datapoints is also called amortized variational inference (Gershman and Goodman, 2014). With amortized inference we can avoid a per-datapoint optimization loop, and leverage the efficiency of SGD.&lt;/p&gt;

&lt;h4 id=&quot;example-5-decoder--how-to-explain-pxmid-z-的-conditional-distribution&quot;&gt;Example 5: Decoder:  How to explain $p(x\mid z)$ 的 conditional distribution?&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&quot;&gt;https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s now make the assumption that p(z) is a standard Gaussian distribution and that $p(x\mid z)$ is a Gaussian distribution whose mean is defined by a deterministic function f of the variable of z and whose covariance matrix has the form of a positive constant c that multiplies the identity matrix I. The function f is assumed to belong to a family of functions denoted F that is left unspecified for the moment and that will be chosen later. Thus, we have (不是很 make sense!)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}(\boldsymbol{f(z)}) &amp;=\text { EncoderNeuralNet }_{\boldsymbol{\theta}}(\mathbf{z}) \\p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z}) &amp;=\mathcal{N}(\mathbf{x} ; \boldsymbol{f(z)}, c)\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;p(z) \equiv \mathcal{N}(0, I) \\
&amp;p(x \mid z) \equiv \mathcal{N}(f(z), c I) \quad f \in F \quad c&gt;0
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;似乎只能 heuristically 解釋，沒有很 solid math fondation.&lt;/p&gt;

&lt;h2 id=&quot;比較-variational-em-and-vae-algorithm&quot;&gt;比較 Variational EM and VAE Algorithm&lt;/h2&gt;

&lt;p&gt;Recap variational EM algorithm&lt;/p&gt;

&lt;h3 id=&quot;em-and-variation-em-algorithm-recap&quot;&gt;EM and Variation EM Algorithm Recap&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Goal:&lt;/strong&gt; (ML) estimate $\theta$ of $\arg \max_{\theta} \ln p(x;\theta)$  from posterior $p(z\mid x; \theta)$.&lt;/p&gt;

&lt;p&gt;Step 1: 為了 estimate $\theta$ 引入 hidden random variable $z$, log marginal likelihood (negative):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\ln p(\mathbf{x} \mid \boldsymbol{\theta}) &amp;= \mathcal{L}(q, \boldsymbol{\theta}) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}, \boldsymbol{\theta}) ) \\
&amp;= \underbrace{\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} \mid \boldsymbol{\theta})}{q(\mathbf{z})}}_{\text{ELBO}} + \underbrace{D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}, \boldsymbol{\theta}) )}_{\text{Gap of posterior}} \\
&amp;= \underbrace{\sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{x}, \mathbf{z} \mid \boldsymbol{\theta}) + \sum_{\mathbf{z}} -q(\mathbf{z}) \ln {q(\mathbf{z})}}_{\text{ELBO}}+ \underbrace{D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}, \boldsymbol{\theta}) )}_{\text{Gap of posterior}} \\
&amp;= \underbrace{E_{q(z)} \ln p(\mathbf{x}, \mathbf{z} \mid \boldsymbol{\theta}) + H(q)}_{\text{ELBO}} + \underbrace{D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}, \boldsymbol{\theta}) )}_{\text{Gap of posterior}} \\
&amp;= \underbrace{Q(q | \theta) + H(q)}_{\text{ELBO}} + \underbrace{D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}, \boldsymbol{\theta}) )}_{\text{Gap of posterior}} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;第一項 (negative) 加第二項 (self-entropy of q, positive) 稱為 ELBO. 第三項稱為 gap (positive).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Or another formulation (same as above but better notation to compare with DLVM or VAE)&lt;/p&gt;

&lt;p&gt;Let’s start with EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\ln p(\mathbf{x} ; \boldsymbol{\theta})&amp;=\mathcal{L}(q, \boldsymbol{\theta})+K L(q \| p) \\
\mathcal{L}(q, \boldsymbol{\theta}) &amp;= \int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z} \\
\mathrm{KL}(q \| p)&amp;= \int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;Step 2: 假設 posterior $p(z\mid x)$ 有 analytic soluiton, e.g. GMM 的 posterior 是 softmax funtion.&lt;/p&gt;

&lt;p&gt;We let $q(z) = p(z \mid x )$  and define the  $Q$ function (log joint distribution integration over posterior)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right) &amp;=\int p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\text {OLD }}\right) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) d \mathbf{z} \nonumber\\
&amp;=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{0 \mathrm{LD}}\right)}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap&lt;/strong&gt;
&lt;strong&gt;ELBO = Q function (negative value) + self-entropy (postive value)&lt;/strong&gt;
&lt;strong&gt;Q Function = log joint distribution (tractable) expectation over (approx.) posterior&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;此時可以用定義 EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\text{E-step, Minimize KL Gap : Compute}\quad &amp;p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\mathrm{OLD}}\right)\\
\text{M-step, Maximize ELBO : Evaluate}\quad &amp;\boldsymbol{\theta}^{\mathrm{NEW}}=\underset{\boldsymbol{\theta}}{\arg \max } Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right)
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;一般 $\eqref{eqQ}$ 的 joint distribution $p\left(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}\right)$ 包含完整的 data，容易計算或有 analytical solution.
大多的問題是 $\eqref{eqE}$ conditional or posterior distribution 是否容易計算，是否有 analytical solution.&lt;/p&gt;

&lt;h3 id=&quot;vae&quot;&gt;VAE&lt;/h3&gt;

&lt;p&gt;主要參考 [@kingmaIntroductionVariational2019].&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210901154112484.png&quot; alt=&quot;image-20210901154112484&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal A:&lt;/strong&gt; get the $\theta$ (and decoder $\phi$) is to $\arg \max_{\theta} \ln p_{\theta}(x)$  –&amp;gt; &lt;strong&gt;Should be arg max ELBO?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal B:&lt;/strong&gt; get the marginal likelihood:  $\ln_{\theta} p(x)$&lt;/p&gt;

&lt;p&gt;Step 1: same as above (引入 hidden random variable $z$ and decoder NN $\theta$)&lt;/p&gt;

&lt;p&gt;Step 2: 因為 posterior intractable, 引入另一個 encoder neural network ($\phi$) which is tractable&lt;/p&gt;

&lt;h3 id=&quot;em-algorithm-和-vae-的差別&quot;&gt;EM algorithm 和 VAE 的差別&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;EM posterior is tractable (Q funciton);  VAE posterior is intractable (沒有 analytical form). 我們用另一個 (tractable) neural network $\phi$ 去近似 (intractable) posterior.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\log p_{\boldsymbol{\theta}}(\mathbf{x}) &amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x})\right] \\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right] \\
&amp;=\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})} \frac{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right] \\
&amp;=\underbrace{\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}_{=\mathcal{L}_{\theta,\phi}{(\boldsymbol{x}})}+\underbrace{\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{q_{\boldsymbol{x}}(\mathbf{z} \mid \mathbf{x})}{p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}_{=D_{K L}\left(q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x}) \| p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})\right)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;把所有 EM 的 $q(z)$  變成 $q_{\phi}(z\mid x)$.    兩者完全一致&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap.&lt;/strong&gt;  兩者完全一致&lt;/li&gt;
  &lt;li&gt;第一項是 ELBO, $\mathcal{L}_{\theta,\phi}{(\boldsymbol{x}})$,
    &lt;ul&gt;
      &lt;li&gt;第二項是 KL divergence gap, $D_{K L} \ge 0$.&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;KL divergence 決定近似的 NN 和 true posterior 距離多遠。&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;KL divergence gap 也決定 ELBO bound 的 tightness.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;EM Training 方法：（&lt;strong&gt;假設 posterior is tractable&lt;/strong&gt;）&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;E-step: &lt;strong&gt;update posterior&lt;/strong&gt; ( tractable $q=p(z\mid x)$ ) to &lt;strong&gt;minimize KL gap&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;M-step: &lt;strong&gt;update parameter&lt;/strong&gt; $\theta$ to &lt;strong&gt;maximize ELBO/Marginal likelihood&lt;/strong&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;E-step and M-step Iterative update 永遠會增加 ELBO, 但這不一定是好事！很有可能會卡在 local maximum, 需要多個 initial condition to avoid some local maximum.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;VAE 的 posterior is intractable, 但巧妙的利用 encoder ($\phi$) + decoder ($\theta$) structure.  可以用原來的 image 為 golden 做 self-supervise learning.  使用 SGD 於多張 images to back-propagation &lt;strong&gt;同時 update&lt;/strong&gt; $\theta, \phi$  (&lt;strong&gt;這和 EM 不同，一石二鳥&lt;/strong&gt;)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap  $\to$  ELBO = Log Marginal Likelihood - KL Gap&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Update $\theta$ and $\phi$  to &lt;strong&gt;maximize ELBO implies maximize the marginal likelihood&lt;/strong&gt;,  equivalent to M-step in EM.&lt;/li&gt;
      &lt;li&gt;NN $\phi$  近似 posterior ($q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x}) \approx p_{\boldsymbol{\theta}}(\mathbf{z} \mid \mathbf{x})$), &lt;strong&gt;update $\phi$ implies to minimize KL gap&lt;/strong&gt;, equivalent to E-step in EM.&lt;/li&gt;
      &lt;li&gt;VAE 使用 SGD with mini-batch training iteratively,  並不保證 ELBO 永遠會增加 (or loss function 永遠變小)，但可以 leverage neural network trainging 的經驗，似乎收斂性還不錯，雖然無法證明 global 收斂性, 但不至於卡在太差的 local minimum.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210901180808893.png&quot; alt=&quot;image-20210901180808893&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VAE 和 AE neural network 不同，中間還卡了一個 random variable $z$!  如何 back-propagation 穿過 $z$? Reparameterization Trick!&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;question-maximize-elbo-等價-minimize-gap-between-posterior-and-q&quot;&gt;Question: Maximize ELBO 等價 Minimize GAP between posterior and q?&lt;/h4&gt;

&lt;p&gt;在 EM 這是兩件事：E-step: update posterior q = .. to minimize the gap between ;   M-step: update $\theta$  to maximize ELBO or the simplified version Q function (joint distribution over posterior distribution, remove self-entropy from ELBO)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap&lt;/strong&gt;
&lt;strong&gt;ELBO = Q function (negative value) + self-entropy (postive value)&lt;/strong&gt;
&lt;strong&gt;Q Function = log joint distribution (tractable) expectation over (approx.) posterior&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在 VAE 似乎是同一件事，let’s take a look of minimize KL gap between posterior and approx. q.&lt;/p&gt;

&lt;p&gt;此處 $g^&lt;em&gt;= \mu$ and $h^&lt;/em&gt; = \log \sigma$,  $g^&lt;em&gt;$ and $h^&lt;/em&gt;$ 其實就是 $\phi$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\left(g^{*}, h^{*}\right) &amp;=\underset{(g, h) \in G \times H}{\arg \min } K L\left(q_{x}(z), p(z \mid x)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \min }\left(\mathbb{E}_{z \sim q_{x}}\left(\log q_{x}(z)\right)-\mathbb{E}_{z \sim q_{x}}\left(\log \frac{p(x \mid z) p(z)}{p(x)}\right)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \min }\left(\mathbb{E}_{z \sim q_{x}}\left(\log q_{x}(z)\right)-\mathbb{E}_{z \sim q_{z}}(\log p(z))-\mathbb{E}_{z \sim q_{x}}(\log p(x \mid z))+\mathbb{E}_{z \sim q_{x}}(\log p(x))\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \max }\left(\mathbb{E}_{z \sim q_{x}}(\log p(x \mid z))-K L\left(q_{x}(z), p(z)\right)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \max }\left(\mathbb{E}_{z \sim q_{x}}\left(-\frac{\|x-f(z)\|^{2}}{2 c}\right)-K L\left(q_{x}(z), p(z)\right)\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;這個結果好像跟下面 maximize ELBO 的結論一樣？？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;結論一： 從 joint pdf 出發 (ELBO)&lt;/li&gt;
  &lt;li&gt;結論二：從 conditional pdf 出發 (posterior)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;vae-的-loss-function&quot;&gt;VAE 的 Loss Function&lt;/h3&gt;

&lt;p&gt;標準 bayesian formulated VAE 的 loss function for a specific $x_i$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;l_{i}(\theta, \phi)=-E_{z \sim q_{\phi}\left(z | x_{i}\right)}\left[\log p_{\theta}(x_{i} | z)\right]+K L\left(q_{\phi}(z | x_{i}) \|\,p(z)\right)&lt;/script&gt;

&lt;p&gt;數學等價上面的 ELBO x (-1)：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underbrace{\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}_{=\mathcal{L}_{\theta,\phi}{(\boldsymbol{x}})}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}) p(z)}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})p(z)}\right]\right]} = {\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})}{p(z)}\right]\right]} + {\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[\frac{ p(z)}{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\right]\right]}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= {\mathbb{E}_{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})}\left[\log \left[{p_{\boldsymbol{\theta}}(\mathbf{x}\mid \mathbf{z})}\right]\right]} - K L  { \left[{q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x}) \| { p(z)}}\right]}&lt;/script&gt;

&lt;h4 id=&quot;normal-distribution-assumption&quot;&gt;Normal Distribution Assumption&lt;/h4&gt;

&lt;h5 id=&quot;假設-pz-px--z-為-normal-distribution-vae-的-elbo-可以近似為&quot;&gt;假設 p(z)， p(x | z) 為 Normal distribution, VAE 的 ELBO 可以近似為&lt;/h5&gt;

&lt;p&gt;參考 &lt;a href=&quot;https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&quot;&gt;https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&lt;/a&gt;
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{z \sim q_{\phi}(z\mid x)}\left(-\frac{\|x-f(z)\|^{2}}{2 c}\right)-K L\left(q_{\phi}(z\mid x)\| p(z)\right)&lt;/script&gt;
第二項假設 prior p(z) and posterior q(z|x) 為 normal distribution, 有 close form.&lt;/p&gt;

&lt;p&gt;ELBO x (-1) 變成 VAE loss function.  此時拆解和解釋和 EM 有些不同。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;EM ELBO 留下 Q function of joint distribution，discard self-entropy independent of parameter.  因為我們目標是&lt;/strong&gt; $\arg \max_{\theta} Q$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;VAE ELBO loss 第一項則是 reconstruction loss; 第二項代表 regularization.  兩者是互相 balance, 而不是 minimize gap!&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;如果 input/output loss 很小，代表 variance 接近 0。 此時 regularization loss 變大，這是 overfit case like conventional autoencoder, not good.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;如果 regularization 很小，代表 variance 接近 1。此時 reconstruction loss 變大。 encoding or decoding 就不好。&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Log Marginal Likelihood = ELBO + KL Gap&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ELBO (negative value) = Q function (negative value) + self-entropy (postive value).&lt;/strong&gt; (for EM)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;-1 x ELBO = Loss (positive value) = reconstruction loss (positive value) + regularization loss (positive value).&lt;/strong&gt;  (for VAE)&lt;/p&gt;

&lt;p&gt;Very important:  maximize ELBO = minimize gap between posterior and q!!! (by xxx)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\left(g^{*}, h^{*}\right) &amp;=\underset{(g, h) \in G \times H}{\arg \min } K L\left(q_{x}(z), p(z \mid x)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \min }\left(\mathbb{E}_{z \sim q_{x}}\left(\log q_{x}(z)\right)-\mathbb{E}_{z \sim q_{x}}\left(\log \frac{p(x \mid z) p(z)}{p(x)}\right)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \min }\left(\mathbb{E}_{z \sim q_{x}}\left(\log q_{x}(z)\right)-\mathbb{E}_{z \sim q_{z}}(\log p(z))-\mathbb{E}_{z \sim q_{x}}(\log p(x \mid z))+\mathbb{E}_{z \sim q_{x}}(\log p(x))\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \max }\left(\mathbb{E}_{z \sim q_{x}}(\log p(x \mid z))-K L\left(q_{x}(z), p(z)\right)\right) \\
&amp;=\underset{(g, h) \in G \times H}{\arg \max }\left(\mathbb{E}_{z \sim q_{x}}\left(-\frac{\|x-f(z)\|^{2}}{2 c}\right)-K L\left(q_{x}(z), p(z)\right)\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;vae-elbo-用-sgd-optimization&quot;&gt;VAE ELBO 用 SGD Optimization&lt;/h3&gt;

&lt;p&gt;VAE 的 ELBO 是 joint optimization of parameters ($\phi$ and $\theta$) using SGD!  這和 EM algorithm 不同，也不保證遞增。&lt;/p&gt;

&lt;p&gt;VAE training 一般用 mini-batch. 假設 i.i.d dataset, the ELBO objective is the sum (or average) of each datapont ELBO:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\mathcal{L}_{\boldsymbol{\theta}, \phi}(\mathcal{D})=\sum_{\mathbf{x} \in \mathcal{D}} \mathcal{L}_{\boldsymbol{\theta}, \phi}(\mathbf{x}) \label{eqELBO3}
\end{align}&lt;/script&gt;

&lt;p&gt;$\eqref{eqELBO3}$ 的 gradient $\nabla_{\theta, \phi}\mathcal{L}_{\boldsymbol{\theta}, \phi}(\mathbf{x})$  is intratable.&lt;/p&gt;

&lt;p&gt;不過存在 unbiased estimators  $\tilde{\nabla}_{\theta, \phi}\mathcal{L}_{\boldsymbol{\theta}, \phi}(\mathbf{x})$，可以使用 mini-batch SGD.&lt;/p&gt;

&lt;p&gt;Unbiased gradients of the ELBO w.r.t. the generative model (也就是 decoder) parameter $\theta$ are simple:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\nabla_{\boldsymbol{\theta}} \mathcal{L}_{\boldsymbol{\theta}, \boldsymbol{\phi}}(\mathbf{x}) &amp;=\nabla_{\boldsymbol{\theta}} \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})\right] \label{eqGd1}\\
&amp;=\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\nabla_{\boldsymbol{\theta}}\left(\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})\right)\right] \label{eqGd2}\\
&amp; \simeq \nabla_{\boldsymbol{\theta}}\left(\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})\right) \label{eqGd3}\\
&amp;=\nabla_{\boldsymbol{\theta}}\left(\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})\right) \label{eqGd4}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;The last line $\eqref{eqGd4}$ is a simple Monte Carlo estimator of the second line $\eqref{eqGd2}$, where z in the last two lines $\eqref{eqGd3}$ and $\eqref{eqGd4}$ is a random sample from $q_{\phi}(z\mid x)$.&lt;/p&gt;

&lt;p&gt;Unbiased gradients w.r.t. the variational parameters $\phi$ are more difficult, since the ELBO’s expectation is taken w.r.t. the distribution $q_{\phi}(z\mid x)$, which is a function of $\phi$. In general&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\nabla_{\boldsymbol{\phi}} \mathcal{L}_{\boldsymbol{\theta}, \boldsymbol{\phi}}(\mathbf{x}) &amp;=\nabla_{\boldsymbol{\phi}} \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})-\log q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})\right] \\
&amp; \neq \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[\nabla_{\boldsymbol{\phi}}\left(\log p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z})-\log q_{\phi}(\mathbf{z} \mid \mathbf{x})\right)\right]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;我們可以用 reparameterization trick 計算 unbiased estimates of $\nabla_{\theta, \phi}\mathcal{L}_{\boldsymbol{\theta}, \phi}(\mathbf{x})$.&lt;/p&gt;

&lt;h3 id=&quot;reparameterization-trick&quot;&gt;Reparameterization Trick&lt;/h3&gt;

&lt;p&gt;Example 4 提到 VAE 的 forward path 如下圖右：input $x$ 經過 encoder NN $\phi$ 產生 parameters ($\mu, \log \sigma$) of a random variable $\mathbf{z}$  再 with distribution $q_{\phi}(z\mid x)$.  從 $\mathbf{z}$ 產生 sample f 經過 decoder NN $\theta$  (not shown here).  問題在於 (SGD) back propagation 整條路徑需要是 differentiable.  顯然 random variable $\mathbf{z}$ 的 sample process 不是 differentiable, back propagation 無法 update encoder NN $\phi$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/img-2021-09-14-23-34-51.png&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reparameterization trick 就是為了解決這個問題。How?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;把 $\mathbf{z} \sim q_{\phi}(z\mid x)$ 轉換 (differentiable and invertable) 成另一個 random variable $\boldsymbol{\epsilon}$, given $\mathbf{z}$ and $\phi$:&lt;/li&gt;
&lt;/ol&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{z}=\mathbf{g}(\boldsymbol{\epsilon}, \boldsymbol{\phi}, \mathbf{x})&lt;/script&gt;

&lt;p&gt;where the distribution of random variable $\boldsymbol{\epsilon}$ is indepedent of $\boldsymbol{\phi}, \mathbf{x}$.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Gradient of expectation under change of variable
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}[f(\mathbf{z})]=\mathbb{E}_{p(\epsilon)}[f(\mathbf{z})]&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;where $\mathbf{z}=\mathbf{g}(\boldsymbol{\epsilon}, \boldsymbol{\phi}, \mathbf{x})$, and the gradient and expectation becomes commutative,  結果如上圖右。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
   \nabla_{\phi} \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}[f(\mathbf{z})] &amp;=\nabla_{\phi} \mathbb{E}_{p(\boldsymbol{\epsilon})}[f(\mathbf{z})] \\
   &amp;=\mathbb{E}_{p(\boldsymbol{\epsilon})}\left[\nabla_{\phi} f(\mathbf{z})\right] \\
   &amp; \simeq \nabla_{\phi} f(\mathbf{z})
   \end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;更多的數學推導可以參考 ref[Maxwelling], 最後完整的形式如下：&lt;/p&gt;

&lt;h4 id=&quot;假設-factorized-gaussian-encoder&quot;&gt;假設 factorized Gaussian encoder&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{array}{r}
q_{\phi}(\mathbf{z} \mid \mathbf{x})=\mathcal{N}\left(\mathbf{z} ; \boldsymbol{\mu}, \operatorname{diag}\left(\boldsymbol{\sigma}^{2}\right)\right): \\
(\boldsymbol{\mu}, \log \boldsymbol{\sigma})=\text { EncoderNeuralNet }_{\boldsymbol{\phi}}(\mathbf{x}) \\
q_{\phi}(\mathbf{z} \mid \mathbf{x})=\prod_{i} q_{\phi}\left(z_{i} \mid \mathbf{x}\right)=\prod_{i} \mathcal{N}\left(z_{i} ; \mu_{i}, \sigma_{i}^{2}\right)
\end{array}&lt;/script&gt;

&lt;p&gt;做完 reparametrization, 我們得到&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\boldsymbol{\epsilon} &amp; \sim \mathcal{N}(0, \mathbf{I}) \\
(\boldsymbol{\mu}, \log \boldsymbol{\sigma}) &amp;=\text { EncoderNeuralNet }_{\phi}(\mathbf{x}) \\
\mathbf{z} &amp;=\boldsymbol{\mu}+\boldsymbol{\sigma} \odot \boldsymbol{\epsilon}
\end{aligned} %]]&gt;&lt;/script&gt;
where $\odot$ is the element-wise product.  The Jacobian of the transformation from $\boldsymbol{\epsilon}$ to $\mathbf{z}$ is:
&lt;script type=&quot;math/tex&quot;&gt;\log d_{\boldsymbol{\phi}}(\mathbf{x}, \boldsymbol{\epsilon})=\log \left|\operatorname{det}\left(\frac{\partial \mathbf{z}}{\partial \boldsymbol{\epsilon}}\right)\right|=\sum_{i} \log \sigma_{i}&lt;/script&gt;
and the posterior distribution is:
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\log q_{\phi}(\mathbf{z} \mid \mathbf{x}) &amp;=\log p(\boldsymbol{\epsilon})-\log d_{\phi}(\mathbf{x}, \boldsymbol{\epsilon}) \\
&amp;=\sum_{i} \log \mathcal{N}\left(\epsilon_{i} ; 0,1\right)-\log \sigma_{i}
\end{aligned} %]]&gt;&lt;/script&gt;
when $\mathbf{z}=\mathbf{g}(\boldsymbol{\epsilon}, \boldsymbol{\phi}, \mathbf{x})$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal A - Algorithm 1: Not VAE, since using minibatch.  Similar to ??&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;SGD optimization of ELBO.  這裡的 noise 包含 sampling of $p(\boldsymbol{\epsilon})$ 以及 mini-batch sampling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	$\mathcal{D}$ : Dataset&lt;/p&gt;

&lt;p&gt;​	$q_{\phi}(\mathbf{z}\mid \mathbf{x})$ : Inference model&lt;/p&gt;

&lt;p&gt;​	$p_{\theta}(\mathbf{z}, \mathbf{x})$ : Generative model&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	$\theta, \phi$ : Learned parameters&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ALG:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;($\theta, \phi$)  Initialize parameters&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;while&lt;/strong&gt; SGD not converged &lt;strong&gt;do&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	$\mathcal{M} \sim \mathcal{D}$ (Random minibatch of data)&lt;/p&gt;

&lt;p&gt;​	$\boldsymbol{\epsilon} \sim p(\boldsymbol{\epsilon})$  (Random noise for every datapoint in $\mathcal{M}$)&lt;/p&gt;

&lt;p&gt;​	Compute  $\tilde{\mathcal{L}}_{\theta, \phi}(\mathcal{M}, \boldsymbol{\epsilon})$  and gradients $\nabla_{\boldsymbol{\theta}, \phi} \tilde{\mathcal{L}}_{\boldsymbol{\theta}, \phi}(\mathcal{M}, \boldsymbol{\epsilon})$
​	Update $\theta$ and $\phi$ using SGD optimizer&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;end&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;full-covariance-gaussian-encoder&quot;&gt;Full-covariance Gaussian encoder&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{\phi}(\mathbf{z} \mid \mathbf{x})=\mathcal{N}(\mathbf{z} ; \boldsymbol{\mu}, \boldsymbol{\Sigma})&lt;/script&gt;

&lt;p&gt;A reparameterization of this distribution is given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I}) \\
&amp;\mathbf{z}=\boldsymbol{\mu}+\mathbf{L} \boldsymbol{\epsilon}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\mathbf{L}$ is a lower (or upper) triangular matrix, with non-zero entries on the diagonal.  The off-diagonal elements defines the correlations of elements in $\mathbf{z}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Goal A - Algorithm 2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Computation of unbiased estimate of &lt;strong&gt;single datapoint ELBO for example VAE&lt;/strong&gt; with a full-covariance Gaussian inference model and a factorized Bernoulli generative model. $\mathbf{L}_{mask}$ is a masking matrix with zeros on and above the diagonal, and ones below the diagonal.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	$\mathbf{x}$ : a datapoint, and optionally other conditioning information&lt;/p&gt;

&lt;p&gt;​	$\boldsymbol{\epsilon}$ : a random sample from $p(\boldsymbol{\epsilon}) =  \mathcal{N}(0, \mathbf{I})$&lt;/p&gt;

&lt;p&gt;​	$\boldsymbol{\theta}$ : Generative model parameter&lt;/p&gt;

&lt;p&gt;​	$\boldsymbol{\phi}$ : Inference model parameter&lt;/p&gt;

&lt;p&gt;​	$q_{\phi}(\mathbf{z}\mid \mathbf{x})$ : Inference model&lt;/p&gt;

&lt;p&gt;​	$p_{\theta}(\mathbf{z}, \mathbf{x})$ : Generative model&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Result:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;​	$\tilde{\mathcal{L}}$ : unbiased estimate of the signle-datapoint ELBO $\mathcal{L}_{\theta,\phi}(\mathbf{x})$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ALG:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
&amp;\left(\boldsymbol{\mu}, \log \boldsymbol{\sigma}, \mathbf{L}^{\prime}\right) \leftarrow \text { EncoderNeuralNet }_{\phi}(\mathbf{x}) \\
&amp;\mathbf{L} \leftarrow \mathbf{L}_{\text {mask }} \odot \mathbf{L}^{\prime}+\operatorname{diag}(\boldsymbol{\sigma}) \\
&amp;\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I}) \\
&amp;\mathbf{z} \leftarrow \mathbf{L} \boldsymbol{\epsilon}+\boldsymbol{\mu} \\
&amp;\tilde{\mathcal{L}}_{\text {logqz }} \leftarrow-\sum_{i}\left(\frac{1}{2}\left(\epsilon_{i}^{2}+\log (2 \pi)+\log \sigma_{i}\right)\right)_{i} &amp; \triangleright=q_{\boldsymbol{\phi}}(\mathbf{z} \mid \mathbf{x})\\
&amp;\tilde{\mathcal{L}}_{\operatorname{logpz}} \leftarrow-\sum_{i}\left(\frac{1}{2}\left(z_{i}^{2}+\log (2 \pi)\right)\right) &amp; \triangleright=p_{\boldsymbol{\theta}}(\mathbf{z})\\
&amp;\mathbf{p} \leftarrow \text { DecoderNeuralNet }_{\theta}(\mathbf{z}) \\
&amp;\tilde{\mathcal{L}}_{\operatorname{logpx}} \leftarrow \sum_{i}\left(x_{i} \log p_{i}+\left(1-x_{i}\right) \log \left(1-p_{i}\right)\right) &amp; \triangleright=p_{\boldsymbol{\theta}}(\mathbf{x} \mid \mathbf{z}) \\
&amp;\tilde{\mathcal{L}}=\tilde{\mathcal{L}}_{\operatorname{logpx}}+\tilde{\mathcal{L}}_{\operatorname{logpz}}-\tilde{\mathcal{L}}_{\operatorname{logqz}}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;p&gt;第一項 loss function 就是 reconstruction loss, 不過是 Bernoulli distribution，可以視爲 black-and-white image.  第二項是 prior loss gauge how far it is from normal distribution?  第三項是 regularization term? $\sigma = 1$ 是 minimum loss point.&lt;/p&gt;

&lt;h4 id=&quot;goal-b---estimation-of-marginal-likelihood-generative&quot;&gt;Goal B - Estimation of Marginal Likelihood (Generative)&lt;/h4&gt;

&lt;p&gt;在 VAE training $(\theta, \phi)$ 之後，下一步是可以 estimate marginal likelihood, $p_{\theta}(\mathbf{x})$, using &lt;strong&gt;important sampling&lt;/strong&gt; technique.  The marginal likelihood likelihood of a datapoint is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log p_{\boldsymbol{\theta}}(\mathbf{x})=\log \mathbb{E}_{q_{\phi}(\mathbf{z} \mid \mathbf{x})}\left[p_{\boldsymbol{\theta}}(\mathbf{x}, \mathbf{z}) / q_{\phi}(\mathbf{z} \mid \mathbf{x})\right]&lt;/script&gt;

&lt;p&gt;Taking random samples from $q_{\phi}(\mathbf{z} \mid \mathbf{x})$, a Monte Carlo estimator is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log p_{\boldsymbol{\theta}}(\mathbf{x}) \approx \log \frac{1}{L} \sum_{l=1}^{L} p_{\boldsymbol{\theta}}\left(\mathbf{x}, \mathbf{z}^{(l)}\right) / q_{\phi}\left(\mathbf{z}^{(l)} \mid \mathbf{x}\right)&lt;/script&gt;

&lt;p&gt;where each $\mathbf{z}^{(l)}\sim q_{\phi}(\mathbf{z} \mid \mathbf{x})$ is a random sample from the inference (i.e. encoder) model.&lt;/p&gt;

&lt;p&gt;如果讓 $L$ 足夠大 $L\to\infty$，這個 Monte Carlo approximate estimator 就會越來越接近 marginal likelihood estimation.&lt;/p&gt;

&lt;p&gt;相反 $L=1$， 基本就變成 VAE 的 ELBO estimation.&lt;/p&gt;

&lt;p&gt;先停在這裡。&lt;/p&gt;

&lt;h3 id=&quot;qa&quot;&gt;Q&amp;amp;A&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Decoder NN 的 probablistic interprestation 如何解釋？&lt;/li&gt;
  &lt;li&gt;ML (maximum marginal likelihood) objective ; maximize ELBO objective,  Minimize KL of $(q_{\phi}(x \mid z) | p_{\theta} (x\mid z) $)  objective.  這三個 objectives 的關係?
    &lt;ol&gt;
      &lt;li&gt;EM:  final ML objective :  first minimize KL objective (E-step);  then maximize ELBO objective (M-step); and iteration&lt;/li&gt;
      &lt;li&gt;VAE:  maximize ELBO objective!   Does it equal to Minimize KL objective? and equal to ML objective? (No, not equivalent?)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="ML" /><category term="VAE" /><category term="Autoencoder" /><category term="Variational" /><category term="EM" /><summary type="html"></summary></entry><entry><title type="html">Math ML - Maximum Likelihood Vs. Bayesian</title><link href="http://localhost:4000/ai/2021/08/17/Math_ML_Bayesian/" rel="alternate" type="text/html" title="Math ML - Maximum Likelihood Vs. Bayesian" /><published>2021-08-17T00:00:00+08:00</published><updated>2021-08-17T00:00:00+08:00</updated><id>http://localhost:4000/ai/2021/08/17/Math_ML_Bayesian</id><content type="html" xml:base="http://localhost:4000/ai/2021/08/17/Math_ML_Bayesian/">&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;[@poczosCllusteringEM2015]&lt;/li&gt;
  &lt;li&gt;[@matasExpectationMaximization2018] good reference&lt;/li&gt;
  &lt;li&gt;[@choyExpectationMaximization2017]&lt;/li&gt;
  &lt;li&gt;[@tzikasVariationalApproximation2008] excellent introductory paper&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation-vs-bayesian-inference&quot;&gt;Maximum Likelihood Estimation Vs. Bayesian Inference&lt;/h2&gt;

&lt;p&gt;ML estimation 和 Bayesian inference 到底有什麼差別？簡單說 ML estimation 把 unknown/hidden 視為 a &lt;strong&gt;“fixed parameter”&lt;/strong&gt;.  Bayesian inference 把 unknown/hidden 視為 &lt;strong&gt;“distribution”&lt;/strong&gt; described by a random variable.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bernoulli distribution&lt;/em&gt;：投擲硬幣正面的機率 $\theta$, 反面的機率 $1-\theta$. 連續投擲的正面/反面的次數分別是 x/(n-x).  Likelihood function, 其實就是 probability distribution  為&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(x; \theta) = p(x ; \theta) = \theta^{x}(1-\theta)^{n-x}&lt;/script&gt;

&lt;p&gt;有時候我們也把 $p(x;\theta)$ 寫成 conditional distribution 形式 $p(x\mid\theta).$​  嚴格來說並不對。不過可以視為 Bayesian 詮釋的擴展。&lt;/p&gt;

&lt;p&gt;ML estimation 做法是微分上式，解 $\theta$ parameter.&lt;/p&gt;

&lt;p&gt;Bayesian 的觀念是: (1) $\theta$ 視為 hidden random variable; (2) 引入 hidden random variable $z$ with $\theta$ as a parameter.&lt;/p&gt;

&lt;p&gt;我們假設 (1), 利用 Bayes formula&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta | x) = \frac{p(x | \theta) p(\theta)}{p(x)}&lt;/script&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z | x; \theta ) = \frac{p(x | z; \theta) p(z; \theta)}{p(x)}&lt;/script&gt;

&lt;p&gt;&lt;u&gt;上式的術語和解讀&lt;/u&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Random variable $x$ :  post (事後) observations, (post) evidence. $p(x)$ 稱為 evidence distribution or marginal likelihood.&lt;/li&gt;
  &lt;li&gt;Random variable $\theta$ : 相對於 $x$, $\theta$ 是 prior (事前, 先驗) 並且是 hidden variable (i.e. not evidence).  擴展我們在 maximum likelihood 的定義，從 parameter 變成 random variable.  &lt;strong&gt;$p(\theta)$​​ 稱為 prior distribution.&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;注意 prior 是 distribution&lt;/strong&gt;,  不會出現在 ML, 因為 $\theta$​ 在 ML 是 parameter.  只有在 Bayesian 才有 prior (distribution)!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conditional distribution $p(x\mid\theta)$ :  likelihood (或然率)。擴展我們在 maximum likelihood 的定義，從 parameter dependent distribution or function 變成 conditional distribution.&lt;/li&gt;
  &lt;li&gt;Conditional distribution $p(\theta\mid x)$ ： &lt;strong&gt;posterior, 事後機率。就是我們想要求解的東西。&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;注意 posterior 是 conditional distribution&lt;/strong&gt;.  有人會以為 $p(\theta)$ 是 prior distribution, $p(x)$​ 是 posterior distribution. Wrong!&lt;/li&gt;
      &lt;li&gt;Posterior 不會出現在 ML, 因為 $\theta$​ 在 ML 是 parameter.  只有在 Bayesian 才會討論 posterior (distribution)!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;簡言之：Posterior&lt;/strong&gt; $\propto$ &lt;strong&gt;Likelihood x Prior&lt;/strong&gt; $\to p(\theta \mid x) \propto {p(x \mid \theta) \times p(\theta)}$
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;一般我們忽略 $p(x)$ ，因為它和要 estimate 的 $\theta$​​ distribution (or parameter) 無關，視為常數忽略。&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;很好記: 事後 = 事前 x 喜歡 (likelihood).  如果很喜歡，才會有事後。如果不喜歡，事後不理 (0分)&lt;/li&gt;
      &lt;li&gt;Prior 和 posterior (事前/先驗，事後) 都是 Bayesian 才有的說法。 ML (or Frequentist) 不會有 prior and posterior 說法。&lt;/li&gt;
      &lt;li&gt;以通信為例，$z$ 是 transmitted signal (unknown),  $x$ 是 received signal,  $x = z + n$,  是 transmitted signal 加 noise.  如果只根據 $p(\text{received signal}\mid\text{transmitted signal}) = p(x\mid z)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;事前事後哪一個重要&quot;&gt;事前、事後，哪一個重要？&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;是否注意到一件很矛盾的事？要估計 posterior (事後),&lt;/strong&gt;  $p(\theta\mid x)$​​, &lt;strong&gt;必須要有 prior (事前),&lt;/strong&gt; $p(\theta)$​.&lt;/p&gt;

&lt;p&gt;那如果都已經有 $p(\theta)$​ 的 distribution, 就可以直接 estimate $\theta$​ 的特性 (e.g. mean, variance), 還需要 posterior 嗎？&lt;/p&gt;

&lt;p&gt;有兩個 answers:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bayesian 相信 evidence!  Prior 只是沒有 evidence 的一種猜測。不可靠的 prior 在更多的 evidence 後會轉變成更可靠的 posterior!&lt;/li&gt;
  &lt;li&gt;大多數情況，我們並不關心 prior 的 distribution, 而是關心 likelihood or posterior distribution!
    &lt;ul&gt;
      &lt;li&gt;在 ML estimation, 我們只關心 &lt;strong&gt;the specific $\theta$  (not distribution) to maximize the likelihood.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;在 ML extension to EM algorithm, 我們我們只關心 &lt;strong&gt;the specific $\theta$  to maximize $Q$ function&lt;/strong&gt; &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
      &lt;li&gt;在窮人的 Bayesian inference, MAP (Maximum A Posteriori) estimation,  我們只關心 &lt;strong&gt;posterior distribution 的 maximum.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;在 Bayesian inference, 同樣我們關心的是 &lt;strong&gt;posterior distribution&lt;/strong&gt; (例如 EAP - Expected A Posteriori), 而非 prior.&lt;/li&gt;
      &lt;li&gt;以實際應用：一般通信使用 $p(x\mid z)$, i.e. maximum likelihood; 或者 $p(z\mid x)$, i.e. MAP, to decode each bit information!   通常我們不需要 $p(z)$ ，除了偶爾在 MAP 會用到。一般我們假設 $p(z)$ by default, e.g. uniform distribution in communication.&lt;/li&gt;
      &lt;li&gt;在 ML 應用，Dirichlet, Gaussian, or W-Gaussian prior distribution 通常用於 default setting.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;以 Bayesian 而言，posterior (事後) 遠比 prior (事前) 重要！&lt;/strong&gt;  &lt;strong&gt;甚至  Posterior &amp;gt; Likelihood &amp;gt; Prior&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;所以針對 prior, 只要是合理的假設 (猜測)，一般都可以接受。因為 more evidence, $x$, 所得出的 posterior 會把 prior 的影響消除！&lt;/p&gt;

&lt;h2 id=&quot;真的-prior-information-先驗-怎麼辦&quot;&gt;真的 Prior Information (先驗) 怎麼辦?&lt;/h2&gt;

&lt;p&gt;Bayesian prior 只是一個 initial condition.  隨著 evidence 越多，posterior 逐漸 overtake prior.&lt;/p&gt;

&lt;p&gt;但如果有真的 prior information 如何處理，例如物理定律或者一些 rule (e.g. 左括號一定對應一個右括號)？&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Bayesian prior 的定義就是一個假設，並非是 hard rule.  不像哲學的先驗有拔高的地位。Bayesian 期待 rule 會從 evidence 學到。&lt;/li&gt;
  &lt;li&gt;如果 rule 無法反應在 evidence, 可能要考慮其他的 AI 方法，e.g. rule-based AI, or mixture model.&lt;/li&gt;
  &lt;li&gt;如果 rule 有反應在 evidence, 但 Bayesian 學不好。可以考慮 embedded the rule, e.g. rule violation penalty in the cost function during training, post-processing for hard rule, etc.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ml-em-map-and-bayesian-inference-difference&quot;&gt;ML, EM, MAP, and Bayesian Inference Difference&lt;/h2&gt;

&lt;p&gt;這幾種都是常見的 parameter estimator, 差別為何？&lt;/p&gt;

&lt;h4 id=&quot;ml-maximum-likelihood-estimator&quot;&gt;ML (Maximum likelihood) Estimator&lt;/h4&gt;

&lt;p&gt;$\theta_{MLE} = \arg_{\theta} \max  p(x\mid\theta)$   還是強調一下此處 $\theta$ 是 parameter, 不是 conditional distribution 中的 random variable.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt; (1) consistency, converges in probability to its true value; (2) almost unbiased; (3) 2nd order efficiency.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt; (1) point estimator, sensitive to assumption of distribution and parameter.&lt;/p&gt;

&lt;p&gt;另一個 ML twist 可能更常見：maximum log-likelihood estimator (MLL).  基本和 ML 等價。&lt;/p&gt;

&lt;p&gt;$\theta_{MLLE} = \arg_{\theta} \max  \log p(x\mid\theta)$&lt;/p&gt;

&lt;p&gt;Maximization of the log-likelihood criterion is equivalent to minimization of a Kullback Leibler divergence between the data and model distributions.&lt;/p&gt;

&lt;h4 id=&quot;em-estimator-extension-of-ml-for-hidden-data&quot;&gt;EM Estimator (Extension of ML for Hidden Data)&lt;/h4&gt;

&lt;p&gt;$\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} Q(\boldsymbol{\theta}^{t+1} \mid \boldsymbol{\theta}^{t})$ &lt;sup id=&quot;fnref:1:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;    iteratively get the ML estimation of parameter&lt;/p&gt;

&lt;p&gt;Q function 包含 posterior of hidden variable $z$,  已經半步 bayesian!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt; (1) point estimator, sensitive to assumption of distribution and parameter.&lt;/p&gt;

&lt;h4 id=&quot;map-maximum-a-posteriori-estimator&quot;&gt;MAP (Maximum A Posteriori) Estimator&lt;/h4&gt;

&lt;p&gt;$\theta_{MAP} =\arg_{\theta} \max p(\theta\mid x) = \arg_{\theta} \max p(x\mid\theta) p(\theta)$   此處 $\theta$ 是 random variable.&lt;/p&gt;

&lt;p&gt;窮人的 bayesian: 利用 posterior, 但只取 maximum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pros:&lt;/strong&gt;  unknown is a distribution instead of a fixed parameter, better for the non-stationary circumstance&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cons:&lt;/strong&gt;  (1) still point estimator, still sensitive to assumption?  (2) biased?&lt;/p&gt;

&lt;h4 id=&quot;bayesian-inference&quot;&gt;Bayesian Inference&lt;/h4&gt;

&lt;p&gt;Bayesian inference 的精神就是 posterior distribution.  至於從 posterior 再找 maximum (MAP), 或是平均 (EAP)&lt;/p&gt;

&lt;p&gt;$\theta_{EAP} =E[\theta\mid x]$, 或是 marginal distribution,  或是再進一步做 parameter estimation (e.g. EM) or variational inference, 都屬於 bayesian inference.  此處先不討論。&lt;/p&gt;

&lt;h3 id=&quot;bayesian-inference-and-directed-acyclic-graph-dag&quot;&gt;Bayesian Inference and Directed Acyclic Graph (DAG)&lt;/h3&gt;

&lt;p&gt;Bayesian inference 最有威力的部分是結合 DAG.  不然只是把簡單的問題複雜化。&lt;/p&gt;

&lt;p&gt;在 DAG model 中，可以一路用 conditional probablility back trace 到 root.  TBD&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://i.stack.imgur.com/BNspA.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;$Q(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}) = \langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{0 \mathrm{LD}}\right)}$​ &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="ML" /><category term="EM" /><category term="Bayesian" /><category term="MAP" /><summary type="html">Reference [@poczosCllusteringEM2015] [@matasExpectationMaximization2018] good reference [@choyExpectationMaximization2017] [@tzikasVariationalApproximation2008] excellent introductory paper</summary></entry><entry><title type="html">Math AI - From EM to Variational Bayesian Inference</title><link href="http://localhost:4000/ai/2021/08/16/Math_AI_Baysian_variational/" rel="alternate" type="text/html" title="Math AI - From EM to Variational Bayesian Inference" /><published>2021-08-16T07:10:08+08:00</published><updated>2021-08-16T07:10:08+08:00</updated><id>http://localhost:4000/ai/2021/08/16/Math_AI_Baysian_variational</id><content type="html" xml:base="http://localhost:4000/ai/2021/08/16/Math_AI_Baysian_variational/">&lt;script id=&quot;MathJax-script&quot; async=&quot;&quot; src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;&lt;/script&gt;

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
//MathJax.Hub.Config({
//  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
//});
&lt;/script&gt;

&lt;h2 id=&quot;main-reference&quot;&gt;Main Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[@matasExpectationMaximization2018] : good reference&lt;/li&gt;
  &lt;li&gt;[@tzikasVariationalApproximation2008] : excellent introductory paper&lt;/li&gt;
  &lt;li&gt;[@wikiVariationalBayesian2021]&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;em-algorithm&quot;&gt;EM Algorithm&lt;/h2&gt;

&lt;p&gt;EM 可以視為 MLE 的 extension to hidden state / data.&lt;/p&gt;

&lt;p&gt;Let’s start with EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align*}
\ln p(\mathbf{x} ; \boldsymbol{\theta})&amp;=F(q, \boldsymbol{\theta})+K L(q \| p) \\
F(q, \boldsymbol{\theta})&amp;=\int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z} \\
\mathrm{KL}(q \| p)&amp;= \int q(\mathbf{z}) \ln \left(\frac{p(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta})}{q(\mathbf{z})}\right) d \mathbf{z}
\end{align*} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right) &amp;=\int p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\text {OLD }}\right) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) d \mathbf{z} \nonumber\\
&amp;=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{0 \mathrm{LD}}\right)} \label{eqQ}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;此時可以用 $\eqref{eqQ}$ 定義 EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\text{E-step : Compute}\quad &amp;p\left(\mathbf{z} \mid \mathbf{x} ; \boldsymbol{\theta}^{\mathrm{OLD}}\right) \label{eqE}\\
\text{M-step : Evaluate}\quad &amp;\boldsymbol{\theta}^{\mathrm{NEW}}=\underset{\boldsymbol{\theta}}{\arg \max } Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{\mathrm{OLD}}\right) \label{eqM}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;一般 $\eqref{eqQ}$ 的 joint distribution $p\left(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}\right)$ 包含完整的 data，容易計算或有 analytical solution.
大多的問題是 $\eqref{eqE}$ conditional or posterior distribution 是否容易計算，是否有 analytical solution.&lt;/p&gt;

&lt;h2 id=&quot;variational-em-or-variational-bayesian-framework&quot;&gt;Variational EM or Variational Bayesian Framework&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Q&amp;amp;A 這裡的思路和前文 variation EM minimize KL gap 似乎不同？&lt;/strong&gt;&lt;br /&gt;
A: 這裏定義的 variational EM 比較是一般的定義。思路還是 maximize ELBO (or F free energy function), 但採取 divide-and-conquer 方法。可以和 graph model 結合。前文定義比較有問題。&lt;/p&gt;

&lt;p&gt;最簡單的話就是 hidden variable $\mathbf{z} = [z_1, z_2,\cdots,z_M]$  and $p(\mathbf{z}) = p(z_1)\cdots p(z_M)$.
什麼時候會有這種 distribution product?  主要是來自 graph model, 後面會說明。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q(\mathbf{z})=\prod_{i=1}^{M} q_{i}\left(z_{i}\right) \label{eqFactor}
\end{equation}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
F(q, \boldsymbol{\theta})=&amp; \int \prod_{i} q_{i}\left[\ln p (\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})-\sum_{i} \ln q_{i}\right] d \mathbf{z}\nonumber\\
=&amp; \int \prod_{i} q_{i} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i} d z_{i} - \sum_{i} \int \prod_{j} q_{j} \ln q_{i} d z_{i} \nonumber\\
=&amp; \int q_{j}\left[\int \ln p (\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i \neq j}\left(q_{i} d z_{i}\right)\right] d z_{j} -\int q_{j} \ln q_{j} d z_{j}-\sum_{i \neq j} \int q_{i} \ln q_{i} d z_{i} \nonumber\\
=&amp; \int q_{j} \ln \tilde{p} (\mathbf{x}, z_{j} ; \boldsymbol{\theta}) d z_{i}-\int q_{j} \ln q_{j} d z_{j} -\sum_{i \neq j} \int q_{i} \ln q_{i} d z_{i} \nonumber\\
=&amp;-\mathrm{KL}\left(q_{j} \| \tilde{p}\right)-\sum_{i \neq j} \int q_{i} \ln q_{i} d z \label{eqVarELBO}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\ln \tilde{p}\left(\mathbf{x}, z_{j} ; \boldsymbol{\theta}\right)=\langle\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})\rangle_{i \neq j} =E_{i \neq j} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) =\int \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \prod_{i \neq j}\left(q_{i} d z_{i}\right) \label{eqVarJ}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqVarELBO}$ 是 (variational, 因為有 KL divergence) lower bound, KL divergence 必大於 0, 負號後必小於 0.  第二項加上負號是 self-entropy 必大於 0.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q&amp;amp;A: 這裏 KL divergence between $q_j(z_j)$ and “joint distribution” $\tilde{p}(\mathbf{x}, z_{j} ; \boldsymbol{\theta})$, 似乎抵觸前文說的 KL divergence between $q(\mathbf{z})$ and joint distribution $p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})$ dimension 不對的問題&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
F(q, \boldsymbol{\theta})= \mathcal{L}(q, \boldsymbol{\theta})&amp;=\int_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} d\mathbf{z}  \\
&amp;\ne - D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z}, \mathbf{x}; \boldsymbol{\theta}) )
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; $\eqref{eqVarJ}$ 的 “joint distribution” $\tilde{p}$ 不是真的 joint distribution. 重點 $\tilde{p}$ 是不是一個 distribution: (1) $\tilde{p} \ge 0$, and (2) $\int \tilde{p}(\mathbf{x}, z_j; \boldsymbol{\theta})\, dz_j = 1$ for any $\mathbf{x}$.  From $\eqref{eqVarJ}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{p}(\mathbf{x}, z_j; \boldsymbol{\theta}) = \exp(E_{i \neq j} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})) \ge 0&lt;/script&gt;

&lt;p&gt;滿足 (1).  我們主要檢查 (2), how to prove? TBD&lt;/p&gt;

&lt;p&gt;直觀看出讓 KL 為 0，就是 $q_j(z_j) = \tilde{p}(x, z_j; \theta)$, 似乎就是最大值 (how about the self-entropy?).
也就是 optimal distribution $q_j^* (z_j)$ 是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln q_j^* \left(z_{j}\right)= E_{i \neq j} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) + \text{const.}&lt;/script&gt;

&lt;p&gt;上面的 const 可以由 distribution normalization 得到。所以我們可以得到一組 consistency conditions $\eqref{eqVarJ2}$ for the maximum of variational lower bound subject to $\eqref{eqFactor}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
q_{j}^{*}\left(z_{j}\right)=\frac{\exp E_{i \neq j} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{\int \exp E_{i \neq j}\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) d z_{j}} \quad\text{for}\,\, j=1,\cdots,M \label{eqVarJ2}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqVarJ2}$ 顯然不會有 explicit solution, 因為 $q_j$ factors 之間是相互 dependent.  A consistent solution 需要 cycling through these factors.  我們定義 Variational EM algorithm&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\text{Variational E-step : Evaluate}\quad &amp;q^{\mathrm{NEW}}(\mathbf{z})\quad\text{using above equations}\\
\text{Variational M-step : Find}\quad &amp;\boldsymbol{\theta}^{\mathrm{NEW}}=\underset{\boldsymbol{\theta}}{\arg \max } F\left(q^{\mathrm{NEW}}, \boldsymbol{\theta}\right) \label{eqM2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&quot;例一-linear-regression-filterestimate-a-noisy-signal&quot;&gt;例一： Linear Regression (filter/estimate a noisy signal)&lt;/h3&gt;

&lt;p&gt;我很喜歡這個例子。從簡單的 least-square error filter 進步到 Kalman filter.  類似的應用：deconvolution/equalization, channel estimation, speech recognition, frequency estimation, time series prediction, and
system identification.&lt;/p&gt;

&lt;h4 id=&quot;問題描述&quot;&gt;問題描述&lt;/h4&gt;

&lt;p&gt;考慮一個未知信號 $y(x) \in R, x \in \Omega ⊆ R^N$, i.e. $R^N \to R$.
我們想要 predict its value $t_* = y(x_&lt;em&gt;)$ at an arbitrary location $x_&lt;/em&gt; \in \Omega$.&lt;/p&gt;

&lt;p&gt;我們用 vector 表示 $(t_1, \cdots, t_N)$
 using a vector t = (t1,…, tN)T of N noisy observations tn = y(xn) + εn, at locations x = (x1,…, xN)T, xn ∈ , n = 1,…, N. The additive noise εn is commonly assumed to be independent, zero mean, Gaussian distributed:
&lt;script type=&quot;math/tex&quot;&gt;y(\mathbf{x})=\sum_{m=1}^{M} \omega_{m} \phi_{m}(\mathbf{x})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;注意 $y(x)$ 不是真正的 observables, 而是加上 noise 之後的 t 才是 observations.  我們的目標就是用 $\mathbf{t}$ 來 estimate $\mathbf{w}$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{t}=\boldsymbol{\Phi} \mathbf{w}+\boldsymbol{\varepsilon}&lt;/script&gt;

&lt;p&gt;The likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
p(\mathbf{t} ; \mathbf{w}, \beta)&amp;=N\left(\mathbf{t} \mid \mathbf{\Phi} \mathbf{w}, \beta^{-1} \mathbf{I}\right)\\
&amp;=(2 \pi)^{-\frac{N}{2}} \beta^{\frac{N}{2}} \exp \left(-\frac{\beta}{2}\|\mathbf{t}-\Phi \mathbf{w}\|^{2}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;三種解法圖式&quot;&gt;三種解法圖式&lt;/h4&gt;

&lt;p&gt;以下我們用三種 methodologies 用 $\mathbf{t}$ 來 estimate $\mathbf{w}$ (i.e. signal) and $\beta$ (i.e. noise if needed).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 1:&lt;/em&gt; ML Estimation
如果 number of parameters (w) is the same as the number of observations (t), the ML estimates are very sensitive to the model noise.  我們可以用 DAG (Directed Acyclic Graphic) 說明，如下圖 (a).  雙圓框 t 代表 observed random variable. 方框 (W, beta) 代表 parameter to be estimated.  單圓框（e.g. (b) W）代表 hidden random variable.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 2:&lt;/em&gt; 假設 weight W 是 random variable with imposed prior. 我們先用 a simple Bayesian model with stationary Gaussian prior on weight, 如下圖 (b).  以這個 model 而言，我們用 EM algorithm performs Bayesian inference.  結果 robust to noise, 類似 Kalman filter?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286850167880.jpg&quot; width=&quot;414&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Method 3:&lt;/em&gt; method 2 的一個缺點是假設 stationary Gaussian noise (i.e. $\beta$, a fixed value to be estimated, 無法 capture the local signal properties.  我們可以引入更複雜 spatially/temporally varying hierarchical model which is based on a non-stationary Gaussian prior for the weight, W and a hyperprior, $\beta$, 如下圖 (c).&lt;/p&gt;

&lt;p&gt;這麼複雜的 DAG 顯然無法用 EM algorithm 解，必須用本文的 “Variational EM Framework” infer values of the unknowns.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286850351205.jpg&quot; width=&quot;245&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;method-1-ml-for-vanilla-linear-regression&quot;&gt;Method 1, ML for Vanilla Linear Regression&lt;/h4&gt;

&lt;p&gt;始於 likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
p(\mathbf{t} ; \mathbf{w}, \beta)=(2 \pi)^{-\frac{N}{2}} \beta^{\frac{N}{2}} \exp \left(-\frac{\beta}{2}\|\mathbf{t}-\Phi \mathbf{w}\|^{2}\right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;假設 $\mathbf{w}, \beta$ 為 constant parameters (to be estimated).  Maximize the likelihood or log-likelihood 等價於 minimize $|\mathbf{t}-\Phi \mathbf{w}|^{2}$.  因此**maximal likelihood (ML) estimate of w 等價 least squares (LS) estimate.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\mathbf{w}_{L S}=\underset{w}{\arg \max } p(\mathbf{t} ; \mathbf{w}, \beta)=\underset{w}{\arg \min } E_{L S}(\mathbf{w})=\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)^{-1} \boldsymbol{\Phi}^{T} \mathbf{t} \label{eqLS}
\end{equation}&lt;/script&gt;

&lt;p&gt;很多情況 $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)$ 可能是 “ill-conditioned” and difficult to invert.  意味如果 observation t 包含 noise $\varepsilon$, noise 會嚴重干擾 $\mathbf{w}_{L S}$ estimation.&lt;/p&gt;

&lt;h5 id=&quot;例-1acommunication-equalizationdeconvolution&quot;&gt;例 1A：Communication equalization/deconvolution&lt;/h5&gt;

&lt;p&gt;Assuming a lowpass channel $\Phi = 1 + 0.9 z^{-1}$.  The equalizer $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)^{-1} \boldsymbol{\Phi}^{T}$ 變成 highpass filter; zero-forcing equalizer (ZFE).  如果 noise $\varepsilon$ 是 broadband noise, high frequency noise 會被放大。&lt;/p&gt;

&lt;p&gt;In the case of ML, 我們必須小心選 basis functions to ensure matrix $\left(\boldsymbol{\Phi}^{T} \boldsymbol{\Phi}\right)$ can be inverted and avoid “ill-condition”.  通常使用 sparse model with few basis functions.&lt;/p&gt;

&lt;h4 id=&quot;method-2-em-algorithm-for-bayesian-linear-regression&quot;&gt;Method 2, EM algorithm for Bayesian Linear Regression&lt;/h4&gt;

&lt;p&gt;Method 2 放寬 $w$ 從定值 fixed value 變成 distribution (random variable). Voila，這就是 Bayesian 精神！&lt;/p&gt;

&lt;p&gt;A Bayesian treatment of the linear model begins by assigning a prior distribution to the weights of the model. This introduces bias in the estimation but also greatly reduces its variance, which is a major problem of the ML estimate.&lt;/p&gt;

&lt;p&gt;此處我們用 common choice of independent, zero-mean, Gaussian prior distribution for the weights of the linear model:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{w} ; \alpha)=\prod_{m=1}^{M} N\left(w_{m} \mid 0, \alpha^{-1}\right)&lt;/script&gt;

&lt;p&gt;當然假設 zero-mean 聽起來有點奇怪，有可能引入 bias, 但好處是有 regularization 的效果，儘量讓 $w_m$ 不要太大。&lt;/p&gt;

&lt;p&gt;Bayesian inference 接下來是計算 posterior distribution of the hidden variable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
p(\mathbf{w} \mid \mathbf{t} ; \alpha, \beta)=\frac{p(\mathrm{t} \mid \mathbf{w} ; \beta) p(\mathbf{w} ; \alpha)}{p(\mathbf{t} ; \alpha, \beta)} \label{eqMAP}
\end{equation}&lt;/script&gt;

&lt;p&gt;$\eqref{eqMAP}$ 分母部分進一步展開：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{t} ; \alpha, \beta)=\int p(\mathbf{t} \mid \mathbf{w} ; \beta) p(\mathbf{w} ; \alpha) d \mathbf{w}=N\left(\mathbf{t} \mid 0, \beta^{-1} \mathbf{I}+\alpha^{-1} \mathbf{\Phi} \boldsymbol{\Phi}^{T}\right)&lt;/script&gt;

&lt;p&gt;$\eqref{eqMAP}$，posterior of the hidden variable，可以寫成：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
p(\mathbf{w} \mid \mathbf{t} ; \alpha, \beta)=N(\mathbf{w} \mid \boldsymbol{\mu}, \boldsymbol{\mathbf{\Sigma}}) \label{eqPost}
\end{equation}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\boldsymbol{\mu} &amp;=\beta \boldsymbol{\Sigma} \Phi^{T} \mathbf{t} \label{eqMean}\\
\boldsymbol{\Sigma} &amp;=\left(\beta \boldsymbol{\Phi}^{T} \boldsymbol{\Phi}+\alpha \mathbf{I}\right)^{-1} \label{eqVar}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;可以證明，$\alpha, \beta$ 可以用以下的 maximum likelihood estimate.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\left(\alpha_{\mathrm{ML}}, \beta_{\mathrm{ML}}\right)=&amp; \underset{\alpha, \beta}{\arg \min }\left\{\log \left|\beta^{-1} \mathbf{I}+\alpha^{-1} \boldsymbol{\Phi} \boldsymbol{\Phi}^{T}\right|\right. \nonumber \\
&amp;\left.+\mathbf{t}^{T}\left(\beta^{-1} \mathbf{I}+\alpha^{-1} \boldsymbol{\Phi} \boldsymbol{\Phi}^{T}\right)^{-1} \mathbf{t}\right\} \label{eqab}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;直接計算 $\eqref{eqab}$ 非常困難。除了 $\eqref{eqab}$ 微分非常複雜。$\alpha, \beta \ge 0$ 是一個 constrained optimization 問題。 EM algorithm 提供一個有效的方法解 $\alpha, \beta$ and infer $\mathbf{w}$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;E-step&lt;/strong&gt; Compute the Q function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta) &amp;=\langle\ln p(\mathbf{t}, \mathbf{w} ; \alpha, \beta)\rangle_{p\left(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)}\right)} \\
&amp;=\langle\ln p(\mathbf{t} \mid \mathbf{w} ; \alpha, \beta) p(\mathbf{w} ; \alpha, \beta)\rangle_{p\left(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)}\right)} \\
&amp;=\left\langle\frac{N}{2} \ln \beta-\frac{\beta}{2}\left(\|\mathbf{t}-\boldsymbol{\Phi} \mathbf{w}\|^{2}\right)\right.\\
&amp;\left.+\frac{M}{2} \ln \alpha-\frac{\alpha}{2}\left(\|\mathbf{w}\|^{2}\right)\right\rangle+\text { const } \\
=&amp; \frac{N}{2} \ln \beta-\frac{\beta}{2}\left\langle\|\mathbf{t}-\boldsymbol{\Phi} \mathbf{w}\|^{2}\right\rangle+\frac{M}{2} \ln \alpha \\
&amp;-\frac{\alpha}{2}\left(\left\langle\|\mathbf{w}\|^{2}\right\rangle\right)+\text { const. }
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;三角括號是對 $p(\mathbf{w} \mid \mathbf{t} ; \alpha^{(t)}, \beta^{(t)})$ 的期望值。代入 $\eqref{eqPost}$ 得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)=&amp; \frac{N}{2} \ln \beta-\frac{\beta}{2}\left(\left\|\mathbf{t}-\boldsymbol{\Phi} \boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Phi}^{T} \boldsymbol{\Sigma}^{(t)} \boldsymbol{\Phi}\right]\right) \\
&amp;+\frac{M}{2} \ln \alpha-\frac{\alpha}{2}\left(\left\|\boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Sigma}^{(t)}\right]\right)+\mathrm{const}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where $\boldsymbol{\mu}^{(t)}$ and $\boldsymbol{\Sigma}^{(t)}$ are computed using the current estimates of the parameters $\alpha^{(t)}$ and $\beta^{(t)}$ :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\boldsymbol{\mu}^{(t)} &amp;=\beta^{(t)} \boldsymbol{\Sigma}^{(t)} \boldsymbol{\Phi}^{T} \mathbf{t} \\
\boldsymbol{\Sigma}^{(t)} &amp;=\left(\beta^{(t)} \mathbf{\Phi}^{T} \boldsymbol{\Phi}+\alpha^{(t)} \mathbf{I}\right)^{-1}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;M-step&lt;/strong&gt; Maximize $Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)$ with respect to $\alpha, \beta$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\left(\alpha^{(t+1)}, \beta^{(t+1)}\right)=\underset{(\alpha, \beta)}{\arg \max } Q^{(t)}(\mathbf{t}, \mathbf{w} ; \alpha, \beta)&lt;/script&gt;

&lt;p&gt;結果很簡單&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\alpha^{(t+1)} &amp;=\frac{M}{\left\|\boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Sigma}^{(t)}\right]} \label{eqa}\\
\beta^{(t+1)} &amp;=\frac{N}{\left\|\mathbf{t}-\boldsymbol{\Phi} \boldsymbol{\mu}^{(t)}\right\|^{2}+\operatorname{tr}\left[\boldsymbol{\Phi}^{T} \mathbf{\Sigma}^{(t)} \boldsymbol{\Phi}\right]} \label{eqb}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$\eqref{eqa}$ 和 $\eqref{eqb}$ 同時保證 $\alpha, \beta$ 永遠為正值。&lt;/p&gt;

&lt;p&gt;幾個重點：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;EM algorithm 有可能收斂到 local minimum; initial condition 很重要&lt;/li&gt;
  &lt;li&gt;注意 $\mathbf{w}$ 不是一個值，而是 distribution.  Inference of $\mathbf{w}$ 就是 posterior distribution $\eqref{eqPost}$.  Posterior distribution 的 mean $\eqref{eqMean}$ 稱為 Bayesian linear minimum mean squire error (LMMSE) inference for $\mathbf{w}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;method-3-variational-em-based-bayesian-linear-regression&quot;&gt;Method 3, Variational EM-based Bayesian Linear Regression&lt;/h4&gt;

&lt;p&gt;因為非常複雜，可以直接參考 [@tzikasVariationalApproximation2008].&lt;/p&gt;

&lt;h5 id=&quot;例-1bnoisy-signal-estimation&quot;&gt;例 1B：Noisy Signal Estimation&lt;/h5&gt;

&lt;p&gt;如下圖，Original signal 是虛線。實際的 observations ‘x’ 是 N = 50 samples 包含 signal + Gaussian noise ($\sigma^2 = 4 \times 10^{-2}$), 大約 SNR = 6.6dB.&lt;/p&gt;

&lt;p&gt;這裡的 basis functions 使用 Gaussian kernels&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi_{i}(\mathbf{x})=K\left(\mathbf{x}, \mathbf{x}_{i}\right)=\exp \left(-\frac{1}{2 \sigma_{\phi}^{2}}\left\|\mathbf{x}-\mathbf{x}_{i}\right\|^{2}\right)&lt;/script&gt;

&lt;p&gt;接下來用上述三個方法 (1) ML estimation; (2) EM-based Bayesian inference, and (3) variational EM-based Bayesian inference.&lt;/p&gt;

&lt;p&gt;(1) ML 基本上完全 follow noisy input, 所以最糟。這也符合期待，因為沒有任何 constraint on the weight. 所以所有的 weights 和 Gaussian kernel 都用來 fit noisy observations.  也就是說 N=50 samples/observations 對應 50 個 Gaussian kernel functions.  這可以從下圖的綠線看出。&lt;/p&gt;

&lt;p&gt;(2) Weights are constrained by prior, 此處 prior 假設 zero-mean Gaussian, which regularise the weight to be minimum; otherwise it will incur penalty.&lt;/p&gt;

&lt;p&gt;(3) 我們可以通過 $a, b$ 選取控制 non-zero weights, 類似 supporting vectors in SVM.  我們稱為 relevance vectors (RV). 此例只有 5 個  non-zero RV.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16287874512211.jpg&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;例二-bayesian-gmm&quot;&gt;例二： Bayesian GMM&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{x})=\sum_{j=1}^{M} \pi_{j} N\left(x ; \boldsymbol{\mu}_{j}, \mathbf{T}_{j}\right)&lt;/script&gt;

&lt;p&gt;where $\boldsymbol{\pi} =  \{ \pi_j \}$ 代表 weights or mixing coefficients.&lt;br /&gt;
$\boldsymbol{\mu} =  \{ \mu_{j} \} $ 是 means of Gaussian distribution.
$\mathbf{T} = \{ \mathbf{T}_{j} \}$ 是 precision (inverse covariance) matrices.   在 Bayesian GMM 我們更常用 precision matrix.&lt;/p&gt;

&lt;p&gt;Bayesian GMM 和一般 GMM 有什麼不同？ 最大的差別就是 $\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T}$ 不再是 parameters for estimation, 而是 random variables. 這有什麼好處？我們可以 impose or embedded our priors on $\boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T}$, 通常是 conjugate priors (i.e. no informative priors) &lt;sup id=&quot;fnref:prior&quot;&gt;&lt;a href=&quot;#fn:prior&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Bayesian GMM 的 graph model 如下。Hidden random variables 包含 $h = (\mathbf{Z}, \boldsymbol{\pi}, \boldsymbol{\mu}, \mathbf{T})$. Bayesian 的目標是找出 $p(h\mid x)$, 顯然不會有 analytic solution.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285137362672.jpg&quot; width=&quot;237&quot; /&gt;&lt;/p&gt;

&lt;p&gt;因此我們 divide-and-conquer 利用 $\eqref{eqVarJ2}$
假設 mean-field approximation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
q(\mathrm{h}) &amp;= q_{Z}(\mathbf{Z}) q_{\pi}(\boldsymbol{\pi}) q_{\mu T}(\boldsymbol{\mu}, \mathbf{T}) \\
q_{Z}(\mathbf{Z}) &amp;=\prod_{n=1}^{N} \prod_{j=1}^{M} r_{j n}^{z_{j n}} \\
q_{\pi}(\boldsymbol{\pi}) &amp;=\operatorname{Dir}\left(\boldsymbol{\pi} \mid\left\{\lambda_{j}\right\}\right) \\
q_{\mu T}(\boldsymbol{\mu}, \mathbf{T}) &amp;=\prod_{j=1}^{M} q_{\mu}\left(\boldsymbol{\mu}_{j} \mid \mathbf{T}_{j}\right) q_{T}\left(\mathbf{T}_{j}\right) \\
q_{\mu}\left(\boldsymbol{\mu}_{j} \mid \mathbf{T}\right) &amp;=\prod_{j=1}^{M} N\left(\boldsymbol{\mu}_{j} ; \mathbf{m}_{j}, \beta_{j} \mathbf{T}_{j}\right) \\
q_{T}(\mathbf{T}) &amp;=\prod_{j=1}^{M} W\left(\mathbf{T}_{j} ; \eta_{j}, \mathrm{U}_{j}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;看起來還是很複雜，不過 [@tzikasVariationalApproximation2008] 的 reference [27] 有詳細的公式。可以用“簡單” iterative update procedure 得到 optimal approximation $q(h)$ to the true posterior $p(h\mid x)$, 這就是 variational E-step.  下一步就是 variation M-step, 不贅述。&lt;/p&gt;

&lt;p&gt;Bayesian-GMM 比起 EM-GMM 到底有什麼好處。前面提到可以 impose priors. 如果沒有 prior information (i.e. use conjugate prior), 還有好處嗎？[@tzikasVariationalApproximation2008] 的說法是 Bayesian-GMM 不會有 singular solution, i.e. single data point Gaussian.  然而在 EM-GMM 常常會發生，如下圖 20 Gaussian components。一般 EM-GMM 解決的方法就是多跑幾次 randomize initial conditions to avoid it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285679550223.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;另一個好處是可以直接用 Bayesian GMM 決定 Gaussian component number, 而不需要用其他方法 (e.g. cross-validation)。實作如下圖。(a) 初始是 20 component Gaussians; (b), (c) model evolution; (d) 最終解只剩下 5 個 Gaussian components, 其餘 15 個 Gaussian components weight 為 0。注意收斂的過程中都沒有 singularity.&lt;/p&gt;

&lt;p&gt;這聽起來比較 significant, 不過有一個 catch, 就是 Dirichlet prior 不允許 component mixing weight 為 0.  因此如果要用 Bayesian-GMM 決定 Gaussian component number, 必須 remove $\boldsymbol{\pi} = \{ \pi_j \}$ from priors.  也就是把 $\boldsymbol{\pi} = \{ \pi_j \}$ 視為 parameter to be estimated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16285916007272.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Bayesian GMM 的 graph model 如下。注意此時的 $\pi$ 變成方框，代表 parameter to be estimated.  Hidden random variables 包含 $h = (\mathbf{Z}, \boldsymbol{\mu}, \mathbf{T})$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16286002562443.jpg&quot; width=&quot;237&quot; /&gt;&lt;/p&gt;

&lt;p&gt;根據新的 DAG, 我們可以分解如下：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;q(\mathrm{h})=q_{Z}(\mathbf{Z}) q_{\mu}(\boldsymbol{\mu}) q_{T}(\mathrm{T})\\
&amp;q_{Z}(\mathbf{Z})=\prod_{n=1}^{N} \prod_{j=1}^{M} r_{j n}^{z_{j n}} \\
&amp;q_{\mu}(\boldsymbol{\mu})=\prod_{j=1}^{M} N\left(\boldsymbol{\mu}_{j} \mid \mathrm{m}_{j}, \mathbf{S}_{j}\right) \\
&amp;q_{T}(\mathbf{T})=\prod_{j=1}^{M} W\left(\mathbf{T}_{j} \mid \eta_{j}, \mathbf{U}_{j}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;同樣經過一番計算 variational E-step and M-step (此處省略)，可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi_{j}=\frac{\sum_{n=1}^{N} r_{j n}}{\sum_{k=1}^{M} \sum_{n=1}^{N} r_{k n}}&lt;/script&gt;

&lt;p&gt;在 iteration 過程中，有一些 mixing coefficients $\{\pi_j\}$ 收斂到 0. 定性來說，variational bound 可以視為兩項之和：第一項是 likelihood function, 第二項是 prior 造成的 penalty term to penalizes complex models.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;Choy, Chris. 2017. “Expectation Maximization and Variational Inference (Part 1).” February 26, 2017.&lt;br /&gt;
&lt;a href=&quot;https://chrischoy.github.io/research/Expectation-Maximization-and-Variational-Inference/&quot;&gt;https://chrischoy.github.io/research/Expectation-Maximization-and-Variational-Inference/&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Matas, J., and O. Drbohlav. 2018. “Expectation Maximization Algorithm.” December 1, 2018.&lt;br /&gt;
&lt;a href=&quot;https://cw.fel.cvut.cz/old/_media/courses/a4b33rpz/pr_11_em_2017.pdf&quot;&gt;https://cw.fel.cvut.cz/old/_media/courses/a4b33rpz/pr_11_em_2017.pdf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Poczos, Barnabas. 2015. “Cllustering and EM.” 2015.&lt;br /&gt;
&lt;a href=&quot;https://www.cs.cmu.edu/~epxing/Class/10715/lectures/EM.pdf&quot;&gt;https://www.cs.cmu.edu/~epxing/Class/10715/lectures/EM.pdf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Tzikas, Dimitris G., Aristidis C. Likas, and Nikolaos P. Galatsanos. 2008. “The Variational Approximation for Bayesian Inference.”   &lt;em&gt;IEEE Signal Processing Magazine&lt;/em&gt; 25 (6): 131–46.&lt;br /&gt;
&lt;a href=&quot;https://doi.org/10.1109/MSP.2008.929620&quot;&gt;https://doi.org/10.1109/MSP.2008.929620&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:prior&quot;&gt;
      &lt;p&gt;Dirichlet for $\boldsymbol{\pi}$.  Gauss-Wishart for ($\boldsymbol{\mu}, \mathbf{T})$ &lt;a href=&quot;#fnref:prior&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="ML" /><category term="EM" /><category term="Bayesian" /><summary type="html"></summary></entry><entry><title type="html">English</title><link href="http://localhost:4000/2021/08/03/English/" rel="alternate" type="text/html" title="English" /><published>2021-08-03T00:00:00+08:00</published><updated>2021-08-03T00:00:00+08:00</updated><id>http://localhost:4000/2021/08/03/English</id><content type="html" xml:base="http://localhost:4000/2021/08/03/English/">&lt;h1 id=&quot;語音語調和節奏&quot;&gt;語音語調和節奏&lt;/h1&gt;

&lt;p&gt;語音：pronunciation (word)
語調：intonation (sentence)
節奏：rhymes: biggest problem!!! for Chinese&lt;/p&gt;

&lt;p&gt;Isochrone:  Chinese word is unit time!! syllable-timed
stress-timed language: english
mora-timed language: Japanese&lt;/p&gt;

&lt;p&gt;https://www.youtube.com/watch?v=VMDhdaMkeBU&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><summary type="html">語音語調和節奏</summary></entry><entry><title type="html">Math AI - ML Estimation To EM Algorithm For Hidden Data</title><link href="http://localhost:4000/ai/2021/06/30/MLE_to_EM/" rel="alternate" type="text/html" title="Math AI - ML Estimation To EM Algorithm For Hidden Data" /><published>2021-06-30T16:29:08+08:00</published><updated>2021-06-30T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/06/30/MLE_to_EM</id><content type="html" xml:base="http://localhost:4000/ai/2021/06/30/MLE_to_EM/">&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&lt;/script&gt;

&lt;h2 id=&quot;main-reference&quot;&gt;Main Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;[@poczosCllusteringEM2015]&lt;/li&gt;
  &lt;li&gt;[@matasExpectationMaximization2018] good reference&lt;/li&gt;
  &lt;li&gt;[@choyExpectationMaximization2017]&lt;/li&gt;
  &lt;li&gt;[@tzikasVariationalApproximation2008] excellent introductory paper&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation-mle-和應用&quot;&gt;Maximum Likelihood Estimation (MLE) 和應用&lt;/h2&gt;

&lt;p&gt;Maximum likelihood estimation (MLE) 最大概似估計是一種估計模型參數的方法。適用時機在於手邊有模型，但是模型參數有無限多種，透過真實觀察到的樣本資訊，想辦法導出最有可能產生這些樣本結果的模型參數，也就是挑選使其概似性(Likelihood)最高的一組模型參數，這系列找參數的過程稱為最大概似估計法。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bernoulli distribution&lt;/em&gt;：投擲硬幣正面的機率 $\theta$, 反面的機率 $1-\theta$. 連續投擲的正面/反面的次數分別是 H/T.  Likelihood function 為&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f(\theta, H, T)=\theta^{H}(1-\theta)^{T}&lt;/script&gt;

&lt;p&gt;MLE 在無限個 $\theta$ 中，找到一個使概似性最大的 $\theta$, i.e. $\widehat{\theta}_{\mathrm{MLE}} =\arg \max _{\theta} {\theta^{H}(1-\theta)^{T}}$&lt;/p&gt;

&lt;p&gt;只要 likelihood function 一次微分，可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\widehat{\theta}_{M L E}=\frac{H}{T+H}&lt;/script&gt;

&lt;p&gt;就是平均值，推導出來的模型參數符合直覺。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Normal distribution&lt;/em&gt;： 假設 mean unknown, variance known, 我們可以用 maximum log-likelihood function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underset{\mu}{\operatorname{argmax}} f\left(x_{1}, \ldots, x_{n}\right) \Rightarrow \underset{\mu}{\operatorname{argmax}} \log f\left(x_{1}, \ldots, x_{n}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
&amp;\frac{\mathrm{d}}{d \mu}\left(\sum_{i=1}^{n}-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}\right)=\sum_{\mathrm{i}=1}^{\mathrm{n}} \frac{\left(x_{i}-\hat{\mu}\right)}{\sigma^{2}}=\sum_{i=1}^{n} x_{i}-n \hat{\mathrm{u}}=0 \\
&amp;\hat{\mu}=\overline{\mathrm{X}}=\frac{\sum_{i=1}^{n} x_{i}}{n}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;微分的結果告訴我們，樣本的平均值，其實就是母體平均值 $\mu$ 最好的估計！又是一個相當符合直覺的答案，似乎 MLE 只是用來驗證直覺的工具。&lt;/p&gt;

&lt;p&gt;這是一個錯覺，常見的 distribution (e.g. Bernoulli, normal distribution) 都是 exponential families.  可以證明 maximum log-likelihood functions of exponential families 都是 concave function, 沒有 local minimum. 非常容易用數值方法找到最佳解，而且大多有 analytical solution.&lt;/p&gt;

&lt;p&gt;但只要 distribution function 更複雜一點，例如兩個 normal/Gaussian distribution weighted sum to 1, MLE 就非常難解。稱為 Gaussian mixture model (GMM) with 2 groups, GMM(2).&lt;/p&gt;

&lt;p&gt;另一種情況：MLE 雖然直接明瞭，但現實常常會遇到 missing data 或是 hidden data/state (state 也視為 data). 此時就需要 Expectation Maximization (EM) algorithm.&lt;/p&gt;

&lt;p&gt;例如 GMM(2) 可以視為有一個 hidden state $z$ with binary value, $p(x) = p(x\mid z=0) p(z=0) + p(x\mid z=1) p(z=1)$. $p(x\mid z=0)$ 和 $p(x\mid z=1)$ 分別是不同 normal distributions.&lt;/p&gt;

&lt;p&gt;以下先 Q&amp;amp;A maximum likelihood estimation (MLE) vs. expectation maximization (EM) 兩種算法。其實是視 EM 為 MLE 的推廣。 接著用四個簡單例子 (toy example) 說明 MLE 如何推廣到 EM.&lt;/p&gt;

&lt;h2 id=&quot;qa-of-mle-versus-em&quot;&gt;Q&amp;amp;A of MLE Versus EM&lt;/h2&gt;

&lt;p&gt;Q: Why EM is a special case of MLE?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the problem can be formulated as MLE parameter estimation of incomplete/hidden data.  Then EM algorithm 的 E-step is guessing incomplete/hidden data; M-step 就對應 MLE parameter estimation with modification (見本文後段)。&lt;/li&gt;
  &lt;li&gt;EM M-Step is essentially a MLE parameter estimation with modification.&lt;/li&gt;
  &lt;li&gt;EM can be seen as an iterative MLE.  EM may converge at local minimum during iteration.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Q: How EM can be used for to parameter estimation and incomplete/hidden data estimation?&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For Bayesian, 兩者可以視為同一類。Unknown parameters 亦可以視為 missing data with distribution.  此時 EM algorithm 相當于 2D &lt;strong&gt;coordinate descent&lt;/strong&gt; (energy) optimization [@wikiCoordinateDescent2021], different from &lt;strong&gt;gradient descent&lt;/strong&gt;.  EM 的 E-step 對應 (conditional) distribution coordinate descent; M-step 對應 parameter coordinate descent.&lt;/li&gt;
  &lt;li&gt;For Frequentist (古典統計), E-step is guessing incomplete/hidden data; M-step 就對應 MLE parameter estimation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;toy-example-matasexpectationmaximization2018&quot;&gt;Toy Example [@matasExpectationMaximization2018]&lt;/h2&gt;

&lt;h3 id=&quot;前提摘要&quot;&gt;前提摘要&lt;/h3&gt;
&lt;p&gt;一個簡單例子觀察 temperature and amount of snow (溫度和雪量, both are binary input) 的 joint probability depending on two “scalar factors” $a$ and $b$ as $p(t, s | a, b)$&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$a$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$5a$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$3b$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$b$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;注意 $a$ and $b$ are parameters, 不是 conditional probability.
另外因為機率和為 1 做為一個 constraint: $6a + 4b = 1$&lt;/p&gt;

&lt;h3 id=&quot;例一-mle&quot;&gt;例一: MLE&lt;/h3&gt;
&lt;p&gt;一個 ski-center 觀察 $N$ 天的溫度和雪量得到以下的統計，$N_{ij} \in \mathbf{I}$, 如何估計 $a$ and $b$?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{00}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{01}$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{10}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$N_{11}$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Likelihood function (就是 joint pdf of $N$ repeat experiments)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathcal{T} \mid a, b)= C a^{N_{00}}(5 a)^{N_{01}}(3 b)^{N_{10}}(b)^{N_{11}}&lt;/script&gt;

&lt;p&gt;where $C = (\Sigma N_{ij})! / \Pi (N_{ij}!)$ 是 MLE 無關的常數&lt;/p&gt;

&lt;p&gt;問題改成 maximum log-likelihood with constraint and $C’ = \ln C$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(a, b, \lambda) = C' + N_{00} \ln a+N_{01} \ln 5 a+N_{10} \ln 3 b+N_{11} \ln b+\lambda(6 a+4 b-1)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{gathered}
\frac{\partial L}{\partial a}=N_{00} \frac{1}{a}+N_{01} \frac{1}{a}+6 \lambda=0 \\
\frac{\partial L}{\partial b}=N_{10} \frac{1}{b}+N_{11} \frac{1}{b}+4 \lambda=0 \\
\frac{\partial L}{\partial \lambda}=6 a+4 b - 1 = 0
\end{gathered}&lt;/script&gt;

&lt;p&gt;上述方程式的解為
&lt;script type=&quot;math/tex&quot;&gt;a=\frac{N_{00}+N_{01}}{6 N} \quad b=\frac{N_{10}+N_{11}}{4 N} \quad \lambda = -(N_{00}+N_{01}+N_{10}+N_{11})=-N&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;結果很直觀。其實就是利用大數法則： $a\cdot N \sim N_{00}; 5a\cdot N\sim N_{01}; 3b\cdot N\sim N_{10}; b\cdot N\sim N_{11}$
再來大數法則 (a+5a)N~N00+N01; (3b+b)N~N10+N11 =&amp;gt; a = .. ; b = …&lt;/p&gt;

&lt;h3 id=&quot;例二-incompletehidden-data&quot;&gt;例二 incomplete/hidden Data&lt;/h3&gt;
&lt;p&gt;假設我們無法觀察到完整的”溫度和雪量“；而是“溫度或雪量”，有時“溫度”，有時“雪量”，但不是同時。對應的不是 joint pdf, 而是 marginal pdf 如下：
&lt;img src=&quot;/media/16247543929429/16265417789274.jpg&quot; alt=&quot;-w451&quot; style=&quot;zoom:40%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;觀察如下：
&lt;img src=&quot;/media/16247543929429/16265418866309.jpg&quot; alt=&quot;-w274&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The Lagrangian (log-likelihood with constraint)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(a, b, \lambda)=T_{0} \ln 6 a+T_{1} \ln 4 b+S_{0} \ln (a+3 b)+S_{1} \ln (5 a+b)+\lambda(6 a+4 b-1)&lt;/script&gt;

&lt;p&gt;此時的方程式比起之前複雜的多，不一定有 close-form solution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{gathered}
\frac{\partial L}{\partial a}=\frac{T_{0}}{a}+\frac{S_{0}}{a+3 b}+\frac{5 S_{1}}{5 a+b}+6 \lambda=0 \\
\frac{\partial L}{\partial b}=\frac{T_{1}}{b}+\frac{3 S_{0}}{a+3 b}+\frac{S_{1}}{5 a+b}+4 \lambda=0 \\
6 a+4 b=1
\end{gathered}&lt;/script&gt;

&lt;p&gt;如果用大數法則：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$6a \cdot(T_0+T_1) \sim T0; \, 4b\cdot(T_0+T_1) \sim T_1$&lt;/li&gt;
  &lt;li&gt;$(a+3b) \cdot (S_0+S_1)\sim S_0; \, (5a+b)\cdot(S_0+S_1) \sim S_1$ 
注意不論 1. or 2. 都滿足 $6a+4b = 1$ constraint, 可以用來估計 $a$ and $b$.
問題是我們要用那一組 $(a, b)$?  單獨用一組都會損失一些 information, 應該要 combine 1 and 2 的 information, how?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;思路一&lt;/strong&gt; 平均 (a, b) from 1 and 2.  但這不是好的策略，因為平均 (a,b) 不一定滿足 constraint. 在這個 case 因為 linear constraint, 所以平均 (a,b) 仍然滿足 constraint.  但對於更複雜 constraint, 平均並非好的方法。&lt;/p&gt;

&lt;p&gt;更重要的是平均並無法代表 maximum likelihood in the above equation.  我們的目標是 maximum likelihood, 平均 (a, b) 完全無法保證會得到更好的 likelihood value!&lt;/p&gt;

&lt;p&gt;或者把 (a,b) from 1 or 2 代入上述 likelihood function 取大值。顯然這也不是最好的策略。因為一半的資訊被捨棄了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思路二&lt;/strong&gt; 比較好的方法是想辦法用迭代法解微分後的 Lagrange multiplier 聯立方程式。 (a, b) from 1. or 2. 只作為 initial solution, 想辦法從聯立方程式找出 iterative formula.  這似乎是對的方向，問題是 Lagrange multiplier optimization 是解聯立(level 1)微分方程式。不一定有 close form as in this example.  同時也無法保證收斂。另外如何找出 iterative formula 似乎是 case-by-case, 沒有一致的方式。
&lt;strong&gt;=&amp;gt; iterative solution is one of the key, but NOT on Lagrange multiplier (level 1)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;思路三&lt;/strong&gt; 既然是 missing data, 我們是否可以假設 $(a, b) \to$  fill missing data $\to$ update $(a, b) \to$  update missing data $\cdots$ 具體做法 
$N_{00} = T_0 \cdot \frac{1}{6} + S_0 \cdot \frac{a}{a+3b}$
$N_{01} = T_0 \cdot \frac{5}{6} + S_1 \cdot \frac{5a}{5a+b}$
$N_{10} = T_1 \cdot \frac{3}{4} + S_0 \cdot \frac{3b}{a+3b}$
$N_{11} = T_1 \cdot \frac{1}{4} + S_1 \cdot \frac{b}{5a+b}$&lt;/p&gt;

&lt;p&gt;有了 $N_{00},N_{01},N_{10},N_{11}$ 可以重新估計 $(a, b)$ using joint pdf&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a'=\frac{N_{00}+N_{01}}{6 N} \quad b'=\frac{N_{10}+N_{11}}{4 N}&lt;/script&gt;

&lt;p&gt;Q: 如何證明這個方法是最佳或是對應 complete data MLE or incomplete/hidden data MLE? 甚至會收斂？&lt;/p&gt;

&lt;h4 id=&quot;em-algorithm-邏輯&quot;&gt;EM algorithm 邏輯&lt;/h4&gt;

&lt;h3 id=&quot;前提摘要-1&quot;&gt;前提摘要&lt;/h3&gt;
&lt;h3 id=&quot;gmm-特例estimate-means-of-two-gaussian-distributions-known-variance-and-ratio-unknown-means&quot;&gt;GMM 特例：Estimate Means of Two Gaussian Distributions (known variance and ratio; unknown means)&lt;/h3&gt;

&lt;p&gt;We measure lengths of vehicles. The observation space is two-dimensional, with $x$ capturing vehicle type (binary) and $y$ capturing length (Gaussian).&lt;/p&gt;

&lt;p&gt;$p(x, y)$  $x\in$ {car, truck},  $y \in \mathbb{R}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\text {car}, y)=\pi_{\mathrm{c}} \mathcal{N}\left(y \mid \mu_{\mathrm{c}}, \sigma_{\mathrm{c}}=1\right)=\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y-\mu_{\mathrm{c}}\right)^{2}\right\},\left(\kappa_{\mathrm{c}}=\frac{\pi_{\mathrm{c}}}{\sqrt{2 \pi}}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\text {truck,} y)=\pi_{\mathrm{t}} \mathcal{N}\left(y \mid \mu_{\mathrm{t}}, \sigma_{\mathrm{t}}=2\right)=\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y-\mu_{\mathrm{t}}\right)^{2}\right\},\left(\kappa_{\mathrm{t}}=\frac{\pi_{\mathrm{t}}}{\sqrt{8 \pi}}\right)&lt;/script&gt;

&lt;p&gt;where $\pi_c + \pi_t = 1$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/16247543929429/16266210341198.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;例三-complete-data-easy-case&quot;&gt;例三 Complete Data (Easy case)&lt;/h3&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;T=\{\underbrace{\left(\operatorname{car}, y_{1}^{(c)}\right),\left(\operatorname{car}, y_{2}^{(c)}\right), \ldots,\left(\operatorname{car}, y_{C}^{(c)}\right)}_{C \text { car observations }}, \underbrace{\left(\text {truck}, y_{1}^{(\mathrm{t})}\right),\left(\text {truck}, y_{2}^{(\mathrm{t})}\right), \ldots,\left(\text {truck}, y_{T}^{(\mathrm{t})}\right)}_{T \text { truck observations }}\}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Log-likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(\mathcal{T})=\sum_{i=1}^{N} \ln p\left(x_{i}, y_{i} \mid \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)=C \ln \kappa_{\mathrm{c}}-\frac{1}{2} \sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{\mathrm{c}}\right)^{2}+T \ln \kappa_{\mathrm{t}}-\frac{1}{8} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)^{2}&lt;/script&gt;

&lt;p&gt;很容易用 MLE 估計 $\mu_1, \mu_2$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{c}}}=\sum_{i=1}^{C}\left(y_{i}^{(\mathrm{c})}-\mu_{\mathrm{c}}\right)=0 \quad \Rightarrow \quad \mu_{\mathrm{c}}=\frac{1}{C} \sum_{i=1}^{C} y_{i}^{(c)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{t}}}=\frac{1}{4} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)=0 \quad \Rightarrow \quad \mu_{\mathrm{t}}=\frac{1}{T} \sum_{i=1}^{T} y_{i}^{(\mathrm{t})}&lt;/script&gt;

&lt;p&gt;直觀上很容易理解。如果 observations 已經分組，求 mean 只要做 sample 的平均即可。&lt;/p&gt;

&lt;p&gt;以這個例子，ratio $\pi_c, \pi_t$ 不論已知或未知，都不影響結果。&lt;/p&gt;

&lt;h3 id=&quot;例四-incompletehidden-data&quot;&gt;例四 incomplete/hidden Data&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{T}=\{\left(\operatorname{car}, y_{1}^{(c)}\right), \ldots,\left(\operatorname{car}, y_{C}^{(c)}\right),\left(\text {truck}, y_{1}^{(\mathrm{t})}\right), \ldots,\left(\text {truck}, y_{T}^{(\mathrm{t})}\right), \underbrace{\left(\bullet, y_{1}^{\bullet}\right), \ldots,\left(\bullet, y_{M}^{\bullet}\right)}_{\begin{array}{l}
\text { data with uknown } \\
\text { vehicle type }
\end{array}}\}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p\left(y^{\bullet}\right)=p\left(\text {car}, y^{\bullet}\right)+p\left(\text {truck}, y^{\bullet}\right)&lt;/script&gt;

&lt;p&gt;Log-likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(\mathcal{T})=\sum_{i=1}^{N} \ln p\left(x_{i}, y_{i} \mid \mu_{c}, \mu_{\mathrm{t}}\right)=\overbrace{C \ln \kappa_{\mathrm{c}}-\frac{1}{2} \sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{\mathrm{c}}\right)^{2}+T \ln \kappa_{\mathrm{t}}-\frac{1}{8} \sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)^{2}}^{\text {same term as before }} \\
+\sum_{i=1}^{M} \ln \left(\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}+\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)^{2}\right\}\right)&lt;/script&gt;

&lt;p&gt;不用微分也知道非常難解 MLE. 我們必須用另外的方法，就是 EM 算法。
不過我們還是微分一下，得到更多的 insights.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
0=\frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{c}}} &amp;=\sum_{i=1}^{C}\left(y_{\mathrm{c}}^{(\mathrm{c})}-\mu_{\mathrm{c}}\right) \\
&amp;+ \sum_{i=1}^{M} \overbrace{\frac{\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}}{\kappa_{\mathrm{c}} \exp \left\{-\frac{1}{2}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)^{2}\right\}+\kappa_{\mathrm{t}} \exp \left\{-\frac{1}{8}\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)^{2}\right\}}}^{p\left(\operatorname{car} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)}\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0=4 \frac{\partial \ell(\mathcal{T})}{\partial \mu_{\mathrm{t}}}=\sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)+\sum_{i=1}^{M} p\left(\text {truck} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)&lt;/script&gt;

&lt;p&gt;上兩式非常有物理意義。基本是 easy case 的延伸：已知分類的平均值，加上未知分類的機率平均值。一個簡單的方法是只取前面已知的部分平均，不過這不是最佳，因為丟失部分的資訊。&lt;/p&gt;

&lt;h4 id=&quot;missing-values-em-approach&quot;&gt;Missing Values, EM Approach&lt;/h4&gt;
&lt;p&gt;重新 summarize optimality conditions&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^{C}\left(y_{i}^{(c)}-\mu_{c}\right)+\sum_{i=1}^{M} p\left(\operatorname{car} \mid y_{i}^{\bullet}, \mu_{c}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{c}}\right)=0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^{T}\left(y_{i}^{(\mathrm{t})}-\mu_{\mathrm{t}}\right)+\sum_{i=1}^{M} p\left(\text {truck } \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)\left(y_{i}^{\bullet}-\mu_{\mathrm{t}}\right)=0&lt;/script&gt;

&lt;p&gt;如果 $p(\text {truck} \mid y_{i}^{\bullet}, \mu_c, \mu_t)$ 和 $p(\text {car} \mid y_{i}^{\bullet}, \mu_c, \mu_t)$ 已知，上式非常容易解 $\mu_c$ and $\mu_t$。實際這是一個雞生蛋、蛋生雞的問題，因為這兩個機率又和 $\mu_c$ and $\mu_t$ 相關。&lt;/p&gt;

&lt;p&gt;EM algorithm 剛好用來打破這個迴圈。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Let $z_i \,(i=1, 2, \cdots, M), z_i \in \text{{car, truck}}$ denote the &lt;strong&gt;missing data&lt;/strong&gt;.  Define $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$&lt;/li&gt;
  &lt;li&gt;上述 optimality equations 可以得到&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{\mathrm{c}}=\frac{\sum_{i=1}^{C} y_{i}^{(\mathrm{c})}+\sum_{i=1}^{M} q\left(z_{i}=\mathrm{car}\right) y_{i}^{\bullet}}{C+\sum_{i=1}^{M} q\left(z_{i}=\mathrm{car}\right)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{\mathrm{t}}=\frac{\sum_{i=1}^{T} y_{i}^{(\mathrm{t})}+\sum_{i=1}^{M} q\left(z_{i}=\text { truck }\right) y_{i}^{\bullet}}{T+\sum_{i=1}^{M} q\left(z_{i}=\text { truck }\right)}&lt;/script&gt;

&lt;p&gt;EM Algorithm 可以用以下四步驟表示&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize $\mu_c$, $\mu_t$&lt;/li&gt;
  &lt;li&gt;Compute $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$ for $i = 1, 2, \cdots, M$&lt;/li&gt;
  &lt;li&gt;Recompute $\mu_c$, $\mu_t$ according to the above equations.&lt;/li&gt;
  &lt;li&gt;If termination condition is met, finish.  Otherwise, goto 2.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;上述步驟 2 稱為 Expectation (E) Step, 步驟 3 稱為 Maximization (M) Step.  統稱為 EM algorithm.&lt;/p&gt;

&lt;p&gt;Q. Why Step 2 稱為 Expectation? not clear.  Maximization 比較容易理解，因為 optimality condition 就是 maximization (微分為 0).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In summary&lt;/strong&gt;, EM algorithm 的一個關鍵點是：讓 incomplete/hidden data 變成 complete (Expectation?).  有了完整的 data, 就容易用 MLE 找到 maximal likelihood estimation ($\mu_c$ and $\mu_t$ in this case).&lt;/p&gt;

&lt;h2 id=&quot;clustering-soft-assignment-vs-hard-assignment-k-means&quot;&gt;Clustering: Soft Assignment Vs. Hard Assignment (K-means)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/media/16270144925547/16270374215686.jpg&quot; style=&quot;zoom: 67%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;em-algorithm-derivation&quot;&gt;EM Algorithm Derivation&lt;/h2&gt;

&lt;p&gt;EM algorithm 如果只是 heuristic algorithm, 可能有用度大幅縮減。以下討論 EM 數學上的 formulation.  先定義 terminologies&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\mathbf{x}$: observed random variables (下圖雙圓框)&lt;/li&gt;
  &lt;li&gt;$\mathbf{z}$: hidden random variables (下圖單圓框)&lt;/li&gt;
  &lt;li&gt;$\mathbf{\theta}$: fixed model parameters to be estimated (下圖單方框)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210905175447897.png&quot; alt=&quot;image-20210905175447897&quot; style=&quot;zoom:80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;目標：Find $\theta^*$ to maximize likelihood or marginal likelihood 如下 $\eqref{eqMLE}$. 此處 $\theta$ 是一個 fixed parameter, 不是一個 random variable.  所以我們用 $p(x; \theta)$ notation, 而避免用 $p(x \mid \theta)$ notation. 不過有時候引用其他文章還是難以完全避免，可以從上下文判斷。&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\begin{align}
\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ell(\boldsymbol{\theta})=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{x} ; \boldsymbol{\theta}) \label{eqMLE}
\end{align}&lt;/script&gt;​&lt;/p&gt;

&lt;p&gt;思路：假設解下列完整 data 很容易解 (例如例一和例三)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \label{eqMLE2}
\end{align}&lt;/script&gt;

&lt;p&gt;我們的想法是把 $\eqref{eqMLE}$ 先變形成上式 $\eqref{eqMLE2}$，再想辦法優化&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x} ; \boldsymbol{\theta}) &amp;=\ln \sum_{\mathbf{z}} p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) \nonumber \\
&amp;=\ln \sum_{\mathbf{z}} q(\mathbf{z}) \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}  \label{eqMLE3}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;這裡引入看似任意 probability distribution $q(\mathbf{z})$ with $\sum_{\mathbf{z}} q(\mathbf{z})=1$. 後面會說明如何選 $q(\mathbf{z})$.&lt;/p&gt;

&lt;h3 id=&quot;log-likelihood-with-hidden-variable-lower-bound&quot;&gt;Log-Likelihood with Hidden Variable Lower Bound&lt;/h3&gt;

&lt;p&gt;上式 $\eqref{eqMLE3}$ 利用 Jensen’s inequality 可以導出 $\geq \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}$&lt;/p&gt;

&lt;p&gt;我們定義 $\ln p(\mathbf{x} ; \boldsymbol{\theta})$ 的 lower bound or ELBO (Evidence Lower BOund) 為 $\mathcal{L}(q, \boldsymbol{\theta})$, for any distribution $q(\mathbf{z})$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\mathcal{L}(q, \boldsymbol{\theta})=\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} \label{eqELBO}
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;這已經非常接近思路！我們的思路修正成把有 hidden data 的 MLE 變成用完整 data 的 MLE 做為 lower bound.  再通過 $q(\mathbf{z})$ 提高 lower bound 逼近原來的目標。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Maximizing $\mathcal{L}(q, \boldsymbol{\theta})$ by choosing $q(\mathbf{z})$ 就可以 push the log likelihood $\ln p(\mathbf{x} ; \boldsymbol{\theta})$ upwards.&lt;/p&gt;

&lt;p&gt;反過來我們可以計算和 lower bound 之間的 gap.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x}, \boldsymbol{\theta})-\mathcal{L}(q; \boldsymbol{\theta}) &amp;=\ln p(\mathbf{x} ; \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} \nonumber\\
&amp;=\ln p(\mathbf{x} ; \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln \underbrace{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}_{p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) p(\mathbf{x} ; \boldsymbol{\theta})}-\ln q(\mathbf{z})\} \nonumber\\
&amp;=\ln p(\mathbf{x} ; \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})+\ln p(\mathbf{x} ; \boldsymbol{\theta})-\ln q(\mathbf{z})\} \nonumber\\
&amp;=\ln p(\mathbf{x} ; \boldsymbol{\theta})-\underbrace{\sum_{\mathbf{z}} q(\mathbf{z})}_{1} \ln p(\mathbf{x} ; \boldsymbol{\theta})-\sum_{\mathbf{z}} q(\mathbf{z})\{\ln p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})-\ln q(\mathbf{z})\} \nonumber\\
&amp;=-\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})}{q(\mathbf{z})} \label{eqGAP} \\
&amp;= D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \ge 0 \label{eqKL}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;這個 gap $\eqref{eqKL}$ 深具物理意義，就是 KL divergence between $q(\mathbf{z})$ and posterior  $p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$, 也就是兩者之間的距離，永遠大於 0. 這也和 Jensen Inequality 的結論一致！&lt;/p&gt;

&lt;p&gt;以下是關鍵：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果能找到 $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$ 的 analytical solution，就可以讓 gap 變成 0.  Lower bound $\eqref{eqELBO}$ 就是我們要 maximize 目標，voila!
    &lt;ul&gt;
      &lt;li&gt;例如例四 GMM 的 $p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$ 就是 softmax function.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;即使 $q(\mathbf{z})$ 有 analytical solution, e.g. softmax, 不代表容易解 maximum 以及對應的 parameter.  EM algorithm 就是用來處理這個問題，見下文。&lt;/li&gt;
  &lt;li&gt;假如 $q(\mathbf{z})$ 非常複雜沒有 analytical solution，還有另外方法：variational approximation; 稱為 Bayesian inference；或是用一個 neural network approximate posterior；稱為 variational autoencoder (VAE). 本文不討論，下文再討論。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;em-algorithm-push-the-lower-bound-upwards&quot;&gt;EM Algorithm Push the Lower Bound Upwards&lt;/h3&gt;
&lt;p&gt;Log likelihood function 可以分為兩個部分： ELBO + KL Gap of posterior&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{equation}
\ln p(\mathbf{x} ; \boldsymbol{\theta})=\mathcal{L}(q, \boldsymbol{\theta})+ D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) )
\end{equation}\label{eqSUM}&lt;/script&gt;

&lt;p&gt;從 Jensen’s inequality 得到 $\mathcal{L}(q; \boldsymbol{\theta})$ 是 lower bound.  從 KL divergence $\ge$ 0 再度驗證。&lt;/p&gt;

&lt;p&gt;如果 $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$, the bound is tight.&lt;/p&gt;

&lt;p&gt;接下來看兩個極端的 examples.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Trivial Case:&lt;/strong&gt;&lt;/em&gt;  Hidden variable $\mathbf{z}$ does NOT provide any information of $\mathbf{x}$&lt;/p&gt;

&lt;p&gt;如果 $\mathbf{x}$ 和 $\mathbf{z}$ 完全無關，$p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) = p(\mathbf{z} ; \boldsymbol{\theta})$.  We can make $q(\mathbf{z}) = p(\mathbf{z} ; \boldsymbol{\theta})$
such that $D_{\mathrm{KL}}(q(\mathbf{z}) | p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})) = 0$, 也就是 gap = 0. Lower bound 就變成原來的 log-likelihood function, trivial case.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(q, \boldsymbol{\theta}) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}\\ 
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x} ; \boldsymbol{\theta}) p(\mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{x} ; \boldsymbol{\theta})\\
&amp;= \ln p(\mathbf{x} ; \boldsymbol{\theta})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;Case 2:&lt;/strong&gt;&lt;/em&gt; 如果  $p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$ 有 analytical solution, let $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(q, \boldsymbol{\theta}) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})}\\ 
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) p(\mathbf{x} ; \boldsymbol{\theta})}{q(\mathbf{z})} \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{x} ; \boldsymbol{\theta})\\
&amp;= \ln p(\mathbf{x} ; \boldsymbol{\theta})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;其實這就是 EM algorithm 的精髓&lt;/p&gt;

&lt;h2 id=&quot;em-具體步驟&quot;&gt;EM 具體步驟&lt;/h2&gt;

&lt;p&gt;Recap EM algorithm:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gap 可以視為從 observables 推論出 unobservables, i.e. incomplete/hidden data, &lt;strong&gt;對應 EM algorithm 的 E-Step.&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Lower bound 其實可以視為 MLE of complete data， &lt;strong&gt;對應 EM algorithm 的 M-Step.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Recap lower bound $\eqref{eqELBO}$ 包含兩個部分：(i) $q(\mathbf{z})$ distribution and (ii) log-likelihood of complete data, $\ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})$.&lt;/p&gt;

&lt;p&gt;這兩個部分剛好對應 EM algorithm 的 E-step (i) and M-step (ii).&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Initialize $\boldsymbol{\theta}=\boldsymbol{\theta}^{(0)}$&lt;/li&gt;
  &lt;li&gt;E-step (Expectation):&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
q^{(t+1)}=\underset{q}{\operatorname{argmax}} \mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right) \label{eqEstep}
\end{align}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;M-step (Maximization):&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \mathcal{L}\left(q^{(t+1)}, \boldsymbol{\theta}\right) \label{eqMstep}
\end{align}&lt;/script&gt;

&lt;h3 id=&quot;m-step-qt1-is-fixed&quot;&gt;M-step: $q^{(t+1)}$ is fixed&lt;/h3&gt;
&lt;p&gt;我們先看 M-step $\eqref{eqMstep}$​​, 因為這和 MLE estimate $\theta$​​ 非常相似。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}\left(q^{(t+1)}, \boldsymbol{\theta}\right) &amp;=\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q^{(t+1)}(\mathbf{z})} \\
&amp;=\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})-\underbrace{\sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln q^{(t+1)}(\mathbf{z})}_{\text {const. }}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \sum_{\mathbf{z}} q^{(t+1)}(\mathbf{z}) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{(t)}) \label{eqMstep2}
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;注意 M-Step 和完整 data 的 MLE 思路如下非常接近，只加了對 $q(\mathbf{z})$ 的 weighted sum.&lt;/strong&gt;
&lt;script type=&quot;math/tex&quot;&gt;\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;上式微分等於 0 就可以解 $\theta^{t+1}$。上面例四以及例二就是很好的例子。&lt;/p&gt;

&lt;p&gt;另一個常見的寫法&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} E_{q(z)} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{(t)}) \label{eqMstep3}
\end{align}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;注意 M-Step 是 maximize lower bound, 並不等於 maximize 不完整 data 的 MLE，因為還差了一個 gap function (i.e. KL divergence).  E-Step 的目標才是縮小 gap function, which is also $\boldsymbol{\theta}$ dependent.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;e-step-boldsymbolthetat-is-fixed&quot;&gt;E-step: $\boldsymbol{\theta}^{(t)}$ is fixed&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^{(t+1)}=\underset{q}{\operatorname{argmax}} \mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}\left(q, \boldsymbol{\theta}^{(t)}\right)=\underbrace{\ln p\left(\mathbf{x} ; \boldsymbol{\theta}^{(t)}\right)}_{\text {const. }}-D_{\mathrm{KL}}(q \| p)&lt;/script&gt;

&lt;p&gt;以上 KL divergence 大於等於 0，所以 maximize lower bound 就要讓 要選擇 $q(z)$ 儘量縮小 gap  (i.e. KL divergence) 到 0.  Gap 等於 0 的條件就是&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
q^{(t+1)}(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)}) \label{eqEstep2}
\end{align}&lt;/script&gt;

&lt;p&gt;同樣 E-Step 深具物理意義，就是猜 incomplete/hidden data distribution based on 已知的 observables 和 iterative $\theta$.&lt;/p&gt;

&lt;p&gt;例如例四 E-Step 就是計算 $q\left(z_{i}\right)=p\left(z_{i} \mid y_{i}^{\bullet}, \mu_{\mathrm{c}}, \mu_{\mathrm{t}}\right)$ for $i = 1, 2, \cdots, M$.  結果是 softmax function.&lt;/p&gt;

&lt;h4 id=&quot;conditional-vs-joint-distribution&quot;&gt;Conditional Vs. Joint Distribution&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;我們可以把 conditional distribution 改成 joint distribution 如下。兩者都可以用來解 E-Step.&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)}) = p(\mathbf{z}, \mathbf{x} ; \boldsymbol{\theta}^{(t)}) / p(\mathbf{x} ; \boldsymbol{\theta}^{(t)})&lt;/script&gt;

&lt;h3 id=&quot;em-精髓-結合-e-step-and-m-step&quot;&gt;EM 精髓: 結合 E-Step and M-Step&lt;/h3&gt;

&lt;p&gt;如果 E-Step $\eqref{eqEstep2}$ 有 analytic solution, 可以代入 M-Step $\eqref{eqMstep2}$ 得到有名的 $Q$ function:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
Q(\theta^{t+1} | \theta^{t}) &amp;=  \sum_{\mathbf{z}} p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)}) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{t+1}) \nonumber \\
&amp;= \int d \mathbf{z} \, p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)}) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{t+1}) \\
&amp;= E_{z\sim p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)})} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{(t+1)}) 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;New EM algorithm with fixed $\boldsymbol{\theta}^{t}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{align}
\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} Q(\boldsymbol{\theta}^{t+1} | \boldsymbol{\theta}^{t}) \label{eqQ}
\end{align}&lt;/script&gt;

&lt;h3 id=&quot;qa&quot;&gt;Q&amp;amp;A&lt;/h3&gt;

&lt;p&gt;From $\eqref{eqELBO}$, 我們可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\mathcal{L}(q, \boldsymbol{\theta})&amp;=\sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} \nonumber \\ 
&amp;= - D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z}, \mathbf{x}; \boldsymbol{\theta}) ) \label{eqELBOKL}
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;代入 $\eqref{eqKL}$, 我們可以得到&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x}; \boldsymbol{\theta}) &amp;= \mathcal{L}(q; \boldsymbol{\theta}) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \nonumber \\
&amp;= - D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z}, \mathbf{x}; \boldsymbol{\theta}) ) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \nonumber
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;也就是 &lt;strong&gt;ELBO =&lt;/strong&gt; $\mathcal{L}(q; \boldsymbol{\theta}) = - D_{\mathrm{KL}}(q(\mathbf{z}) | p(\mathbf{z}, \mathbf{x}; \boldsymbol{\theta}) )$. 我們可以反過來驗證&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x}; \boldsymbol{\theta}) &amp;= \sum_z q(z) \ln p(\mathbf{x}; \boldsymbol{\theta}) \nonumber \\
&amp;= \sum_z q(z) \ln \frac{p(z, x; \theta)}{q(z)}  \frac{q(z)}{p(z \mid x; \theta)} \nonumber \\
&amp;= \sum_z q(z) \ln \frac{p(z, x; \theta)}{q(z)} + \sum q(z) \ln \frac{q(z)}{p(z \mid x; \theta)} \nonumber \\
&amp;= - D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z}, \mathbf{x}; \boldsymbol{\theta}) ) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \label{eqKL3} 
\end{align} %]]&gt;&lt;/script&gt;

&lt;p&gt;$\eqref{eqKL3}$ 不免讓人浮想翩翩。 KL divergence 一定為大於等於 0.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果要 maximize (marginal) likelihood $\ln p(x; \theta)$, 好像正確的做法是讓 $\eqref{eqKL3}$ maximize 第一個 KL divergence 為 0； 第二個 KL divergence 越大越好？
    &lt;ul&gt;
      &lt;li&gt;e.g. let $q(z) = p(z, x; \theta) \to \ln p(x; \theta) = 0 + D_{K L}(p(z, x; \theta) | p(z \mid x; \theta) \ge 0$&lt;/li&gt;
      &lt;li&gt;但我們知道 $\ln p(x;\theta) &amp;lt; 0$, 如何解釋這個矛盾？&lt;/li&gt;
      &lt;li&gt;一個是 $\eqref{eqELBOKL}$ 寫成 KL divergence 有問題。因為 KL divergence 是兩個同樣 dimension distribution 的距離 measurement.  $\eqref{eqELBOKL}$ 的 joint distribution $(z, x)$ 的 dimension 大於 $q(z)$，寫成 KL divergence 無意義，也沒有距離的觀念。除非把 joint distribution marginalized 成 $p(z)$, i.e. prior, 才能和 $q(z)$ 做 KL divergence. 或者 with a fixed $x=c$, $\int p(z, x=c; \theta) = 1$ 才能滿足 distribution 的定義。&lt;/li&gt;
      &lt;li&gt;但是 conditional distribution $p(z\mid x)$, i.e. posterior 和 $q(z)$ 則是同樣的 dimension, KL divergence 有意義。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;實務上，我們的做法完全不同，甚至相反。正確的表示式 from $\eqref{eqKL}$ 得到：&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{align}
\ln p(\mathbf{x}; \boldsymbol{\theta}) &amp;= \sum_z q(z) \ln \frac{p(z, x; \theta)}{q(z)} + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta})) 
\end{align} %]]&gt;&lt;/script&gt;

    &lt;ul&gt;
      &lt;li&gt;我們 maximize 第一項 lower bound (ELBO), 以及 minimize 第二項 KL divergence 為 0&lt;/li&gt;
      &lt;li&gt;e.g. $q(z) = p(z \mid x; \theta) \to \ln p(x; \theta) = E_{q(z)} \ln p(z, x; \theta) + H(q) + 0$&lt;/li&gt;
      &lt;li&gt;重點是 find $\theta^* = \arg \max_{\theta} E_{p(z\mid x; \theta)} \ln p(z, x; \theta)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;free-energy-interpretation-poczoscllusteringem2015&quot;&gt;Free Energy Interpretation [@poczosCllusteringEM2015]&lt;/h2&gt;
&lt;p&gt;搞 machine learning 很多是物理學家 (e.g. Max Welling), 習慣用物理觀念套用於 machine learning.  常見的例子是 training 的 &lt;em&gt;momentum&lt;/em&gt; method.  另一個是 &lt;em&gt;energy/entropy&lt;/em&gt; loss function.  此處我們看的是類似 energy loss function.&lt;/p&gt;

&lt;p&gt;我們從 gap 開始&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ln p(\mathbf{x} ; \boldsymbol{\theta})-\mathcal{L}(q, \boldsymbol{\theta}) = D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \ge 0&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\ln p(\mathbf{x} ; \boldsymbol{\theta}) &amp;= \mathcal{L}(q, \boldsymbol{\theta}) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln \frac{p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta})}{q(\mathbf{z})} + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \\
&amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) + \sum_{\mathbf{z}} -q(\mathbf{z}) \ln {q(\mathbf{z})}+ D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \\
&amp;= E_{q(z)} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}) + H(q) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}) ) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where H(q) is the entropy of q,  第一項是負的，第二項和第三項是正的。
我們用一個例子來驗證
q = {0 or 1} with 50% chance, =&amp;gt; 
H(q) = 1 (bit) or ln (?) &amp;gt; 0
Eq(z) ln p(o, z) = -(0.5 (o-u1)^2 + 0.5 (o-u2)^2 ) / sqrt(2pi) &amp;lt; 0&lt;/p&gt;

&lt;p&gt;此處我們 switch to [@poczosCllusteringEM2015] notation.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Observed data: $D = {x_1, \cdots, x_n}$&lt;/li&gt;
  &lt;li&gt;Unobserved/hidden variable: $z = {z_1, \cdots, z_n}$&lt;/li&gt;
  &lt;li&gt;Parameter: $\theta = [\mu_1, \cdots, \mu_K, \pi_1, \cdots, \pi_K, \Sigma_1, \cdots, \Sigma_K]$&lt;/li&gt;
  &lt;li&gt;Goal: $\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} \ln p(D \mid \theta)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;重寫上式：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\ln p(D ; \boldsymbol{\theta}^t) &amp;= \sum_{\mathbf{z}} q(\mathbf{z}) \ln p(D, \mathbf{z} ; \boldsymbol{\theta}^t) + \sum_{\mathbf{z}} -q(\mathbf{z}) \ln {q(\mathbf{z})}+ D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D; \boldsymbol{\theta}^t) ) \\
&amp;= E_{q(z)} \ln p(D, \mathbf{z} ; \boldsymbol{\theta}) + H(q) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D; \boldsymbol{\theta}^t) ) \\
&amp;= F_{\theta^t} (q(\cdot), D) + D_{\mathrm{KL}}(q(\mathbf{z}) \| p(\mathbf{z} \mid D; \boldsymbol{\theta}) )
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;$F_{\theta^t} (q(\cdot), D)$ 稱為 free energy (也就是 ELBO), 包含 joint distribution expectation 和 self-entropy.&lt;/p&gt;

&lt;p&gt;如果 $p(z\mid x; \theta)$ is analytically available (e.g. GMM, this is just a softmax!).  The E-step 基本就是代入 $p(z\mid x; \theta)$ 到  LBO becomes a Q(theta, theta^old) function + H(q)&lt;/p&gt;

&lt;p&gt;The EM algorithm can be summzied as argmax Q!!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;E-step:  代入 $p(z\mid D)$ 到 free-energy (ELBO) update Q function (忽略 self-entropy)&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;Q\left(\theta \mid \theta^{t}\right)=\int d y P\left(y \mid D, \theta^{t}\right) \log P(y, D \mid \theta)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;M-step; argmax Q&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta^{t+1}=\arg \max _{\theta} Q\left(\theta \mid \theta^{t}\right)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It can be proved&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;log likelihood is always increasing! i.e. $\ln P(D\mid \theta^t) \le \ln P(D\mid \theta^{t+1})$  這是 EM 的重要特徵！&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/media/16270144925547/16274030539044.jpg&quot; alt=&quot;-w400&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/media/16270144925547/16274031504070.jpg&quot; alt=&quot;-w408&quot; style=&quot;zoom:33%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use multiple, randomized initialization in practice to avoid strucking at local minima.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;variational-expectation-maximization&quot;&gt;Variational Expectation Maximization&lt;/h2&gt;
&lt;p&gt;EM algorithm 一個問題是對於複雜的問題沒有 analytical from $p(z\mid x)$, then (1) variational EM; or (2) use neural network such as variational autoencoder (VAE).&lt;/p&gt;

&lt;p&gt;Variational EM 的重點是不用 Q function, 因為沒有 $p(z\mid x)$.  重點變成 minimize KL gap function for E-step.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Variational E-step:  Fix $\theta^t$&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;q^{t}(\cdot)=\arg \max _{q(\cdot)} F_{\theta^{t}}(q(\cdot), D)=\underset{q(\cdot)}{\arg \min } K L\left(q(y) \| P\left(y \mid D, \theta^{t}\right)\right)&lt;/script&gt;
      &lt;/li&gt;
      &lt;li&gt;但並不保證會找到 best max/min  $q(y) = p(y \mid D, \theta^t)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Variational M-step; Fix $q^t$&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta^{t+1}=\arg \max _{\theta} F_{\theta}\left(q^{t}(\cdot), D\right)&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Variational EM 並不保證 marginal likelihood 每次都遞增！&lt;/li&gt;
  &lt;li&gt;關鍵問題是如何找到 $q(z)$, 下文會討論。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h4 id=&quot;例二的-conditional-vs-joint-distribution-解法&quot;&gt;例二的 Conditional Vs. Joint Distribution 解法&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;我們之前的 E-Step 是猜 joint distribution, $p(t, s | a, b)$.&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_0$&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$s_1$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_0$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$t_1$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3b&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;b&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;如果用上述的 conditional distribution 可以細膩的看每一個 data.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(\bullet, s_0)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(t \mid s_0, a, b)=\left\{\begin{array}{l}
q\left(t_{0}\right)=p\left(t_{0} \mid s_{0}, a, b\right)=\frac{a}{a+3 b} \\
q\left(t_{1}\right)=p\left(t_{1} \mid s_{0}, a, b\right)=\frac{3 b}{a+3 b}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(\bullet, s_1)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(t \mid s_1, a, b)=\left\{\begin{array}{l}
q\left(t_{0}\right)=p\left(t_{0} \mid s_{1}, a, b\right)=\frac{5a}{5 a+ b} \\
q\left(t_{1}\right)=p\left(t_{1} \mid s_{1}, a, b\right)=\frac{b}{5 a+ b}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(t_0, \bullet)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(s \mid t_0, a, b)=\left\{\begin{array}{l}
q\left(s_{0}\right)=p\left(s_{0} \mid t_{0}, a, b\right)=\frac{1}{6} \\
q\left(s_{1}\right)=p\left(s_{1} \mid t_{0}, a, b\right)=\frac{5}{6}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;對於所有 $(t_1, \bullet)$ 
&lt;script type=&quot;math/tex&quot;&gt;q(s \mid t_1, a, b)=\left\{\begin{array}{l}
q\left(s_{0}\right)=p\left(s_{0} \mid t_{1}, a, b\right)=\frac{3}{4} \\
q\left(s_{1}\right)=p\left(s_{1} \mid t_{1}, a, b\right)=\frac{1}{4}
\end{array}\right.&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;再來是例二的 M-Step&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最後再把所有 dataset 的 weighted sum $(t_i, s_j)$ 統計出來，例如
$S_0$ 個 $(\bullet, s_0) \to \frac{a}{a+3b}S_0$ 個 $(t_0, s_0)$ 和 $\frac{3b}{a+3b}S_0$ 個 $(t_1, s_0)$
$S_1$ 個 $(\bullet, s_1) \to \frac{5a}{5a+b}S_1$ 個 $(t_0, s_1)$ 和 $\frac{b}{5a+b}S_1$ 個 $(t_1, s_1)$
$T_0$ 個 $(t_0, \bullet) \to \frac{1}{6}T_0$ 個 $(t_0, s_0)$ 和 $\frac{5}{6}T_0$ 個 $(t_0, s_1)$
$T_1$ 個 $(t_1, \bullet) \to \frac{3}{4}T_1$ 個 $(t_1, s_0)$ 和 $\frac{1}{4}T_1$ 個 $(t_1, s_1)$&lt;/p&gt;

&lt;p&gt;$(t_0, s_0)$ 個數 $\to N_{00} = \frac{1}{6}T_0+\frac{a}{a+3b}S_0$
$(t_0, s_1)$ 個數 $\to N_{01} = \frac{5}{6}T_0+\frac{5a}{5a+b}S_1$
$(t_1, s_0)$ 個數 $\to N_{10} = \frac{3}{4}T_1+\frac{3b}{a+3b}S_0$
$(t_1, s_1)$ 個數 $\to N_{11} = \frac{1}{4}T_1+\frac{b}{5a+b}S_1$&lt;/p&gt;

&lt;p&gt;因此可以使用完整 data 的 MLE estimation:
&lt;script type=&quot;math/tex&quot;&gt;a'=\frac{N_{00}+N_{01}}{6 N} \quad b'=\frac{N_{10}+N_{11}}{4 N}&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;to-do-next&quot;&gt;To Do Next&lt;/h2&gt;
&lt;p&gt;Go through GMM example.&lt;/p&gt;

&lt;p&gt;下一步 go through HMM model or simplest z -&amp;gt; o graph model.&lt;/p&gt;

&lt;p&gt;What is the mutual information of $o$ and $z$ in this case?&lt;/p&gt;

&lt;p&gt;假設可以有一個 close from Q function, e.g. GMM
&lt;strong&gt;In summary:  M-Step maximize the lower bound;  E-Step close the gap&lt;/strong&gt; 
E-Step
&lt;script type=&quot;math/tex&quot;&gt;q^{(t+1)}(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x}; \boldsymbol{\theta}^{(t)})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;M-Step 
&lt;script type=&quot;math/tex&quot;&gt;\boldsymbol{\theta}^{(t+1)}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}} E_{q(z)} \ln p(\mathbf{x}, \mathbf{z} ; \boldsymbol{\theta}^{(t)})&lt;/script&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><category term="EM" /><summary type="html"></summary></entry><entry><title type="html">Jekyll Memo for Github Blog</title><link href="http://localhost:4000/language/2021/06/30/Jekyll-Memo/" rel="alternate" type="text/html" title="Jekyll Memo for Github Blog" /><published>2021-06-30T16:29:08+08:00</published><updated>2021-06-30T16:29:08+08:00</updated><id>http://localhost:4000/language/2021/06/30/Jekyll-Memo</id><content type="html" xml:base="http://localhost:4000/language/2021/06/30/Jekyll-Memo/">&lt;p&gt;幾個重點&lt;/p&gt;

&lt;h2 id=&quot;header&quot;&gt;Header&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;title line:  no other :,  wrong example:  title: Math AI : xxx =&amp;gt; the second : to be removed!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;tags: [xxx, xxx, xxx]&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;table&quot;&gt;Table&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;目前 Jekyll + Next theme 造成 table column width 非常寬。 I don’t know the exact reason.  I changed the xxx/xxx.github.io/_sass/_common/scaffolding/tables.scss
    &lt;ul&gt;
      &lt;li&gt;width: 300px;&lt;/li&gt;
      &lt;li&gt;table-layout: auto;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;equation&quot;&gt;Equation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;\$\$ math equation \$\$ =&amp;gt; leave empty lines “before” and “after” \$\$ \$\$! 也就是上下各要空一行！&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;${{ }}$  =&amp;gt; ${ \{ \}}$.  如果要打 {, 一定要加 \{.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Equation number:  必須先加上 header 如下。Reference: https://jdhao.github.io/2018/01/25/hexo-mathjax-equation-number/&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The commands \tilde, \dot, \ddot, \hat, and \bar mess up with subscripts;  https://github.com/mathjax/MathJax/issues/2474
 solution for me:  add a _ instead of _!!!&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/x-mathjax-config&quot;&amp;gt;
MathJax.Hub.Config({
TeX: { equationNumbers: { autoNumber: &quot;AMS&quot; } }
});
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Equation 本體&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$$\begin{equation}
E=mc^2
\end{equation}\label{eq1}$$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;或是&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$$\begin{align}
E=mc^2  \\         =&amp;gt; auto number 
p = mv \nonumber \\  =&amp;gt; without equation number
F = ma  \label{eqF} \\.  
\end{align}$$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Equation citation use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$\eqref{eq1}$&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mweb 可以直接產生 equation number!&lt;/li&gt;
  &lt;li&gt;Typora 需要 enable :preference :Markdown :Auto Numbering Math Equations”.  不過結果很奇怪。所有的 equation 都有 number in Typora!  但 Jekyll 正常。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image&quot;&gt;Image&lt;/h2&gt;
&lt;p&gt;Markdown resize image 似乎有問題，需要另外的 plug-in =&amp;gt; No!&lt;/p&gt;

&lt;p&gt;我找到一個 work around in Mweb!  使用 &amp;lt;img src …., width=””&amp;gt; 取代 Mweb copy and paste image.&lt;/p&gt;

&lt;p&gt;不過後來我發現 typora 可以直接做，所有 method 2 is using Typora&lt;/p&gt;

&lt;h3 id=&quot;method-1-mweb&quot;&gt;Method 1: Mweb&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Mweb: copy and paste image 自動產生。如下圖中的
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;![-w414](/media/16286850167880.jpg )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;此時同時在 editing window and preview window 都有圖。如下圖左和右上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;我找到的 work around 加在後一行。只會在 preview window 有圖。如下圖右下。
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;img src=&quot;/media/16286850167880.jpg&quot; width=&quot;414&quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/16289455797795.jpg&quot; alt=&quot;-w993&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;問題是這種 image resize 只對 mweb 有效。在 Jekyll 之後的截圖如下 (127.0.0.1:4000)，就不對。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Jekyll 直接忽略 [-w414] in the first image! 因此第一行產生原圖。但接受第二行的 image size
&lt;img src=&quot;/media/16289465237748.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I check the html source code&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/media/16289463211491.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;第一行轉譯的結果：alt=”-w245” 顯然被忽略。&lt;/li&gt;
      &lt;li&gt;第二行轉譯的結果：width=”245” 是正確結果。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;我找到的方法是把第一行改成第二行。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;method-2-typora-how&quot;&gt;Method 2: Typora, How?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;首先要解決的是 root path 的問題！ Jekyll (and therefore github) 有 root path 的觀念。For my local root directory:  /Users/allenlu/Onedrive/allenlu2009.github.io.   文章是在 root: /_posts/xxx;  image 是在 /media/xxx&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Mweb 似乎自動解決這個問題。 Image 直接 refer to:  /media/xxx.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Typora 如何設定？ 有兩個方法&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;直接在本文加上： typora-root-url: ../../allenlu2009.github.io&lt;/p&gt;

        &lt;p&gt;&lt;img src=&quot;/media/image-20210814233107185.png&quot; alt=&quot;image-20210814233107185&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Typora: Format: Image: Use Image Root Path: set to the above directory&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Typora insert image 必須先設定 image save path&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Preference: Image: Copy image to custom folder:
        &lt;ul&gt;
          &lt;li&gt;/Users/allenlu/OneDrive/allenlu2009.github.io/media&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Typora 在設定 display path 之後和 Jekyll 一樣，可以 display image, 但是不會 scale image size!!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果 mweb 改成 “&amp;lt;src img xxx&amp;gt;”  之後 OK.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;不過我發現有更好的方法，就是直接用 typora 的 image zoom 設定。自動就會轉成 &amp;lt;src img,  , zoom xxx&amp;gt; 可以 image resize!!&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;editor&quot;&gt;Editor&lt;/h3&gt;

&lt;p&gt;Mweb&lt;/p&gt;

&lt;p&gt;Typora&lt;/p&gt;

&lt;p&gt;VS Code&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;VS code default math rendering tool is KaTex, which is different from MathJax.  KaTex does not support /label and cross reference.   So I install “Mardown Preview Enhance” and switch the default math engine from KaTex to MathJax.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/media/image-20210911004231947.png&quot; alt=&quot;image-20210911004231947&quot; style=&quot;zoom:50%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;問題是 MathJax mode is buggy!!  Not support \boldsymbol!!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;結論&quot;&gt;結論&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;使用 Typora for image resize (zoom), 當然要設好 typora-root-url (for display), and image save path.  結果是 typora, Mweb, Jekyll/github OK.&lt;/li&gt;
  &lt;li&gt;使用 Mweb,  需要手動改變 image to &amp;lt;src img …., width=”xxx”&amp;gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;推薦使用 1!!!&lt;/p&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="Jekyll" /><category term="Github" /><summary type="html">幾個重點</summary></entry><entry><title type="html">Typora and Mermaid</title><link href="http://localhost:4000/ai/2021/02/16/Typora-Mermaid/" rel="alternate" type="text/html" title="Typora and Mermaid" /><published>2021-02-16T16:29:08+08:00</published><updated>2021-02-16T16:29:08+08:00</updated><id>http://localhost:4000/ai/2021/02/16/Typora-Mermaid</id><content type="html" xml:base="http://localhost:4000/ai/2021/02/16/Typora-Mermaid/">&lt;p&gt;本文測試 Typora 加上 Mermaid script.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;sequenceDiagram
    participant Alice
    participant Bob
    Alice-&amp;gt;John: Hello John, how are you?
    loop Healthcheck
        John-&amp;gt;John: Fight against hypochondria
    end
    Note right of John: Rational thoughts &amp;lt;br/&amp;gt;prevail...
    John--&amp;gt;Alice: Great!
    John-&amp;gt;Bob: How about you?
    Bob--&amp;gt;John: Jolly good!
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-mermaid&quot;&gt;graph LR
A[方形] --&amp;gt;B(圆角)
    B --&amp;gt; C{条件a}
    C --&amp;gt;|a=1| D[结果1]
    C --&amp;gt;|a=2| E[结果2]
    F[横向流程图]
&lt;/code&gt;&lt;/pre&gt;</content><author><name>Allen Lu (from John Doe)</name></author><category term="softmax" /><summary type="html">本文測試 Typora 加上 Mermaid script.</summary></entry></feed>